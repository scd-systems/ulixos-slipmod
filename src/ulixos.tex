\documentclass[a4paper,twoside,open=right]{scrreprt}
%\documentclass[a4paper,twoside,open=right,twocolumn,7pt]{scrreprt}
%\documentclass[a4paper,twoside,open=right,chapterprefix]{scrreprt}
\usepackage[usenames]{color}
\usepackage{minitoc}
\usepackage{microtype}  % optischer Randausgleich

% Babel tip: http://tex.stackexchange.com/questions/27198/babel-adding-ngerman-s-language-shorthands-to-english-as-the-main-document-lan
% "= : Trennung
% "- : weiches Trennzeichen
% Beispiel: Das Ulix"=Be"-triebs"-sys"-tem
\usepackage[ngerman,english]{babel}
\useshorthands{"}
\addto\extrasenglish{\languageshorthands{ngerman}}

\usepackage{hyperref}
\usepackage{noweb}
\usepackage[latin1]{inputenc}
\usepackage{url,graphicx,boxedminipage,a4wide}
\noweboptions{smallcode,english,externalindex}
% fix for empty pages after code chunks
% found in FAQ, http://www.cs.tufts.edu/~nr/noweb/FAQ.html
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par


\usepackage{listings}
\usepackage{type1cm} % beliebig skalierbare Fonts, z. B. \fontsize{3.32}{4}

%\renewcommand{\ttdefault}{ulg}  % tt-font: blg = letter gothic
%\usepackage{inconsolata}  % blg font...

%%% escaping < <:
%%% add a @ character in front of < <
%%% like this:
%%%    @<<  or   @>>

\definecolor{LinkColor}{rgb}{0.18,0,0.44}
\hypersetup{
  pdfauthor={Hans-Georg Eßer},
  pdftitle={Design, Implementation, and Evaluation of the ULIX-i386 Teaching Operating System},
  colorlinks=true,
  urlcolor=blue,
  linkcolor=LinkColor
}


% relax noweb's page breaking rules (taken from Noweb FAQ) at
% http://www.eecs.harvard.edu/~nr/noweb/FAQ.html
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par

% Bessere Einrueckungen im Inhaltsverzeichnis:
\usepackage{tocloft}
% auskommentiert: Variante fuer normale Nummerierung
%\setlength{\cftsecnumwidth}{1.2cm}
%\setlength{\cftsubsecindent}{1.8cm}
% aktiv: Variante fuer Nummerierung A-1.1 etc.

\setlength{\cftchapnumwidth}{1.1cm}

\setlength{\cftsecnumwidth}{1.5cm}
\setlength{\cftsecindent}{1.1cm}

\setlength{\cftsubsecnumwidth}{1.6cm}
\setlength{\cftsubsecindent}{2.6cm}       % 1.2.3

\setlength{\cftsubsubsecnumwidth}{1.6cm}
\setlength{\cftsubsubsecindent}{4.2cm}   % 1.2.3.4


% \renewcommand{\cftchapaftersnum}{.}  %% 1. 2.  statt 1  2 bei chapter

% prepare for index generation
\usepackage{makeidx}
\makeindex


\setcounter{secnumdepth}{4}   % until 1.2.3.4

\newcommand{\eg}{e.\,g.}

\newtheorem{definition}{Definition}

% some typesetting for identifiers in formulas:
\newcommand{\id}[1]{\textit{#1}}


% for indexing (definitions from Felix)
% plain index, additional term to be added (does not appear in text)
\newcommand{\pindex}[1]{\index{#1}}
% like plain index, term is sorted according to first argument but
% typeset as second argument (example: \pcindex{TeX}{\TeX{}})
\newcommand{\pcindex}[2]{\index{#1@#2}}
% verbatim index, term appears in index and in text as is
\newcommand{\vindex}[1]{#1\index{#1}}
%
% indicate where work needs to be done
\newenvironment{work}{\noindent\begin{boxedminipage}{\textwidth}}{\end{boxedminipage}}

\newcommand{\Ulix}{\textsc{Ulix}}
\newcommand{\UlixI}{\Ulix{}-i386}

\newcommand{\shellcmd}[1]{{\tt #1}}

\newcommand{\codesymbol}{*}
\newcommand{\codesection}[1]{\section{#1\codesymbol{}}}

% give normal text in math formulas
\newcommand{\text}[1]{\mbox{#1}}



% Farben:
%\definecolor{black}{rgb}{0,0,0}
\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{green}{rgb}{0,0.5,0}
\definecolor{red}{rgb}{1.0,0,0}
\newcommand\blue{\color{darkblue}}
\newcommand\green{\color{green}}
\newcommand\black{\color{black}}
\newcommand\red{\color{red}}

% Kommentar: Kasten, rot
\newcommand\comment[1]{
  \noindent
  \begin{boxedminipage}{\textwidth}
  \red{}#1\black{}
  \end{boxedminipage}
}

% ordentliche Fussnoten:
\deffootnote[1.5em]{1.5em}{1em} {\textsuperscript{\thefootnotemark}\,\,\,}
% \deffootnotemark{\textsuperscript{\thefootnotemark}}

% part numbering: A, B, ...
\renewcommand*{\thepart}{\Alph{part}}

%%\renewcommand*{\thechapter}{\Alph{part}-\arabic{chapter}}


% hex addresses such as C000.0000: Courier font, small, 0x prefix
\newcommand\hexaddr[1]{{\small\tt 0x#1}}


\begin{document}

\nocite{esser:2011a, esser:2011b}
\nocite{Shanley:1996:PMS:547184}   % Protected Mode Software Architecture
\nocite{Esser-Doelle-Linux-2007}

\title{
% \includegraphics[width=10cm]{pics/fau_logo_dina1_4c.pdf}\\[2.5cm]
\Huge\bf Design, Implementation, \\ and Evaluation of the\\ ULIX-i386 
\\ Teaching Operating System\\[2.5cm]
\LARGE 
Design, Implementation und Evaluation\\
des Lehrbetriebssystems ULIX-i386\\[2.5cm]
\Large
% PhD Thesis in Computer Science\\
% University of Erlangen and Mannheim\\
--- Thesis; draft version ---}
\author{\Large\bf Hans-Georg Eßer}
\date{\today{}}

\maketitle

\pagebreak 

\pagebreak

\cleardoublepage

%${}$
%\vspace{5cm}
%\begin{quote}
%\noindent
%\emph{You can be a master \\
%Don't wait for luck \\
%Dedicate yourself and you gonna find yourself \\[2mm]
%Standing in the hall of fame \\
%And the world's gonna know your name \\
%Cause you burn with the brightest flame }\\
%
%\raggedleft 
%--- ``Hall of Fame'' lyrics (The Script feat. will.i.am)
%\end{quote}
%
%\cleardoublepage

\begin{abstract}
\begin{centering}
\sffamily\textbf{\Large Abstract}\\[2mm]
\end{centering}

\noindent
For this thesis, I have implemented and documented a simple Unix-like 
operating system which is intended to be used in an introductory
operating systems course. Several other systems have been designed for
the same purpose, the novelty of this approach lies in using Knuth's
technique called ``Literate Programming'' which puts the focus on
documentation with embedded code, rather than code with embedded
documentation. The literate program is a book---in this case an
introduction to operating systems' principles which can be found in
the appendix.

The thesis summarizes the research carried out while conceptually
designing and implementing \Ulix-i386 as well as evaluating its value
in an operating systems course.\\[5mm]

\begin{centering}
\sffamily\textbf{\Large Zusammenfassung}\\[2mm]
\end{centering}

\noindent
Deutsche Zusammenfassung


\end{abstract}



\cleardoublepage


\setcounter{tocdepth}{3}   % for front TOC
\doparttoc
\tableofcontents


\pagestyle{headings}

\part{First Part---I Need a Name}

\chapter{Introduction}

\vspace{1cm}
\begin{quote}
\raggedleft
\emph{Hello everybody out there using minix --
I'm doing a (free) operating system \\(just a hobby, won't
be big and professional like gnu) for 386 (486) AT clones.}\\
\raggedleft
--- Linus Torvalds, August 1991 
\end{quote}
\vspace{1cm}

\noindent
Yet another Unix-like operating system---this could be a description
of the project described in this thesis, and it would not be wrong, but
still miss the point entirely.

The goal was not to reinvent Unix (and as far as the code is concerned,
this has not happened) but to find out how Literate Programming
\cite{Knuth:1984:LP}
(a coding / documenting technique invented by Donald E.{} Knuth) can improve an
operating systems course through offering improved insight into the code
of a real operating system.

The full source code of \Ulix{}, the ``Literate Unix'', can be found
in part \ref{part:ulixbook} of this thesis, and it can be read like
a book. In fact, this second part of the thesis \emph{is} a book: an
introduction to the theory of operating systems which covers the
typical topics found in many other undergraduate texts, such as those
by
  Tanenbaum \cite{tanenbaum2008modernos} or
  Silberschatz et al.{} \cite{silberschatz2008osconcepts}.
But each chapter does not only present
the theory, but also includes one or more code sections which show how
to turn the theory into real code that runs on Intel-based PCs. 
The Literate Programming technique
allows to present code parts in the order in which a programmer would
start thinking about (and implementing) them and thus allows the
reader to easily grasp how each part works and how the whole operating
system is built from many basic blocks.

\Ulix{} itself is, from a technical point of view, rather simple. It
implements some of the Unix standards but does not aim to be a truly
useful operating system like Linux or the BSDs; even early versions of
Tanenbaum's Minix
\cite{Tanenbaum:1987:OSD}
were already more advanced than \Ulix{}. No attempts for optimization have been
made because that is what makes the code of most systems hard to read and
understand. For the purpose of teaching OS concepts, such optimizations
are not necessary or helpful, anyway.

Besides writing the \Ulix{} code and the \Ulix{} book (they are actually
the same, as will be seen after reading the description of Literate
Programming), I have used \Ulix{} in a course named ``Operating System
Development with Literate Programming'' at Nuremberg Technical
University (Technische Hochschule Nürnberg). This course was evaluated
using pre- and post-testing and a comparison group in order to find out
how helpful my approach to teaching OS principles is for students, in that
it may improve and deepen the understanding of the theoretical concepts
through seeing a full real implementation. 

%and I have created a website with approximately 
%20 hours of videos, with accompanying coursework tasks and forums which
%allow discussing the course. The traditional lectures and the video site
%were used to evaluate how helpful the Literate Programming approach is
%for students.


\section{Who should read this thesis?}

Besides the obvious limited target group (consisting of those who
grade this thesis), there is a larger intended audience, and I hope that
the text will prove useful to both of them:

\begin{itemize}
\item Instructors who teach operating systems can benefit from the
detailed evaluation if they consider using a similar approach in their
own lectures. To them, I would suggest reading the whole thesis except
for the short introduction to the OS topics in the first part.
\item Students taking an OS course (or those who are interested in the
topic for reasons of their own) can use the second part as a general
introduction to OS concepts, and for them that second part is available
as a separate document.
\end{itemize}


\section{Outline}

After the introduction ...


\chapter{Basics}

\section{Introduction}

\section{Operating Systems}

\section{Linking and Booting}

\subsection{The GNU Linker ld}


\subsection{Boot Managers}

\UlixI{} uses the GRUB Boot Manager (Grand Unified Boot Manager) which
can handle loading the kernel and initial RAM disks from several media,
including floppy disk and CD-ROM images. It is the standard boot manager
for most modern distributions of the Linux operating system and as such
has been well-documented.





\subsection{Literature on Memory Management}

\cite{robinson-memory1, robinson-memory2}


\section{Literate Programming}

Literate Programming is a programming style which was invented
by Donald E. Knuth who used it for his implementation of the
\TeX{} language. The standard method of writing code documentation
is to insert comments into the source code. If this is done in some
specific, consistent way, tools like Javadoc can generate a
separate documentation file from the source code which can be
compiled into a PDF document. However, in all of those methods,
the code comes first. Projects are split into modules consisting
of several source code files, and the arrangement mirrors the
functionalities offered by the program.

With Literate Programming there is a conceptual change in the
programming approach: Here, documentation comes first. A Literate
Program is basically a text describing the program, and the actual
code is inserted in the documentation, thus reversing the normal
ordering.

\subsection{An Introductory Example}

Consider the following simple C program which implements
bubble sort of an array of integers with ten entries: 

{\small
\begin{verbatim}
void bubblesort() {
  int SIZE = 10;
  int i, j, tmp;
  for (j=SIZE; j>1; j--) {
    for (i=0; i<j-1; i++) {
      if (arr[i] > arr[i+1]) {
        tmp = arr[i+1];
        arr[i+1] = arr[i];
        arr[i] = tmp;
      }
    } 
  }
}
\end{verbatim}
}

This is a simple, non-optimized version of bubblesort, taken from
a Wikipedia page (\url{http://de.wikipedia.org/wiki/Bubblesort}).

A traditionally commented version of this program is the following:

{\small
\begin{verbatim}
// bubblesort: sort elements of an array arr[] of size SIZE
void bubblesort() {
  // declarations
  int SIZE = 10;  // size of the array
  int i, j;       // loop variables
  int tmp;        // temporary variable for swapping elements
  // outer loop
  for (j=SIZE; j>1; j--) {
    // check all neighbors in arr[0..j-1] and swap them if their
    // order is wrong
    for (i=0; i<j-1; i++) {
      if (arr[i] > arr[i+1]) {
        // swap neighbors i, i+1 (using tmp as temporary variable)
        tmp = arr[i+1];
        arr[i+1] = arr[i];
        arr[i] = tmp;
      }
    } 
  }
}
\end{verbatim}
}



As a Literate Program the same bubblesort could look like this:\\

To sort a field, we first need to initialize a [[SIZE]] variable
and declare some local variables, such as [[i]] and [[j]] which
are used as loop counters, as well as a temporary variable [[tmp]]:

<<bubblesort: declarations>>=
int SIZE = 10;
int i, j, tmp;
@ 

The main routine of the bubblesort algorithm compares each
field element with its direct (right) neighbor and corrects their order
if it is wrong. After doing this once the biggest element will
be at the end of the list. It then repeats these steps with
a smaller field (ignoring the right-most element). Thus, with each
step in a loop, the unsorted array becomes one element smaller
until there is nothing left to sort:

<<bubblesort program>>=
void bubblesort() {
  <<bubblesort: declarations>>
  for (j=SIZE; j>1; j--) {
    <<bubblesort: check neighbors in range 0..[[j]]>>
  }
}
@

In order to do the neighbor checks, a second loop inside the
outer loop is necessary:

<<bubblesort: check neighbors in range 0..[[j]]>>=
for (i=0; i<j-1; i++) {
  if (arr[i] > arr[i+1]) {
    <<bubblesort: swap elements>>
  }
}
@

For swapping, three commands and usage of a temporary variable
are necessary in a C program:

<<bubblesort: swap elements>>=
tmp = arr[i+1];
arr[i+1] = arr[i];
arr[i] = tmp;
@

Knuth, TeX etc.


\section{Coding Style and Bug Avoidance}

Coding Style:

\begin{verbatim}
rettype function (arguments) {
  bla;
  bla;
  return xy;
}
\end{verbatim}


Since in the first stages a lot of bugs entered the code, I implemented
many of the suggestions by Steve Maguire \cite{Maguire:1993:WSC:151135},
for example \dots

\begin{work}
Give examples
\end{work}

\section{Summary}




\chapter{Contribution}

This thesis presents two contributions to Computer Science research: 

\begin{itemize}
\item \UlixI{} is the first implementation of a complete operating system that
uses Literate Programming. While several authors have used Literate
Programming for smaller projects, it has not been done on this scale before.
\item The evaluation part of this thesis shows how an Operating Systems
course can profit from using the Literate Programming approach.
\end{itemize}

\section{Introduction}

\section{Designing a Teaching Operating System}

\subsection{Design Decisions}

The most important goals in the design of \Ulix-i386 were that (a) the code should
be simple and (b) standard techniques which appear in classical OS courses should
be applied.

\begin{description}

\item[Unix-like:] Unix is an established standard, several Unix systems (e.\,g. Linux, *BSD)
are open source, so the source code is available to students who would like to dig
into a real-world system which implements concepts similar to those in \Ulix-i386.

\item[Minix filesystem:] The original Minix filesystem is well documented, and
Linux supports it to this day (for floppy images with low metadata overhead).

\item[Round Robin scheduler:] Round Robin is one of the standard schedulers
taught in typical OS courses. While it is not optimized and does not treat I/O-heavy
processes fairly, it is good enough to create a usable system.

\item[Simplified disk access:] The decision against integrating a driver for ATA
hard disk controllers was based on the fact that accessing a disk through the ATA
interface is a rather complex task, and for understanding the functionality it is
sufficient to have some sort of disk access which causes processes to block when
reading from or writing to the disk.

\end{description}


\subsection{Implementation Details}

Here we give a brief overview of some of the implementation details.
For a complete description, see the corresponding chapters in Part B.

\subsubsection{Scheduler}

The context switching mechanism in \UlixI{} uses the fact that all
interrupt and system call handlers receive a copy of the current
thread's registers: Every such function is declared as

<<generic handler declaration>>=
sometype handler_function (struct regs *r);
@ ---if a system call or interrupt occurs, the Intel CPU stores
some information (WHICH ONE?) on the stack and jumps to the
handler; the handler then pushes even more information on the
stack. We have designed the handlers so that it does not matter
whether the stack was created by a system call or an interrupt
(some interrupts generate an error code); the system call handler
pushes a zero value instead of an error code (which is 
non-existant for system calls). This makes it easier to call
functions which may be accessed from both system call handlers
and interrupt handlers, as is the case for the scheduler which is
called from both the timer interrupt handler and the [[yield]]
system call handler.

Whenever such a handler executes a more specialized
handler (via a function call), the pointer to this structure is passed 
on as an argument. Selection and order of the individual registers
in this structure are such that the stack contains precisely the
information which the handler and the Intel [[iret]] instruction will 
pop from the stack when the handler's work is done.

Thus, the context switcher can store the current thread's register
contents (including the program counter [[EIP]] and the stack pointer
[[ESP]]) in that thread's thread control block. Then it picks a new
thread to execute and restores its saved register contents.

Since changes to the [[struct regs]] structure are always made in
the addresses which will be the current stack when [[iret]] is
called, the jump back to user mode will always happen with proper
values, and the interrupted and restored thread can continue
execution.

Two things are not dealt with via the [[struct regs]] structure:
the kernel stack and the page tables. So the context switcher
also has to activate the proper stack and tables.

\begin{work}
Idee:

Jeder Prozess hat seinen Kernel Stack an einer festen virtuellen
Adresse, z. B. 1 Seite 0xbfff.f000 - 0xbfff.ffff

Die Zuordnung zu zwei privaten phys. Frames des Prozesses erfolgt
ueber dessen Page Table, aber mit Zugriff nur im Kernel Mode
(Kernel Stack Protection).

Beim fork()en wird der Kernel-Stack kopiert, und alle Adressen
sind automatisch korrekt.

Umschalten auf einen anderen Address Space wechselt automatisch
zum korrekten Kernel Stack.
\end{work}

\subsubsection{System Calls}

\UlixI{} uses the ``traditional'' approach of an [[int 0x80]] for
entering a system call and [[iret]] for leaving it instead of
the newer [[sysenter]] and [[sysexit]] instructions offered by
modern Intel processors. Here we followed the Linux model, where
earlier implementations also used [[int 0x80]] and 
[[iret]]. Linux versions 2.6 and higher use [[sysenter]]
and [[sysexit]] on Intel machines, see Mauerer's book on the
Linux kernel \cite[pp. 833 ff.]{Mauerer:2008:PLK:1502342}.


\subsubsection{Block Devices}

In order to enable \UlixI{} to access permanent filesystems, code
for accessing block device hardware was needed. After reviewing
a freely available implementation of an ATA disk driver
(mindrvr from \url{http://www.ata-atapi.com}, \cite{mindrvr}, ADD CITATION), 
I decided against supporting hard disks,
because the required communication with the hard disk controller
is so complex that it would have filled too many pages of the documentation
without actually improving the understanding of operating system
concepts. Luckily, talking to a floppy disk drive is a simpler
task, but still it uses the same methods as hard disk access
does: both transfer data via DMA, so in both cases the OS sets up
the transfer and then puts the process to sleep. After completion
of the transfer, a hardware interrupts causes the OS to jump into
the interrupt handler which acknowledges the controller's message
and wakes up the sleeping process. So after reading the code for
floppy disk access, students are led to understand that code for
talking to hard disk controllers would be similar in principle,
just more complex in setting up the control communication between
OS and controller.


\subsection{Remarks on the Implementation Task}

Writing a complete operating system from scratch is a tricky task
because most components interact---so when writing code for one
part of the system it will also require writing code for many other
parts, otherwise the new code cannot be tested. For example the
internal [[fork]] and [[exec]] functions require at least a basic
implementation of the scheduler so that they can be tested.

Because of this it was not possible to focus on one part of the
operating system and complete the implementation of that part
before advancing to a different part. Instead most parts of the
operating system evolved in parallel. Change a data structure here,
and code will break in many other places. This problem could be
partly avoided by using a more modern approach such as the one
used by micro kernels, but that would increase the overall
complexity of the operating system, and the goal for \UlixI{} was
to keep it simple.


\section{Literate Teaching}

See chapter on Literate Teaching.


\section{Evaluation}

Usage in a lecture ...


\section{Multimedia Content}

After finishing the implementation and documentation of \Ulix-i386, 20 hours of
video material were produced and uploaded to \url{youtube.com}. The website
\url{ulixos.org} was designed and created by the author as a platform
for accessing these videos, downloading additional materials and
coursework, and discussing the topics in online forums.

...



\section{Related Work}

Over the decades, the contents of Operating Systems courses have
remained pretty identical. If we compare classical introductory
textbooks from the 1970s with recent books, we can see that they
cover the same topics. Main topics have always been concurrency
(of processes or threads) and the abstractions which operating systems
provide. This is still true today, because the main function of an
OS has not changed.

Looking at technical details, we see that operating systems have become
more complex and more sophisticated, for example modern filesystems
offer journaling, applications are threaded, and new concepts for
scheduling tasks are discussed in the OS research community. But
typically, students will not be introduced to the latest developments,
but instead will only see the most simple example implementations,
since a one or two semesters long course can only cover a restricted
set of topics.

Operating system implementation languages have changed over the decades,
but not much. Since Unix had been implemented in C, this language has
become the standard language for most systems. Some projects use its
object-oriented sibling C++ in order to introduce objects, but mostly
developers still use C. Of all the high level languages, C is the
unique language which allows direct machine access most easily; inline
assembler and direct addressing of memory cells are useful for the
implementation of a program that runs on the raw machine.

Historical operating systems which only allowed batch processing are
still covered by modern books since they laid the foundation for later
systems and serve as examples for simple (cooperative, non-preemptive) 
scheduling strategies.

As an example, look at Per Brinch Hansen's ``An Outline of a Course on
Operating System Principles'', published in 1972 
\cite{Hansen:1972:OS-course-outline}, in which he described progress
on his OS textbook which was published one year later
\cite{brinch-hansen:1973:os-principles}: When discussing synchronisation,
he talks about semaphores, message queues, and monitors---just like most
modern textbooks do.

By the way, Brinch Hansen uses the then-brand-new programming language
Pascal \cite{wirth:1971:pascal} to illustrate the OS algorithms he presents.




\subsection{Teaching Operating Systems}

Over the last decades several operating systems have been implemented
with the sole purpose of being used in operating system classes. So
the common focus of all these systems lies in being simple to grasp,
they all avoid optimizations (which would render the code unreadable),
and most of them lack support for a wide set of hardware components,
since a collection of drivers for similar devices does nothing to improve
a system's usefulness in a course setting.

\subsubsection{Minix}
The most popular related approach is Tanenbaum's Minix operating
system which was published as a book containing OS theory and
the whole source code of Minix \cite{Tanenbaum:1987:OSD}.

\subsubsection{Others...}


\begin{itemize}

\item OOStuBS (``Objektorientiertes Studenten-Betriebssystem'') and
MPStuBS (``Multi"=Pro"-zes"-sor"=Studenten"=Betriebssystem'') \cite{Schweikart:2008:MPStuBS}

\item Xv6, a simple Unix-like teaching operating system
\url{http://pdos.csail.mit.edu/6.828/xv6/}
Xv6 is a teaching operating system developed in the summer of 2006 for MIT's operating systems course

\item Topsy (Teachable Operating System) was developed at ETH Zurich
\cite{Fankhauser:1996:Topsy}, the original version runs on the MIPS architecture.
Later it was ported to Intel i386 \cite{Ruf:1998:Topsy-i386} and to the
Pentium 4 \cite{Ryffel:2007:Topsy-P4} by students of the same university.

\item Off++ \cite{Ballesteros:1997:Off} -- literate programming / kernel

\end{itemize}




\subsection{Simple Unix Implementations}

Thix \cite{Hulubei:1995:Thix} is an almost POSIX-1-compatible
Unix implementation.


\subsection{Literate Programs}

While there are many (small and large) programs which were implemented 
with Literate Programming, not many of them are intended for teaching a
specific topic. However, there are exceptions:

\begin{itemize}

\item Donald E.{} Knuth implemented \TeX{} using Literate Programming
and published the \TeX{} code in a book \cite{Knuth:1986:TTP}.

\item David R. Hanson:
C Interfaces and Implementations: Techniques for Creating Reusable Software, 1997,
ISBN: 0-201-49841-3 \cite{Hanson:1997:C-Interfaces}

\item ``Physically Based Rendering: From Theory to Implementation'', Matt Pharr and Greg Humphreys. 2004; 2010

\item ``Algorithms on trees and graphs'', Gabriel Valiente; 
Ort: Berlin [u.a.]
Verlag: Springer
ISBN: 3-540-43550-6
Jahr: 2002

\item ``A Retargetable C Compiler: Design and Implementation'', Christopher Fraser and David Hanson, 1995

\item ``Understanding MP3'', Martin Ruckert, 2005



\end{itemize}



\section{Summary}



\chapter{Literately Programming an Operating System}




%------------------------------------------------------------------------------

\chapter{Literate Teaching}
\label{chap:lippgen}

\begin{work}
Find a better name...?
\end{work}

\section{Introduction}

Using Literate Programming as a teaching tool produces a book which nicely
combines theory and code. If a student were to teach himself a topic such as
the theory of operating systems, then this approach is fully sufficient: The
\UlixI{} book, as it was created and is presented in part B of this thesis,
serves as an example.

However, for regular lectures in a class a book is not of immediate use,
unless some kind of ``reverse classroom'' or ``flip teaching''\footnote{see
\url{http://en.wikipedia.org/wiki/Flip_teaching}} is used for
the course, where students are asked to read the book as coursework which
frees class time with the instructor for the discussion of problems, practical
assignments, etc.

\begin{definition}[Literate Teaching]
We define \textbf{Literate Teaching} as any method of lecturing which combines
the presentation of theory and supporting code fragments in a Literate
Programming style.
\end{definition}

The question we wanted to answer was: how can this be done in a practical
way? Just displaying pages from the book was discarded as an option since
the book is formatted for reading and not for displaying during a course.


\section{Conversion of a Literate Program into a Lecture Presentation}

The idea was to start with a literate program (such as the \UlixI{}
implementation) and convert this into a presentation. The process should
be aided by software---it cannot be fully automatic since it is necessary
to pick parts of code chunks to be displayed and to add bullet points or
other contents to be displayed beside the code.

We use a browser-based approach \cite{Esser:2013:Lippgen}. 
First, the Literate \TeX{} source file
is converted to HTML by a Python program. It separates the documentation 
from code chunks and displays them in two columns. The tool also removes
a lot of \LaTeX{} code so that the HTML version is well-readable.

When showing a code chunk, the other column contains a text entry field
which is a {\tt textarea} element made into a proper editor field using
NicEdit\footnote{\url{http://nicedit.com}}, a JavaScript / AJAX inline
content editor. The input boxes allow  
entering the information that shall be displayed when giving a lecture. 
A web server is needed to receive the information entered into these text 
boxes.

Thus while viewing the HTML file, all information is available.

In the next step, the information provided via the input boxes and
the code chunks are assembled into an HTML file that can be used for
presentation during a lecture. The HTML is based on S5, the Simple 
Standards-based Slide Show 
System,\footnote{\url{http://meyerweb.com/eric/tools/s5/}} which we have 
slightly modified to allow for a two-column display where the second
column (the code column) is scrollable.

We will describe both steps in the following sections.


\subsection{S5}

Modify \path!Literatur/s5/ui/default/pretty.css!, add \verb#td.literate#
definition.

\section{Process for the Instructor}

The process for the instructor is as follows:

\begin{enumerate}
\item Check if the pre-configured port 12349 of [[lippgen]] is free on
your machine---if not, change it to something else in the line
[[PORT = 12349]]. Modify the command which opens a URL in a web browser;
it is currently set to 
{\small\begin{verbatim}
BROWSER_COMMAND = "open %s -a \"Google Chrome\""
\end{verbatim}}
which works on a Mac with Google Chrome installed. For Firefox on a Linux 
machine the proper command would be
{\small\begin{verbatim}
BROWSER_COMMAND = "firefox -new-tab %s"
\end{verbatim}}

\item Mark the relevant part(s) of the Literate Programming source file by 
inserting two lines

{\small\begin{verbatim}%%% BEGIN LITERATE TEACHING %%%
\end{verbatim}}

and

{\small\begin{verbatim}%%% END LITERATE TEACHING %%%
\end{verbatim}}

(without any leading spaces) around each part that is to be included in the slides.

\item Run [[./lippgen]] on the file, e.\,g. by issuing the command
[[./lippgen example.nw]]; this produces a file [[example.form.html]] and
opens it in the preconfigured browser.

\item In the browser, fill in the text input boxes
next to the code chunks; input boxes can be left empty. Click \emph{Submit}
at the end of the page.

\item Submitting will transfer the input boxes' contents to the program's
built-in server, where the processing continues. Your entries in the fields
will also be saved in [[example.lip]] so that it will be reused if you run
[[lippgen]] on the same file again (the input boxes will already be filled
with the entries from the last time). This step creates the final 
presentation file [[example.html]] and opens it in the browser.

\item Check the resulting slides and make changes if necessary (going back
to step 3). 

\item If needed, insert text-only slides in [[example.html]], run
[[lippgen-sanitize]] on the [[example.html]] file (which renumbers the
slides) and give the lecture.

\end{enumerate}

\section{An Example: Filesystems}

<<lp s5 pretty.css>>=
div.literate { overflow: scroll; white-space: wrap; font-size: 0.6em; max-height: 
  25em; margin-top: 0.7em; border-left: 1px; border-left-width:2px; 
  border-left-style:solid;border-left-color:#ff0000; padding-left: 1em; 
  padding-right: 0em; border-right-width: 0em; margin-left: 1em;}
table { border-right: 0em; border-right-width: 0em; padding-right: 0em; }
tr { border-right: 0em; border-right-width: 0em; padding-right: 0em; }

::-webkit-scrollbar {
    width: 0.5em;
    height: 0em;
}

::-webkit-scrollbar-track {
    -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3);
    border-radius: 10px;
}

::-webkit-scrollbar-thumb {
    border-radius: 10px;
    -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.5);
}
@


\section{Supervised Theses}

During my research on \UlixI{} I have supervised three Bachelor theses whose
results have been incorporated into \UlixI{}:

\begin{itemize}
\item Markus Felsner: \emph{Implementation eines Schedulers für das Betriebssystem ULIX} (Implementation of a Scheduler for the ULIX Operating System), Hochschule für Oekonomie und Management (FOM), WS 2012/13 \cite{Felsner:2013:Bachelor}
\item Liviu Beraru: \emph{Implementation eines Dateisystems und einer RAM-Disk für das Betriebssystem ULIX} (Implementation of a Filesystem and a RAM Disk for the ULIX Operating System), Ohm-Hochschule Nürnberg, WS 2012/13 \cite{Beraru:2013:Bachelor}
\item Frank Kohlmann: \emph{\foreignlanguage{ngerman}{Implementierung eines ELF-Programm-Loaders für das ULIX"=Betriebssystem}} (Implementation of an ELF Program Loader for the ULIX Operating System), Ohm-Hochschule Nürnberg, WS 2012/13 \cite{Kohlmann:2013:Bachelor}
\end{itemize}


\subsection{Evaluation of the Literate Programming Process}

\begin{work}
TODO: Questionnaire, ask students how they liked the LP process
\end{work}




\section{Summary}





%------------------------------------------------------------------------------


\chapter{Evaluation}

In the winter term 2013/14 I gave a lecture at Nuremberg Technical University
(Technische Hochschule Nürnberg) called ``Operating System Development with
Literate Programming'' where I used the book in part \ref{part:ulixbook} of 
this thesis as
foundation and lecture slides derived from this book with the LiPPGen
presentation generator (as described in chapter \ref{chap:lippgen}).

This was done in order to evaluate whether using my approach leads to a
better understanding of operating system concepts.

The course was an elective as part of a bachelor's degree program in
computer science, and participants had already finished a classical course
on operating systems theory (required in the program).

Overall, NN students took the course which was held between October 2013 and
January 2014.


\section{Expected pre-existing Knowledge}

All participants also took the course ``Operating Systems'' in
the term NN. This course covered the following topics:

\begin{work}
Enter course contents; find out in which term people took it. Enter a
question in the pre-test about this (``When did you take the OS course?'')
\end{work}

\begin{itemize}
\item ...
\end{itemize}


\section{Pre-testing}

In order to establish the previously available knowledge and understanding
of operating system fundamentals. I developed a multiple-choice test which
focused on topics that I was going to discuss during my course. The test
consisted of NN questions, shown in table NN.

\begin{work}
TODO: Comparison group: Pick other students who are not participating in my
course and have them complete pre- and post-test as well!

The argument for having a comparison group is that by continuing their
studies, students who did not take my course could also gain improved 
understanding of OS concepts, and I want to compare this improvement to
the improvement which my course caused.
\end{work}

\section{Post-testing}

At the end of the term, the initial test was repeated, with exactly the
same questions as in the pre-test. Figure NN shows how the results changed.


\section{Discussion}

The changes between pre-testing and post-testing show an improvement of
understanding ......

In comparison, the second group of students .....

This leads to .....



%------------------------------------------------------------------------------




\chapter{Conclusion}

\comment{Zusammenfassung ``kurz und knackig'' :)}

The research goals that have led to this thesis were the design, implementation,
and evaluation of a Unix-like operating system, implemented with Literate
Programming. All of these goals have been reached:

\begin{itemize}
\item \UlixI{} is a feature-complete Unix-like operating system with virtual
memory management, processes and threads, several schedulers, a virtual
filesystem with two supported filesystems (Minix and FAT) and support for
floppy disks and RAM disks, as well as a collection of system calls.
In addition, a standard library exists which provides several standard
functions which are known from other Unix-like systems. A few example
programs have also been developed (or ported to \UlixI{}), though they are 
not part of this thesis. All of this was done using Literate Programming.
\item The source of \UlixI{}, combined with the theoretical chapters on
OS principles, forms an introductory textbook (``The Design and Implementation
of the \UlixI{} Operating System'') which is currently available on the
\UlixI{} website for other instructors and students to be used in OS
classes.
\item Using \UlixI{} in an OS course was successfully tested, and the
evaluation has shown that ...  The development of LiPPGen, the 
Literate-Programming-based Presentation Generator, was a required task
to make the easy transformation of (parts of) the literate program
into active, scrollable lecture slides possible.
\item The bachelor and master theses written by N students have shown
that the implementation of \UlixI{} components using Literate Programming
is possible and poses an interesting task. In questionnaries, the students
mentioned that they found Literate Programming helpful ... (??)
\end{itemize}

Overall, this work provides the community of OS instructors with a new
method of teaching OS principles, and it delivers both an argument for
using this approach and the necessary tools, since all created materials,
including the book, the \UlixI{} source code, and the lecture slides
have been released under an Open Source license.






%------------------------------------------------------------------------------
%##############################################################################
%------------------------------------------------------------------------------







\part[\Ulix-i386 Design and Implementation]{Design and Implementation of the \textsc{Ulix-i386} Operating System \\[1cm]
  % \includegraphics[width=9cm,trim=1cm 24cm 8cm 6cm]{pics/ULIX-Logo.pdf} \\[2.5cm]
  \includegraphics[width=6cm]{pics/ULIX-Logo3.png}\\[1.5cm]
 \quad \Large{Hans-Georg Eßer, {\green Felix Freiling}\footnote{
  \textbf{Citations in this part of the thesis:} Since this part contains 
  large portions of code and documentation
  written by Felix Freiling, the following coloring convention is used
  to display citations: Text and code \green \textbf{colored green} \black was
  copied verbatim or with small modifications from Felix Freiling's
  unpublished \Ulix{} text \cite{freiling:ulix}. The intention is to make it
  obvious which parts were written by whom.
  This part is also
  available as a separate book by Felix Freiling and the author 
  \cite{EsserFreiling:2012:ULIX} in which
  the color convention is not used.
}
}}
\label{part:ulixbook}

%\appendix





% Anhang mit Kapitel U ("U"lix) anfangen
%\setcounter{chapter}{20}
%\setcounter{chapter}{0}


\renewcommand{\ptifont}{\huge\bfseries\sffamily}
\mtcsetdepth{parttoc}{4}   % for part II TOC
\parttoc



\chapter{Introduction}

%+FELIX
\green
Operating systems are an important part of computing. They mediate between the complex intricacies of modern hardware and the abstract needs of users and applications. Operating systems are one of the oldest research areas in computer science too. Moreover, the topic is one of the core subjects in academic computer science curricula. So there are many books and other teaching resources available.

Because of the wealth of material and the practical appeal of the topic, operating systems are a fun subject to teach which also makes it mostly an enjoyable course for students. As a regular instructor of one of these courses I have learned that one of the key aspects of a good operating systems course is to discuss and analyze real operating systems, i.\,e., operating systems that work in practice and can (potentially) be used by people. To this end, open source operating systems such as FreeBSD and Linux have established themselves as good objects of study because they have commercial value and their source code can be accessed and scrutinized by lecturers and students in course.

Unfortunately, it is hard to use the source code of real operating systems directly and extensively in class. This is because of many reasons. One main reason is the complexity of real operating systems code. Operating systems naturally have to deal with details of the underlying hardware. If an operating system is designed to be portable, then the source code must cater for multiple computer architectures, which makes it even more complex. Furthermore, modern operating systems usually offer an increasing number of features which must all be expressed by code. Another reason for the complexity of operating systems code is that practical operating systems must be extremely efficient. Every instruction cycle and memory cell used by the operating system cannot be used by the applications and their users. That is why operating systems code is often highly optimized. There are many other reasons that prevent instructors from showing real source code in class.

In our view the most important reason for not using real code directly in class is that operating systems have not been written with a human reader in mind, especially non-expert readers like students of operating systems classes who want to learn the basics of the area.



\section{Related Work}

\begin{work}
  List needs to be extended:
\end{work}
%
\begin{itemize}
\item FreeBSD book \cite{McKusick:2005:DIF}: code mixed with explanations and
  figures, but the code is only pseudocode, not executable
\item Lions commentary: Just source code with comments \cite{Lions:1996:LCU}
\item Bach's book: similar to FreeBSD book, no real code \cite{Bach:1986:DUO}
\item NachOS system \cite{nachos:paper,nachos:code} developed in Berkeley,
  now supported at University of Washington.
\item NachOS in Java system \cite{nachos:java} now used in Berkeley.
\item PintOS used for teaching at Stanford \cite{pintos,pintos:code}.
\item Emulator used for the operating systems class at University of
  Oldenburg (Prof.~Oliver Theel) as well as TU Darmstadt (Dr.~Wolfgang
  Heenes)
\item L4 Kernel (Karlsruhe, Dresden)
\item Dikstra's THE operating system \cite{Dijkstra:1968:SMS}
\item Microsoft Singularity \cite{Hunt:2007:SRS,Singularity:homepage}
\end{itemize}

In our view, the two most positive examples of operating system exposition
for students are the well-known \vindex{Minix operating system} and
the less well-known \vindex{Xinu operating system}. Minix was
originally written by Andrew Tanenbaum \cite{Tanenbaum:1987:OSD} to
serve as a minimal working example for teaching his operating systems
course at the Free University of Amsterdam.  In its most advanced form
(Minix3), Minix is still well-structured, simple and very well
documented \cite{Tanenbaum:2006:OSD}. However, it too has evolved into
a commercially relevant system with all advantages and
disadvantages. Allthough the Minix book \cite{Tanenbaum:2006:OSD}
contains the entire source code of the operating system, it lives a
separate life being relegated to an appendix that essentially fills
the second half of the book.

The Xinu system was written by Douglas Comer \cite{Comer:1984:XINU}
for the DEC LSI 11/2 microcomputer (a successor of the famous PDP 11
minicomputer for which UNIX was initially written). Unlike Tanenbaum,
Comer never published a revision of the Xinu book
\cite{Comer:1984:XINU} so concepts like virtual memory were never
added. Somewhat fortunately however, Xinu therefore did not suffer
from its success in the way Minix did. While Minix is highly optimized
and embedded in an extensive textbook on operating systems, Xinu
remained simplistic, its code forming the strong skeleton of the Xinu
book \cite{Comer:1984:XINU}.


\section{Literate Programming}
\label{sec:exposition}

When we write software, do we really think about a human reader?  The
harder we try, the more we feel constrained by the programming tools
available. When writing a complex piece of code, wouldn't you
sometimes like to include a figure into the code to explain the
complex interactions of variables? Or when you implement an algorithm
from a textbook, wouldn't you like to give an automatic reference to
this book in the source code? Or when one part of the code is similar
to another part because you used the same idea, wouldn't you like to
use automatic cross-referencing between these two parts?  And aren't
you bored of writing all these comment signs (like \texttt{//} in C or
Java) all the time (or worse, aligning the stars when using
\texttt{/*} and \texttt{*/})? If you have ever felt such a desire, you
are ready for \vindex{literate programming}.

Literate programming is a programming technique originally developed
by Knuth\pindex{Knuth, Donald E.} to write the
\TeX{}\pcindex{TeX}{\TeX{}} typesetting system. The source code of
\TeX{} appeared 1986 as a book called ``\TeX\ - the program''
\cite{Knuth:1986:TTP}. Reading this book is an entirely different
experience from reading ``normal'' source code.  It contains the
\emph{entire} source code, not just important excepts, and it is
\emph{real} executable code that was originally compiled into
the executable typesetter.

\begin{work}
  More on literate programming \cite{Knuth:1984:LP}.
\end{work}

Following the idea of literate programming, this program  will be a
book for students. The source (this document) can be used to generate
executable code \emph{and} a \LaTeX{} file that can be typeset to an
introductory text on operating systems. If Andrew Tanenbaum would
have known about literate programming, maybe Minix would have been
written using this technique.


\section{The Name of the Game}

The name \Ulix{} is intentionally similar to the name Unix. This is meant
to imply that the code is influenced a lot by things we have seen in
Unix/Linux style operating systems. The focus on Unix is solely based
in the past experiences of the authors, it is in no way intented to
imply that Unix is better or worse than other operating systems.

The choice of the letter ``l'' in \Ulix{} is supposed to concisely
express that the system is meant for \emph{learning} and teaching
operating systems. Besides, the name \Ulix{} is one of the few
four-letter abbreviations that do not seem to have been chosen for
other software systems yet. Furthermore, \Ulix{} is probably the first
operating system that is written as a literate program, and so
\Ulix{} can also stand for ``literate Unix''.



\section{Tools}
\label{sec:tools}

The original goal was to write a book like ``\TeX{} -- The Program''
\cite{Knuth:1986:TTP} with prettyprinted sourcecode and extensive
automatic cross-references and indexes (especially the famous
\vindex{mini indexes} on right-hand pages).  This can be achieved
using the Knuth/Levy \vindex{CWEB} documentation tool
\cite{cweb:homepage,cweb:2001} that also has hypertext extensions.
Mini indexes can be generated by an extension called \vindex{CTWILL}
\cite{Knuth:1993:MIF} that is the program used to generate the source
of ``\TeX{} -- The Program'' \cite{Knuth:1986:TTP}. However, the CWEB
family of tools is restricted to \TeX{} as typesetting language which
we wanted to avoid in favour of \LaTeX{}.  Allthough there exists an
experimental adaption of CWEB for \LaTeX{} by Joachim
Schrod\pindex{Schrod, Joachim} \cite{cweb-latex}, CWEB is also
restricted to the \vindex{C programming language}, so different
languages like the experimental \Ulix{} assembler or configuration
files cannot be handled.

\begin{work}
  Explain \vindex{noweb} \cite{Ramsey:1994:noweb} and its features: allows to
  combine \LaTeX{} with any other language. Is actively used and
  supported, has many extensions for prettyprinting and indexing.
\end{work}


\section{Design Principles of \Ulix{} and Disclaimer}
\label{sec:design:principles}

The following principles determine the design of \Ulix{}:
%
\begin{itemize}

\item \Ulix{} is for \emph{learning and teaching} principles of
  operating systems in a course. \Ulix{} should never be a practical
  system in the sense that it can be used to run real applications.

\item Nevertheless, \Ulix{} should be a \emph{real} operating system,
  i.e., the code should be executable on some well-defined computer
  architecture. If necessary, it should be possible to port \Ulix{} to
  other platforms, but portability is not a core requirement of
  \Ulix{}.

\item The design and implementation \Ulix{} should be governed by the
  principle of \emph{simplicity}, avoiding optimizations, focussing on
  understandble and correct code.

\item It should be possible to use the source code \emph{directly} in
  class. The source code should be written with the human reader in
  mind.

\end{itemize}

\begin{work}
  We will see at the end of the project whether this worked out.
\end{work}

\Ulix{} will be written in C. The choice of C is subjective and could
have been made differently. But since most operating systems are
written in C and C offers a good set of tools it seems a good choice.

The principle of simplicity demands that we use ``clear C'', i.e., we
discipline ourselves to non-optimized and clear code that can also be
understood by people familiar with Java. We also restrict inclusion of
library header files (we want to be self contained).  Use of pointer
arithmetic should be avoided. Pointers should be used in a way object
references are used in Java.

Given the above design principles, one point should be clear --- but
important enough to mention it anyway: While trying to be \emph{real},
\Ulix{} is not \emph{practical}, i.e., we disclaim any fitness for
practical use. On the one hand, the code is not guaranteed to be free
of programming errors. On the other hand, the performance of \Ulix{}
is such that it will not achieve any required quality of service in
practice. \Ulix{} is \emph{purely} for learning. The path chosen is
the one of simplicity. So when you have read this book, you will have
a fairly good idea of how \Ulix{} works but still you have only a
faint idea of how operating systems work in general. Therefore, this
book is (and never will be) a replacement for the excellent general
textbooks on operating systems available.


\section{Executing \Ulix{}}

Using a literate programming tool, from the source file (this
document) we extract a C file of the \Ulix{} kernel. Then we compile
this file into code that is directly executable \black on standard
PC hardware (provided it has a floppy disk drive) or on emulators
or virtual machine software, such as [[qemu]], Bochs, VirtualBox or
VMware.
\green



\section{Copying}
\label{sec:copying}

\Ulix{} naturally is open source software. You can copy and browse the
code, compile it into any form you like. If you find bugs in the
source code, please drop me a message so that I can fix the bug in the
next iteration of the software. Similar to \TeX{}, \Ulix{} is meant to
eventually become a stable platform that does not evolve anymore,
i.e., I will eventually stop issuing new releases. That's why I retain
the entire copyright that must be mentioned in all files associated
with the system. If you think that \Ulix{} should be fundamentally
changed, become more efficient etc., you can take the code but should
call the resulting system something else than \Ulix{}.

<<copyright notice>>=
(c) 2008-2013 Felix Freiling, University of Erlangen-Nürnberg, Germany
(c) 2011-2013 Hans-Georg Eßer, University of Erlangen-Nürnberg, Germany
@

\section{Notation}

\begin{work}
  explain hex notation of [[0xffff]] for addresses and large constants.
\end{work}


\section{Outlook}

Literate programming allows to structure the code in a way that best
suits understanding. That is why we can present the concepts in a
sequence of chapters roughly following the exposition I use in my
lecture (which is based on the sequence in the German book on
operating systems by Nehmer and Sturm \cite{Nehmer:1998:SGM}).

\begin{work}
  Refer to concrete chapters finally.
\end{work}
%
\begin{enumerate}
\item Introduction: What is an operating system? Design principles and
  choices?
\item Virtual memory.
\item Threads.
\item Synchronization: Hardware, Semaphors, Monitors.
\item Concurrent programming.
\end{enumerate}

\begin{work}
  Maybe in the final version we'll have some some exercises per
  chapter. These exercises will have solutions in the book too. These
  solutions may contain code that is necessary to run \Ulix{}. This
  means that students can be required to program parts of \Ulix{}
  themselves.
\end{work}

Every software project contains code that is not very interesting. So
allthough this document contains the entire source code of \Ulix{},
some parts of it might be less pleasant to read than others,
especially if you are only interested in the principles of the
implementation. I have tried to separate those parts of the code from
the more vital and central parts in special sections, that we call
\emph{\vindex{code sections}}.  These sections are marked by a special
\codesymbol{} symbol and can be skipped at first reading.

\red
\begin{work}
REVIEW: Which sections are starred code sections? Mark only the less
important sections with stars!
\end{work}


\black
%-FELIX
























\chapter{Creating an Operating System From Scratch}

What would you first think of when attempting to create a new
operating system (OS)? We asked this question in an introductory
course teaching operating system principles and---most 
often---received the following answers:

\begin{itemize}
\item What kind of applications will it be able to run?

\item What kind of hardware will it work on?

\item What language should we use for coding?
\end{itemize}

\comment{DIESE UMFRAGE WIRKLICH DURCHFÜHREN, INHALT KORRIGIEREN}

All of these are further questions to which we'll provide some
answers in this introductory chapter. A short and combined 
response could go like this:

If you expect to create an OS using Java that will be compatible
with Windows, Linux, and Mac OS and will also sport a high
performance 3D engine so that the latest console games run on
it, then this textbook will be pretty disappointing.

Let's look at the questions in more detail.


\section{Language of choice}

Operating systems are very close to the actual hardware.
In fact you won't see any other class of ``programs'' which
get any closer to the hardware, because there's always the
OS as a natural barrier between hard- and software. We're
in the area of systems programming, and this is where
``old school'' languages still dominate. So with most
operating systems you'll see lots of C code. For those who
have never heard of C (without a $++$ postfix): C is a
procedural language that was created in 1969--1973 by
Dennis Ritchie\footnote{
  Ritchie reviewed the early history of C in an
  article \cite{Ritchie:1993:DCL:154766.155580}.
}
and it's a predecessor to C$++$, Java, and C Sharp. It does not
know objects.\footnote{
  For those readers unfamiliar with C, we have included a
  short introduction to C which requires C++ knowledge,
  see chapter \ref{chap:intro-to-c}.
}

Even closer to the hardware is assembler code, and for that
reason all the early operating systems were programmed in
assembler. Assembler code is what a C compiler will generate
when you provide it some C source code. Today it is no longer
necessary to write complete operating systems in 
assembler\footnote{although some people still do this, e.\,g.
((REF: 64-bit-OS in assembler, BareMetal,
\url{http://code.google.com/p/baremetal/wiki/BareMetal} ))},
but you'll still need some assembler code from time to time,
because some parts of the OS need to access CPU registers
more directly than others.

For the Intel processor platform, two ``dialects'' exist, the
Intel and the AT\&T one. The GNU C compiler supports both but
defaults to the AT\&T variant. We have decided to use the
Intel syntax, because it is close to C syntax: For example,
you can load the [[EAX]] register with the value 0 via the
command [[mov eax, 0]] (in Intel syntax). So the target of
the [[mov]] command comes first which resembles the C command
[[eax = 0]]. In AT\&T syntax, the operands
are reversed, with the target coming last and extra
syntactical elements being needed ([[mov $0, %eax]]).


\section{Selection of target hardware}

The computing world is diverse, allowing for all sorts of
hardware architectures. CPUs can have very different
features---if you have attended a course on computer
architectures, you will have noted things like RISC and CISC
CPUs with very small and simple or huge and complicated
instruction sets. In this book we will focus on the 32 bit Intel
architecture, for the simple reason that most people have
quick access to an Intel-compatible machine or can at least
run an Intel-based operating system in an emulator.

However, Intel hardware has some legacy problems because even
the latest Intel chips are compatible with old systems from
last century's 80s. We will try to ignore most problems which
arise because of this legacy. Where we cannot avoid it, we
will present code with pretty short explanations, and a deeper
understanding will not be expected.\footnote{However, for
those interested, we'll provide links to other texts which give
more detailed descriptions.}


\section{Applications}

A reasonable statement is the following: An operating system X
will run applications which have been developed for X (let's
call them X applications), and it will be either impossible or
very hard to run Y applications for any Y which is not X.
Every OS creates its own software universe, and if you want to
run a program from a parallel universe, you'll need some sort
of emulation---which is not a topic of this book.

Most applications require libraries which are typically considered
part of the operating system. Even for something as simple as 
printing ``Hello world'', you need a library that contains the
code which is necessary to make the OS print something (in a
text console, a window, or perhaps on a printer).

In this book we will develop an operating system that allows input
and output of text via system calls.\footnote{No, there will be
no graphical user interface.}


\section{What's in the book?}

Reading this book, you will see introductory descriptions of
several theoretical concepts, and at the same time you'll see
the complete source code necessary to implement these concepts.
Topics we will cover are:

\begin{itemize}
\item processes and threads (chapter \ref{chap:ulix:processes})

\item interrupts (chapter \ref{chap:ulix:interrupts})

\item memory management (chapter \ref{chap:ulix:mm})

\item scheduling (chapter \ref{chap:ulix:scheduling})

\item filesystems (chapter \ref{chap:ulix:fs})

\item synchronization (chapter \ref{chap:ulix:sync})

\item signals (chapter \ref{chap:ulix:signals})
\end{itemize}

If you \index{copy} copy all the code from the book into appropriate files
(or download the version we provide on the website) you can
compile it into an operating system that will actually boot
on your standard computer or within an emulator or virtualization
program.

We'll set the OS name and version now:
<<macro definitions>>=
#define UNAME "Ulix-i386 0.08_h"
#define BUILDDATE "SCRIPTBUILDDATE"
@

<<kernel declarations>>=
/*
v0.01  2011/06     first version, boots, enables interrupts, keyboard handler,
                   protected mode, most code taken from kernel tutorials
v0.02  2011/07/31  paging for the kernel (not yet for user space)
v0.03  2011/08/12  paging with Higher Half Kernel / GDT trick (preparation for
                   user space)
v0.04  2011/08/17  dynamic memory allocation: request frame, request new page
                   (with update of page table; creations of new page table if
                   last used one is full) 
v0.05  2012/10/02  serial hard disk and external storage server (for use with
                   qemu & co.)
v0.07  2013/04/05  Scheduling and fork / exec / exit / waitpid are working.
v0.08  2013/07/13  Minix Filesystem support (replaces "simplefs"). Can read,
                   write, create files. No sub-directories. 
                   Kernel uses floppy (FDC controller) instead of serial disk
                   Terminal support (up to ten terminals with shells)
*/
@

\noindent
Welcome to \UlixI{} 0.08!


\chapter{Layout of the Kernel Code}

We will now present the overall layout of the \Ulix{} kernel code.
Basically every kernel has to do some essential setup (such as
initializing RAM and other components of the machine), then
activate interrupts and the process system, create a first (init) 
process, and finally enter an infinite loop.

There will be many declarations of data structures used inside
the kernel (we will put them all in the code section called
[[<<kernel declarations>>]] and lots of functions which work with
these data (in [[<<kernel functions>>]]).

So this is the basic structure, with most of the code being in just
one C file, [[ulix.c]]:

\begin{work}
GET RID OF [[ulix.h]] HEADER FILE
\end{work}

<<ulix.c>>=
#include "ulix.h"

/* <<copyright notice>> */
<<macro definitions>>
<<kernel typedefs>>
<<kernel declarations>>
<<kernel global variables>>
<<kernel functions>>
<<kernel mode shell>>
<<kernel main>>
@


\section{Assembler code}

Since we will occasionally have to use assembler statements and the 
standard command in the C GNU compiler is [[__asm__]], we define
a shorthand:

<<macro definitions>>=
#define asm __asm__
@

We have created an assembler pre-processor which replaces code that has the form
of the left side with code that looks like the right side:

{\small\begin{verbatim}
asm {                                          |    asm (".intel_syntax noprefix; \
  starta: mov eax, 0x1001   // comment         |      starta: mov eax, 0x1001; \
  mov ebx, 'A'              // more comment    |      mov ebx, 'A'; \
  int 0x80                                     |      int 0x80; \
}                                              |      .att_syntax; ");
\end{verbatim}}

This allows usage of the Intel assembler syntax (without changing the normal compilation
process which uses AT\&T syntax), it also enables us to add comments in the code, and
the new syntax is closer to C.

The pre-processor also understands [[asm volatile]]. What it cannot cope with is variable / register usage; thus, occasionally there will be appearances of the less readable standard assembler syntax.

Note that it does not change the number or position of code lines.

\begin{work}
TODO: Make this code literate. \\
Maybe: move it to the appendix
\end{work}

<<assembler-parser.py>>=
#!/usr/bin/python

from sys import argv, exit

if len(argv)<3:
  print ("Error: give input and output filenames")
  exit (1)
infilename = argv[1]
outfilename = argv[2]

global ReplaceMode
ReplaceMode = False

def count_leading_blanks (line):
  counter = 0
  while line and (line[0] == " "):
    counter+=1
    line = line[1:]
  return counter

def remove_trailing_blanks (line):
  if (line == ""): return line
  while (line != "") and (line[-1] == " "):
    line = line[:-1]
  return line
  
def transform (line):
  global ReplaceMode
  if ReplaceMode:
    if "}" in line:
      # reached the end; skip this line
      blanks = count_leading_blanks (line)
      line = (blanks+2) * " " + '.att_syntax; ");'
      ReplaceMode = False
      return line
    else:  
      # do something to the line
      if '//' in line:
        # remove comment
        pos = line.find ("//")
        line = line[:pos]
        line = remove_trailing_blanks (line)
      line = line + "; \\"
      return line

def process (line):
  global ReplaceMode
  line = line[:-1]
  if ReplaceMode:
    # we're already in ReplaceMode, working on assembler
    line = transform (line)
  else:
    # we're in normal C mode, check for asm {
    if ("asm volatile{" in line) or ("asm volatile {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm volatile (".intel_syntax noprefix; \\'
      ReplaceMode = True
    elif ("asm{" in line) or ("asm {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm (".intel_syntax noprefix; \\'
      ReplaceMode = True
  return line

infile  = file (infilename,  "r")
outfile = file (outfilename, "w");

EndOfLoop = False

for line in infile:
  # line = infile.readline()[:-1]
  # if (not line): EndOfLoop = True   # end loop
  line = process (line)
  outfile.write (line+"\n")

infile.close()
outfile.close()
@


\section{Debugging support}

We're going to use an [[assert]] macro for debugging:

<<macro definitions>>=
#define assert(e)  \
    ((void) ((e) ? 0 : __assert (#e, __FILE__, __LINE__), abort() ))
#define __assert(e, file, line) \
    ((void)printf ("%s:%u: failed assertion `%s'\n", file, line, e))
void abort() {
  asm ("cli; hlt");
  // for (;;); 
  // asm ("jmp simple_shell");
};
@





\section{The [[main()]] function}

This is the main function of the kernel:

\begin{work}
TODO: clean-up this code
\end{work}

<<kernel main>>=
int main(void *mboot_ptr, uint initial_stack) {

  <<initialize kernel global variables>>
  <<setup serial port>>  // for debugging
  <<setup serial hard disk>>  // we don't want to deal with IDE/FD stuff
  <<setup identity mapping for kernel>>
  <<enable paging for the kernel>>
  gdt_install();
  init_video(); cls();
  printf("%s                           Build: %s\n", 
    UNAME, BUILDDATE); 

  <<initialize system>>
  <<initialize syscalls>>
  fdc_init();
  initialize_module();  // external code
  set_statusline (UNAME);
  debug_printf ("initial_stack = 0x%x\n", initial_stack);
  
  <<start shell>>
  printf ("Executing hlt. Good bye :) ");
  asm ("hlt");
}
@

<<kernel declarations>>=
extern void initialize_module ();
@

\red
<<initialize system>>=
idt_install();
isrs_install();
irq_install();
timer_install();
keyboard_install();

__asm__ __volatile__ ("sti");
@


\black


\begin{work}
TODO: Move the following stuff elsewhere
\end{work}

We'll add a function that prints the values of control registers
0 and 3 (CR1, CR3) since we will often need them:

<<kernel functions>>=
void print_cr0_cr3() {
  uint cr;
  __asm__ __volatile__("mov %%cr0, %0": "=r"(cr));
  kputs("cr0: "); printbits(cr); kputs ("\n");
  __asm__ __volatile__("mov %%cr3, %0": "=r"(cr));
  kputs("cr3: "); printbits(cr); kputs ("\n");
  return;
}
@

<<start shell>>=
kputs("Starting five shells on tty0..tty4. Type exit to quit.\n\n");
// simple_shell();
system_kbd_pos = 0;
system_kbd_lastread = -1;
system_kbd_count = 0;
int i; for (i=0; i<10; i++) terminals[i].kbd_lastread = -1;

// start user mode shell
asm ("sti");
run_command ("exec");
kputs("Shell terminated.\n");
@





% --------------------------------------------------------------------------------





\chapter{Interrupts}
\label{chap:ulix:interrupts}%

Interrupt handling: more detailed!!!


\codesection{Implementation of Interrupts in \Ulix{}}




\subsection{Using Ports for I/O Requests}

\red

The following code was taken from
\url{http://www.osdever.net/tutorials/view/brans-kernel-development-tutorial}
(e.g. from [[irq.c]]) and modified.

<<interrupt code>>=
unsigned char inportb (unsigned short _port) {
    unsigned char rv;
    __asm__ __volatile__ ("inb %1, %0" : "=a" (rv) : "dN" (_port));
    return rv;
}

unsigned short inportw (unsigned short _port) {
    unsigned short rv;
    __asm__ __volatile__ ("inw %w1, %w0" : "=a" (rv) : "Nd" (_port));
    return(rv);
}

void outportb (unsigned short _port, unsigned char _data) {
    __asm__ __volatile__ ("outb %1, %0" : : "dN" (_port), "a" (_data));
}

void outportw (unsigned short _port, unsigned short _data) {
    __asm__ __volatile__ ("outw %w0, %w1" : : "a" (_data), "Nd" (_port));
}
@
\black



\subsection{Interrupt Handlers}

Intel processors expect 

\red
<<interrupt declarations>>=
/* Defines an IDT entry */
struct idt_entry
{
    unsigned short base_lo;
    unsigned short sel;
    unsigned char always0;
    unsigned char flags;
    unsigned short base_hi;
} __attribute__((packed));

struct idt_ptr
{
    unsigned short limit;
    uint base;
} __attribute__((packed));
@

// ORIGINAL CODE COMMENT \\
Declare an IDT of 256 entries. Although we will only use the
first 32 entries in this tutorial, the rest exists as a bit
of a trap. If any undefined IDT entry is hit, it normally
will cause an ``Unhandled Interrupt'' exception. Any descriptor
for which the presence bit is cleared (0) will generate an
``Unhandled Interrupt'' exception

<<interrupt declarations>>=
struct idt_entry idt[256];
struct idt_ptr idtp;

/* This exists in 'start.asm', and is used to load our IDT */
extern void idt_load();
@
\black

We'll add these to the kernel declarations:

<<kernel declarations>>=
<<interrupt declarations>>
@

Note that we're preparing for system calls (see chapter
\ref{chap:ulix:syscall}) by installing a handler for interrupt 0x80
(128).

\red
<<interrupt code>>=
/* Use this function to set an entry in the IDT. A lot simpler
*  than twiddling with the GDT ;) */
void idt_set_gate(unsigned char num, unsigned long base, unsigned short sel, 
                  unsigned char flags)
{
    /* The interrupt routine's base address */
    idt[num].base_lo = (base & 0xFFFF);
    idt[num].base_hi = (base >> 16) & 0xFFFF;

    /* The segment or 'selector' that this IDT entry will use
    *  is set here, along with any access flags */
    idt[num].sel = sel;
    idt[num].always0 = 0;
    idt[num].flags = flags | 0x60;
    // 0x60 needed to set DPL to 3 (0x60 = 1100000(bin))
}

/* Installs the IDT */
void idt_install()
{
    /* Sets the special IDT pointer up, just like in 'gdt.c' */
    idtp.limit = (sizeof (struct idt_entry) * 256) - 1;
    idtp.base = (int) &idt;

    /* Clear out the entire IDT, initializing it to zeros */
    memset(&idt, 0, sizeof(struct idt_entry) * 256);

    /* Add any new ISRs to the IDT here using idt_set_gate */


    /* Points the processor's internal register to the new IDT */
    idt_load();
    __asm__ ("xchg %bx,%bx"); // bochs break point
}
@


The interrupt service routines will be defined in the assembler
file, so we declare them as external:

<<interrupt code>>=
/* These are own ISRs that point to our special IRQ handler
*  instead of the regular 'fault_handler' function */
extern void irq0();  extern void irq1();  extern void irq2();  extern void irq3();
extern void irq4();  extern void irq5();  extern void irq6();  extern void irq7();
extern void irq8();  extern void irq9();  extern void irq10(); extern void irq11();
extern void irq12(); extern void irq13(); extern void irq14(); extern void irq15();

/* This array is actually an array of function pointers. We use
*  this to handle custom IRQ handlers for a given IRQ */
void *irq_routines[16] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };

/* This installs a custom IRQ handler for the given IRQ */
void irq_install_handler(int irq, void (*handler)(struct regs *r)) {
  irq_routines[irq] = handler;
}

/* This clears the handler for a given IRQ */
void irq_uninstall_handler(int irq) {
  irq_routines[irq] = 0;
}
@

// ORIGINAL CODE COMMENT\\
Normally, IRQs 0 to 7 are mapped to entries 8 to 15. This
is a problem in protected mode, because IDT entry 8 is a
Double Fault! Without remapping, every time IRQ0 fires,
you get a Double Fault Exception, which is NOT actually
what's happening. We send commands to the Programmable
Interrupt Controller (PICs - also called the 8259's) in
order to make IRQ0 to 15 be remapped to IDT entries 32 to
47

<<interrupt code>>=
void irq_remap(void) {
  outportb(0x20, 0x11);
  outportb(0xA0, 0x11);
  outportb(0x21, 0x20);
  outportb(0xA1, 0x28);
  outportb(0x21, 0x04);
  outportb(0xA1, 0x02);
  outportb(0x21, 0x01);
  outportb(0xA1, 0x01);
  outportb(0x21, 0x0);
  outportb(0xA1, 0x0);
}
@

// ORIGINAL CODE COMMENT\\
We first remap the interrupt controllers, and then we install
the appropriate ISRs to the correct entries in the IDT. This
is just like installing the exception handlers

<<interrupt code>>=
void irq_install() {
    irq_remap();

    idt_set_gate(32, (unsigned)irq0, 0x08, 0x8E);
    idt_set_gate(33, (unsigned)irq1, 0x08, 0x8E);
    idt_set_gate(34, (unsigned)irq2, 0x08, 0x8E);
    idt_set_gate(35, (unsigned)irq3, 0x08, 0x8E);
    idt_set_gate(36, (unsigned)irq4, 0x08, 0x8E);
    idt_set_gate(37, (unsigned)irq5, 0x08, 0x8E);
    idt_set_gate(38, (unsigned)irq6, 0x08, 0x8E);
    idt_set_gate(39, (unsigned)irq7, 0x08, 0x8E);

    idt_set_gate(40, (unsigned)irq8, 0x08, 0x8E);
    idt_set_gate(41, (unsigned)irq9, 0x08, 0x8E);
    idt_set_gate(42, (unsigned)irq10, 0x08, 0x8E);
    idt_set_gate(43, (unsigned)irq11, 0x08, 0x8E);
    idt_set_gate(44, (unsigned)irq12, 0x08, 0x8E);
    idt_set_gate(45, (unsigned)irq13, 0x08, 0x8E);
    idt_set_gate(46, (unsigned)irq14, 0x08, 0x8E);
    idt_set_gate(47, (unsigned)irq15, 0x08, 0x8E);
}
@

// ORIGINAL CODE COMMENT\\
Each of the IRQ ISRs point to this function, rather than
the [[fault_handler]] in isrs.c. The IRQ Controllers need
to be told when you are done servicing them, so you need
to send them an ``End of Interrupt'' command (0x20). There
are two 8259 chips: The first exists at 0x20, the second
exists at 0xA0. If the second controller (an IRQ from 8 to
15) gets an interrupt, you need to acknowledge the
interrupt at BOTH controllers, otherwise, you only send
an EOI command to the first controller. If you don't send
an EOI, you won't raise any more IRQs

<<interrupt code>>=
void irq_handler(struct regs *r) {
    /* If the IDT entry that was invoked was greater than 40
    *  (meaning IRQ8 - 15), then we need to send an EOI to
    *  the slave controller */
    if (r->int_no >= 40) outportb(0xA0, 0x20);

    /* In either case, we need to send an EOI to the master
    *  interrupt controller too */
    outportb(0x20, 0x20);

    /// DEBUG
    /// printf ("IRQ Handler: No. %d \n", r->int_no-32);

    /* This is a blank function pointer */
    void (*handler)(struct regs *r);

    /* Find out if we have a custom handler to run for this
    *  IRQ, and then finally, run it */
    handler = irq_routines[r->int_no - 32];
    
    if (handler) {
      handler(r);
    }

}


/* These are function prototypes for all of the exception
*  handlers: The first 32 entries in the IDT are reserved
*  by Intel, and are designed to service exceptions! */

extern void isr0();  extern void isr1();  extern void isr2();
extern void isr3();  extern void isr4();  extern void isr5();
extern void isr6();  extern void isr7();  extern void isr8();
extern void isr9();  extern void isr10(); extern void isr11();
extern void isr12(); extern void isr13(); extern void isr14();
extern void isr15(); extern void isr16(); extern void isr17();
extern void isr18(); extern void isr19(); extern void isr20();
extern void isr21(); extern void isr22(); extern void isr23();
extern void isr24(); extern void isr25(); extern void isr26();
extern void isr27(); extern void isr28(); extern void isr29();
extern void isr30(); extern void isr31(); extern void isr128();

extern void isr129();  // call the scheduler; testing....


/* This is a very repetitive function... it's not hard, it's
*  just annoying. As you can see, we set the first 32 entries
*  in the IDT to the first 32 ISRs. We can't use a for loop
*  for this, because there is no way to get the function names
*  that correspond to that given entry. We set the access
*  flags to 0x8E. This means that the entry is present, is
*  running in ring 0 (kernel level), and has the lower 5 bits
*  set to the required '14', which is represented by 'E' in
*  hex. */

#define IDT_GATE(i) idt_set_gate(i, (unsigned)isr##i, 0x08, 0x8E)
// e.g.  idt_set_gate(31,(unsigned)isr31, 0x08, 0x8E)
void isrs_install() {
  IDT_GATE( 0); IDT_GATE( 1); IDT_GATE( 2); IDT_GATE( 3); IDT_GATE( 4);
  IDT_GATE( 5); IDT_GATE( 6); IDT_GATE( 7); IDT_GATE( 8); IDT_GATE( 9);
  IDT_GATE(10); IDT_GATE(11); IDT_GATE(12); IDT_GATE(13); IDT_GATE(14);
  IDT_GATE(15); IDT_GATE(16); IDT_GATE(17); IDT_GATE(18); IDT_GATE(19);
  IDT_GATE(20); IDT_GATE(21); IDT_GATE(22); IDT_GATE(23); IDT_GATE(24);
  IDT_GATE(25); IDT_GATE(26); IDT_GATE(27); IDT_GATE(28); IDT_GATE(29);
  IDT_GATE(30); IDT_GATE(31); IDT_GATE(128); IDT_GATE(129);
}

/* This is a simple string array. It contains the message that
*  corresponds to each and every exception. We get the correct
*  message by accessing like:
*  exception_message[interrupt_number] */
char *exception_messages[] = {
    "Division By Zero",             //  0
    "Debug",                        //  1
    "Non Maskable Interrupt",       //  2
    "Breakpoint",                   //  3
    "Into Detected Overflow",       //  4
    "Out of Bounds",                //  5
    "Invalid Opcode",               //  6
    "No Coprocessor",               //  7

    "Double Fault",                 //  8
    "Coprocessor Segment Overrun",  //  9
    "Bad TSS",                      // 10
    "Segment Not Present",          // 11
    "Stack Fault",                  // 12
    "General Protection Fault",     // 13
    "Page Fault",                   // 14
    "Unknown Interrupt",            // 15

    "Coprocessor Fault",            // 16
    "Alignment Check",              // 17
    "Machine Check",                // 18
    "Reserved", "Reserved", "Reserved", "Reserved", "Reserved",

    "Reserved", "Reserved", "Reserved", "Reserved", "Reserved",
    "Reserved", "Reserved", "Reserved"
};

/* All of our Exception handling Interrupt Service Routines will
*  point to this function. This will tell us what exception has
*  happened! Right now, we simply halt the system by hitting an
*  endless loop. All ISRs disable interrupts while they are being
*  serviced as a 'locking' mechanism to prevent an IRQ from
*  happening and messing up kernel data structures */
void fault_handler(struct regs *r)
{
   __asm__ ("xchg %bx,%bx");  // BOCHS debugger
   // uint faulting_address, eflags;
   // fault address is 2nd entry on the stack, see
   // http://stackoverflow.com/questions/10360888/
   // identifying-faulting-address-on-general-protection-fault-x86
   // __asm__ __volatile__("movl 4(%%esp), %%eax" : "=a" (faulting_address));
   // __asm__ __volatile__("movl 12(%%esp), %%eax" : "=a" (eflags));

    bochs_putch('X');
    if (r->int_no==14) page_fault_handler (r);
    
    if (r->int_no < 32) 
    {
        bochs_putch ('\n');
        bochs_puts(exception_messages[r->int_no]);
        bochs_puts(" Exception. System Halted!\n");
    
        kputs(exception_messages[r->int_no]);
        kputs(" Exception. System Halted!\n");
        
   printf ("address = 0x%08x. current_task = %d. current_as = %d.\nHalting system.\n", 
     r->eip, current_task, current_as);
   // int vreg;
   // asm volatile ("mov %%eax, %0" : "=r"(vreg)); printf ("eax: 0x%x\n", vreg);
   // asm volatile ("mov %%esp, %0" : "=r"(vreg)); printf ("esp: 0x%x\n", vreg);
   // asm volatile ("mov %%ebp, %0" : "=r"(vreg)); printf ("ebp: 0x%x\n", vreg);
   printf ("EFLAGS: 0x%08x; ERRCODE: 0x%08x\n", r->eflags, r->err_code);
   printf ("eax: %08x  ebx: %08x  ecx: %08x  edx: %08x \n",
     r->eax, r->ebx, r->ecx, r->edx);
   printf ("eip: %08x  esp: %08x  int: %8d  err: %8d \n", 
     r->eip, r->esp, r->int_no, r->err_code);
   printf ("ebp: %08x  cs: %d  ds: %d  es: %d  fs: %d  ss:%d \n",
     r->ebp, r->cs, r->ds, r->es, r->fs, r->ss);
        
        DISABLE_SCHEDULER; 
        asm ("sti");
        printf ("\n");   
        asm ("jmp simple_shell");

        __asm__ ("hlt");
    }
}
@
\black


Here's a page fault handler, taken from
\url{http://www.jamesmolloy.co.uk/tutorial_html/6.-Paging.html}
(James Molloy).

\red
<<kernel functions>>=
void page_fault_handler(struct regs *regs)
{
   // asm("hlt");
   // A page fault has occurred.
   // The faulting address is stored in the CR2 register.
   uint faulting_address;
   
   __asm__ __volatile__("mov %%cr2, %0" : "=r" (faulting_address));

   // The error code gives us details of what happened.
   int present   = !(regs->err_code & 0x1); // Page not present
   int rw = regs->err_code & 0x2;           // Write operation?
   int us = regs->err_code & 0x4;           // Processor was in user-mode?
   int reserved = regs->err_code & 0x8;     // Overwritten CPU-reserved bits of page entry?
   int id = regs->err_code & 0x10;          // Caused by an instruction fetch?

   // Output an error message.
   printf("Page fault! ( ");
   if (present) {printf("present ");}
   if (rw) {printf("read-only ");}
   if (us) {printf("user-mode ");}
   if (reserved) {printf("reserved ");}
   if (id) {printf("instruction-fetch ");}
   printf (")\n");

   bochs_puts ((char*)"page fault: address = ");
   bochs_printhex (faulting_address);
   bochs_putch ('\n');


   printf ("address = 0x%08x. current_task = %d. current_as = %d.\nHalting system.\n", 
     faulting_address, current_task, current_as);
   // int vreg;
   // asm volatile ("mov %%eax, %0" : "=r"(vreg)); printf ("eax: 0x%x\n", vreg);
   // asm volatile ("mov %%esp, %0" : "=r"(vreg)); printf ("esp: 0x%x\n", vreg);
   // asm volatile ("mov %%ebp, %0" : "=r"(vreg)); printf ("ebp: 0x%x\n", vreg);

   printf ("eax: %08x  ebx: %08x  ecx: %08x  edx: %08x \n",
     regs->eax, regs->ebx, regs->ecx, regs->edx);
   printf ("eip: %08x  esp: %08x  int: %8d  err: %8d \n", 
     regs->eip, regs->esp, regs->int_no, regs->err_code);
   printf ("ebp: %08x  cs: %d  ds: %d  es: %d  fs: %d  ss:%d \n",
     regs->ebp, regs->cs, regs->ds, regs->es, regs->fs, regs->ss);
   
   
   // FUNNY: JUST RESTART...
   DISABLE_SCHEDULER; 
   asm ("sti");
   printf ("\n");   
   asm ("jmp simple_shell");

   printf ("entering monitor\n");
   asm ("jmp monitor");
   
   __asm__ ("hlt");
   /*
   asm (".intel_syntax noprefix; \
     label2: \
     xchg ax,ax; \
     jmp label2; \
     .att_syntax");
   */
}

void sys_monitor () {
  uint v; int i;
  asm ("monitor: ");
  printf ("In Monitor\n");
  printf ("Stack:\n");
  for (i=0; i<10; i++) {
    asm (".intel_syntax noprefix; \
      pop eax; \
      .att_syntax" : : "r"(v));
    printf ("%08x\n",v);
  };  
  
  activate_address_space (1);
  printf ("ADDRESS SPACE 1:\n");
  hexdump (0,8191);
  activate_address_space (2);
  printf ("ADDRESS SPACE 2:\n");
  hexdump (0,8191);
  asm ("hlt");
}
@
\black


And this also belongs to the kernel code:

<<kernel functions>>=
<<interrupt code>>
@



\chapter{Talking to the Hardware}

In this chapter we provide the code which talks to various kinds
of hardware. In most cases this will include an interrupt handler
which gets called when a device generates a hardware interrupt.


\section{Keyboard}

\subsection{Interrupt Handler}

The keyboard interrupt handler must recognize which key was pressed,
while also checking if any of the modifier keys (such as shift, control
or alt) was held down at the same time. We put all relevant code into
the [[<<keyboard handler>>]] chunk.

<<interrupt code>>=
<<keyboard handler>>
@

The array [[scancode_table]] maps key codes (as generated by the keyboard controller) 
to ASCII characters. It was originally taken from
\url{http://www.osdever.net/bkerndev/Docs/keyboard.htm}, but slightly
modified. Figure \ref{fig:scancodes} shows the scancodes for a standard PC keyboard.

\begin{figure}[h]
\centering
\includegraphics[width=15cm]{pics/pckey.png}
\caption{Scancodes for a standard PC keyboard (REDRAW PICTURE!)}
\label{fig:scancodes}
\end{figure}

Both pressing and releasing a key generates a scancode (that way the operating
system can see whether the user holds a key pressed). The scancodes for pressing
and releasing any specific key are identical except for the upper bit: If a
key was pressed, the scancode's upper bit is unset (0); if it was released it
is set (1). Thus [[scancode &0x80]] is 0 if the event is a key press event, it
is non-zero otherwise. In the latter case [[scancode-0x80]] (or [[scancode & ~0x80]])
calculates the keycode of the corresponding key press event.

All 0 entries in the map make \UlixI{} ignore a key. We also enter 0 in the map
for modifier keys since we handle them separately.

<<keyboard handler>>=
#define KEY_UP     191
#define KEY_DOWN   192
#define KEY_LEFT   193
#define KEY_RIGHT  194

unsigned char scancode_table[128] = {
  /*  0.. 9 */    0,  27, '1', '2', '3', '4', '5', '6', '7', '8',
  /* 10..19 */   '9', '0', '-', '=', '\b',	 /* Backspace */
                 '\t', /* Tab */   'q', 'w', 'e', 'r',	
  /* 20..29 */   't', 'z', 'u', 'i', 'o', 'p', '[', ']', 
                 '\n', /* Enter */  0, /* Control */
  /* 30..39 */   'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', ';',
  /* 40..49 */   '\'', '`', 0, /* Left shift */  '\\', 'y', 'x', 
                 'c', 'v', 'b', 'n',
  /* 50..59 */   'm', ',', '.', '/', 0, /* Right shift */
                 '*', 0, /* Alt */  ' ', /* Space bar */
                 0, /* CapsLock */  0, /* F1 */
  /* 60..69 */   0, 0, 0, 0, 0, 0, 0, 0, 0, /* F2..F10 */
                 0, /* NumLock */
  /* 70..79 */   0, /* Scroll Lock */   0, /* Home key */
                 KEY_UP, 0, /* Page Up */
                 '-', KEY_LEFT, 0, KEY_RIGHT,
                 '+', 0, /* End */
  /* 80..89 */   KEY_DOWN, 0, /* Page Down */
                 0, /* Insert Key */    0, /* Delete */
                 0, 0, 0, 0, /* F11 */  0, /* F12 */   0,
  /* 90..127     not defined */
};
@

The keyboard handler deals will all press and release events:


<<kernel declarations>>=
#define boolean unsigned int
@


\red
<<keyboard handler>>=
void keyboard_handler(struct regs *r) {
  terminal_t *vt = &terminals[cur_vt];

  static boolean shift_pressed = false;
  static boolean left_shift_pressed = false;
  static boolean right_shift_pressed = false;
  static boolean alt_pressed = false;
  static boolean ctrl_pressed = false;
  unsigned char scancode, c;

  scancode = inportb(0x60);   // read from the data buffer
  
  if (scancode < 128) {
    c = scancode_table[scancode];
  }

  if (scancode & 0x80) {
    // release key event
    switch (scancode & ~0x80) {
      case 29: ctrl_pressed = false; break;
      case 42: left_shift_pressed = false; break;
      case 54: right_shift_pressed = false; break;
      case 56: alt_pressed = false; break;
    }
    shift_pressed = left_shift_pressed || right_shift_pressed;
  }  else {
    // press key event
    debug_printf ("KEYCODE: %d\n", scancode);
    switch (scancode) {
      case 29: ctrl_pressed = true; return;
      case 42: shift_pressed = left_shift_pressed = true; return;
      case 54: shift_pressed = right_shift_pressed = true; return;
      case 56: alt_pressed = true; return;
    }

    if ((scancode == 1) && shift_pressed) {
      // Shift+Escape pressed
      DISABLE_SCHEDULER; 
      asm ("sti");
      printf ("\n");
      asm ("jmp simple_shell");
      return;
    };


    // bochs cannot handle ALT key, so Esc is an extra ALT key for now...
    if (scancode == 1) {
      // Esc pressed (don't handle this any longer )
      alt_pressed = !alt_pressed;
      return;
    }

    // switch address spaces on keyboard input Shift-1, Shift-2, ..., Shift-9
    // DISABLED
    /*
    if (shift_pressed && ('0' <= c) && (c <= '9')) {
      for (int i=0; i<10; i++) {	
        if ((c == '0'+i) && (!address_spaces[i].free)) {
          char statusline[80];
          sprintf ((char*)&statusline, "Activating address space %d   ", i);
          set_statusline (statusline);
          activate_address_space(i);
          return;
        }
      };
    };
    */

    if (shift_pressed && ('0' <= c) && (c <= '9')) {
      char shiftkeys[] = "=!\"^$%&/()";
      c = shiftkeys[c-'0'];
    }

    // switch terminals via Alt-0 to Alt-9
    if ((alt_pressed) && ('0' <= c) && (c <= '9')) {
      vt_activate ((int)((c-'0')+9)%10);   // activate virtual console
      move_csr ();  // update cursor on new terminal
      return;
    };
    <<enter pressed key in buffer>>
  }
}
@
\black

If a regular character was entered, we need to store it in one of the
keyboard buffers---as long as it is not filled already. So we first check
whether the buffer can carry the new character

<<enter pressed key in buffer>>=
if (vt->kbd_count < SYSTEM_KBD_BUFLEN) {
  if (shift_pressed && c>='a' && c<='z')  c-=32;     // Upper Case
  else if (ctrl_pressed && c>='a' && c<='z') c-=96;  // Ctrl
  vt->kbd[vt->kbd_pos] = c;
  vt->kbd_pos = (vt->kbd_pos + 1) % SYSTEM_KBD_BUFLEN;
  vt->kbd_count++;
  if ((vt->kbd_count == 1) && scheduler_is_active) {
    // debug_printf ("kbd handler: <waking sleeping process>\n");
    <<wake sleeping process>>
    // debug_printf ("kbd handler: end <waking sleeping process>\n");
  }
}
@

We still need to discuss what happens when a process is sleeping
(while waiting for input from its terminal). We search the 
[[keyboard_queue]] for a process which waits for input and uses
the currently active terminal [[cur_vt]]. If we find one (and we
assume that for each terminal at most one process can wait for
key entry) we wake it up, i.\,e., move it to the ready queue using
the [[deblock]] function:

<<wake sleeping process>>=
thread_id start_pid = keyboard_queue.next;
if (start_pid != 0) {
  // only if there are queue entries...
  thread_id search_pid = start_pid;
  do {
    if (thread_table[search_pid].terminal == cur_vt) {
      thread_table[search_pid].state = TSTATE_READY;
      deblock (search_pid, &keyboard_queue);
      break;
    } else {
      search_pid = thread_table[search_pid].next;
    }
  } while (search_pid != start_pid && search_pid != 0);
}
@

During system initialization we register the keyboard handler:
 
<<keyboard handler>>=
void keyboard_install() {
  irq_install_handler(1, keyboard_handler);
}
@


\subsection{The Keyboard Queue}

We provide several blocked queues---one for each different reason that
a process may block for. Here we define the queue for processes that
wait for a keystroke (on their terminal).

<<kernel global variables>>=
blocked_queue keyboard_queue;   // processes which wait for a keystroke
@

We must initialize the queue:

<<initialize system>>=
keyboard_queue.next = keyboard_queue.prev = 0;
@


<<kernel mode shell>>=
void kgetch (char* c) {
  int t = thread_table[current_task].terminal;
  if (t<0 || t>TERMINALS-1) {
    printf ("ERROR: terminal not set! setting to 0\n");
    t = 0;
  }
  terminal_t *term = &terminals[t];

  *c = 0;
  while (*c == 0) {
    // asm ("hlt");  // let processor sleep until next interrupt
    if (term->kbd_count > 0) {
      // printf (".");
      term->kbd_count--;
      term->kbd_lastread = (term->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
      *c = term->kbd[term->kbd_lastread];
    } else {
      *c = 0;
    };
  };
  return;
};
@

The function [[kreadline()]] is only used in the kernel mode shell.
\UlixI{} applications use their own functions which are defined in
the standard library and make system calls which finally call
[[kgetch()]].

<<kernel mode shell>>=
void kreadline ( char *s, int maxlength ) {
  DISABLE_SCHEDULER;
  char c;
  int pos=0;
  for (;;) {
    asm ("sti");
    kgetch (&c);   // read one character from the keyboard
    if ((c == 0x08) && (pos>0)) {
      // backspace
      pos--;
      kputch (c); kputch (' '); kputch (c);
    } else if ( c == '\n' ) {
      // newline: end of input
      putch ('\n');
      s[pos] = (char) 0;
      ENABLE_SCHEDULER;
      return;
    } else if ( (c != 0x08) && (pos < maxlength) ) {
      // other character
      kputch(c);
      s[pos++] = c;
    };
  };
};
@





\section{A Timer}

Adapted from the tutorial...

As an example for a (somewhat) useful timer, we will have a
clock in our system. It needs to be initialized at system
start, and we'll also need a variable to count how often
the timer interrupt occurred:

<<kernel declarations>>=
/* This will keep track of how many ticks that the system
*  has been running for */
uint system_ticks = 0;
int system_time;      // from 0 to 24*60-1
@

The timer handler will be executed every $\frac{1}{18.222}$
seconds, so we will a need a few calculations to get
seconds, minutes, and hours:

<<kernel declarations>>=
#define SCHED_SRC_TIMER   0
#define SCHED_SRC_YIELD   1
#define SCHED_SRC_WAITFOR 2
@

<<kernel global variables>>=
short int FROM_KERNEL_MODE = false;   // timer handler will set this
                                      // to true if entered from kernel mode

<<interrupt code>>=
<<timer handler>>
@

This is our timer interrupt handler:

\label{chunk:timer-handler}
<<timer handler>>=
void timer_handler(struct regs *r) {
  char buf[9];
  char sched_chars[] = "|/-\\";
  static short sched_c = 0;
  short int sec,min,hour;
  
  <<timer tasks>>

  // show current terminal, free frames, current_as
  sprintf ((char*)&buf, "tty%d  FF=%04x  AS=%04d", cur_vt, free_frames, current_as);
  _set_statusline ((char*)&buf, 48);  
}
@

Here is a function which can change the timer's frequency:

<<timer handler>>=
void timer_phase(int hz) {
  // source: http://www.osdever.net/bkerndev/Docs/pit.htm
  int divisor = 1193180 / hz;       /* Calculate our divisor */
  outportb(0x43, 0x36);             /* Set our command byte 0x36 */
  outportb(0x40, divisor & 0xFF);   /* Set low byte of divisor */
  outportb(0x40, divisor >> 8);     /* Set high byte of divisor */
};
@

We let [[timer_install]] register the handler for interrupt number 0:

<<timer handler>>=
void timer_install() {
  timer_phase (100);   // set timer to 100 Hz (100 interrupts/second)
  irq_install_handler(0, timer_handler);
}
@

\subsection{Tasks for the Timer}

We need the timer handler to do several things which we collect in
the [[<<timer tasks>>]] code chunk. The first and easiest task is to
modify the uptime:

<<timer tasks>>=
system_ticks++;    // one more timer interrupt
// system_time = (int) (system_ticks/18.222);    // original timer freq: 18.222 Hz
system_time = (int) (system_ticks/100);    // new timer freq: 100 Hz
@


In the status line at the bottom of the screen we display the current
time; we want to update this display approximately every other second:

<<timer tasks>>=
if (system_ticks % 100 == 0) {          // Every 100 clocks (approx. 1 second) 
  hour = (system_time/60/60)%24;        // display the time
  min = (system_time/60)%60;
  sec = system_time%60;
  sprintf ((char*)&buf, "%02d:%02d:%02d", hour, min, sec);
  _set_statusline ((char*)&buf, 72);
}
@

However, the most important task is to regularly call the scheduler; we do
that on every second timer interrupt:


<<timer tasks>>=
// Every 2 clocks (approx. 1/9 second) call the scheduler
if (system_ticks % 2 == 0) {
/*
    // REMOVE THE FOLLOWING CODE
    // Don't do scheduling if we're in kernel mode
    if (r->eip >= 0xc0000000) {
      // printf ("timer: eip = %x, going to crash...\n", r->eip);
      FROM_KERNEL_MODE = true;
    } else {
      FROM_KERNEL_MODE = false;
    };
    // (END OF REMOVE)
*/

  // cycle |/-\\- to show scheduler calls in upper right corner
  uint videoaddress = VIDEORAM + 79*2;
  *((char*)videoaddress) = sched_chars[sched_c];
  sched_c++; sched_c %= 4;

  // only run the scheduler if a process hasn't just called yield():
  if (inside_yield == false) {
    // printf ("TIMER CALLING SCHEDULER!!!!\n\n\n");
    scheduler (r, SCHED_SRC_TIMER);  // defined in the process chapter
  }
};
@


%< <timer handler> >=
%/* This will continuously loop until the given time has 
%*  been reached */
%void timer_wait(int ticks)
%{
%    unsigned long eticks;
%
%    eticks = system_ticks + ticks;
%    while(system_ticks < eticks);
%}
@






% --------------------------------------------------------------------------



\chapter{System Calls and a Standard Library}
\label{chap:ulix:syscall}%

...

While we implement system calls, we will also create functions
for the standard library that user mode programs must link in order
to conveniently talk to the operating system via functions such as
[[fork]], [[open]], [[read]], etc.

There are several ways to implement system calls. Let's first look
at the way system calls can be called from user space. On 32 bit Intel
CPUs, Linux does
it via software interrupt 0x80 with arguments in registers:

<<example for system calls in linux>>=
_start:                         ; tell linker entry point
      mov edx,len               ; message length
      mov ecx,msg               ; message to write
      mov ebx,1                 ; file descriptor (stdout)
      mov eax,4                 ; system call number (sys_write)
      int 0x80                  ; call kernel
      mov eax,1                 ; system call number (sys_exit)
      int 0x80                  ; call kernel

section	.data
msg   db 'Hello, world!',0xa    ; our dear string
len   equ $ - msg               ; length of our dear string
@

(taken from \url{http://asm.sourceforge.net/intro/hello.html})

Here [[eax]] always holds the system call number, the other
registers (in this example [[ebx]], [[ecx]], and [[edx]] are
used for arguments. System call 4 is the [[sys_write]] syscall.

Other operating systems put arguments on the stack or into
specific memory areas. We will stick with the Linux way
because it is simple to use registers.


\codesection{System Calls in \UlixI{}}

\UlixI{} provides functions for adding (or modifying) system calls 
to the system and a generic system call handler. For this purpose,
we create a system call table [[syscall_table]] that contains 
pointers to functions, so for example, [[syscall_table[4]]] should
contain the address of \UlixI{}'s [[sys_write]] function. If a
system call is not defined, the table entry is a null pointer, so
we can initialize the whole table with null bytes:

<<kernel declarations>>=
#define MAX_SYSCALLS 0x8000         // max syscall number: 0x7fff
void *syscall_table[MAX_SYSCALLS];
@

Telling \UlixI{} what function to execute when a specific system call
is made is as simple as writing the address into the proper array
entry. Nevertheless, we provide a function for this:

<<kernel functions>>=
void insert_syscall (int syscallno, void* syscall_handler) {
  if (syscallno < MAX_SYSCALLS) {
    syscall_table[syscallno] = syscall_handler;
  }
  return;
};
@

So if we have already defined a function [[sys_write]], we could
activate the [[write]] system call by calling

<<syscall entry example>>=
insert_syscall (__NR_write, sys_write);
@ (if [[__NR_write]] is set to 4).

The actual system call handler simply checks if there is a handler
for the given system call number and (if so) calls it:

<<kernel functions>>=
void syscall_handler (struct regs_syscall *r) {
  /*
  printf ("ULIX syscall handler. Register: \n");
  printf ("address of regs: %x\n", &r);
  printf ("cs=%x, ds=%x, ss=%x, eip=%x, esp=%x, ebp=%x\n",
    r->cs, r->ds, r->ss, r->eip, r->esp, r->ebp);
  printf ("eflags=%x, useresp=%x\n",
    r->eflags, r->useresp);
  printf ("===========\n");
  */
  void (*handler) (struct regs_syscall*);   // handler is a function pointer
  int number = r->eax;
  handler = syscall_table[number];
  if (handler != 0) {
    handler (r);
  } else {
    printf("Unknown syscall no. eax=0x%x; ebx=0x%x. eip=0x%x, esp=0x%x. Continuing.\n", 
    r->eax, r->ebx, r->eip, r->esp);
  };
  
  if (number == __NR_fork)
    debug_printf ("DEBUG: syscall_handler: returning from fork syscall\n");
  return;
}
@

<<kernel functions>>=
<<syscall functions>>
@

%\begin{work}
%Eigentlich will ich hier die Page Table aendern, so dass ich 
%gleichzeitig den User Space und den Kernel Space sehe. Im Moment
%gibt's aber noch keinen User Space ;)\\
%
%Ideen:
%
%-- testen, ob Page Table Eintrag fuer \hexaddr{C000.0000} ein Nulleintrag
%ist (dann weiss ich: ich bin im User Mode)
%
%-- falls ja: irgendwo speichern, dass ich im User mode bin
%
%-- falls nein: Page Table anpassen (kernel einblenden)
%
%-- nach Rueckkehr: pruefen, ob ich vorher im User mode war
%
%-- falls ja: Page Table anpassen (Kernel-Teil nullen)
%\end{work}

<<start.asm>>=
[BITS 32]
[section .text]
; 128: int 0x80
extern syscall_handler
extern scheduler

global isr128
isr128:
    push byte 0     ; put 128 on the stack so it looks the same
    ; push byte 128   ; as it does after a hardware interrupt
    push byte -128  ; (getting rid of nasm error for signed byte)
    pusha
    push ds
    push es
    push fs
    push gs
    mov ax, 0x10
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov eax, esp
    push eax
    mov eax, syscall_handler
    call eax
    ;call syscall_handler
    pop eax
    pop gs
    pop fs
    pop es
    pop ds
    popa
    add esp, 8   ; undo the two "push byte" commands from the start
    iret

global isr129
isr129:
    push byte 0     ; put 129 on the stack so it looks the same
    ; push byte 129   ; as it does after a hardware interrupt
    push byte -127  ; (getting rid of nasm error for signed byte)
    pusha
    push ds
    push es
    push fs
    push gs
    mov ax, 0x10
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov eax, esp
    push eax
    mov eax, scheduler
    call eax
    ;call scheduler
    pop eax
    pop gs
    pop fs
    pop es
    pop ds
    popa
    add esp, 8   ; undo the two "push byte" commands from the start
    iret

@

For increased Linux compatibility we will use the same system call numbers
as Linux does---at least for those calls that \UlixI{} does also provide.

The following definitions were taken from the 32-bit 
Linux\footnote{Ubuntu 11.10, \url{http://www.ubuntu.com/}} file 
\path!/usr/include/i386-linux-gnu/asm/unistd_32.h!:

\begin{work}
TODO: In the end: remove all numbers which are not used 
\end{work}

{\small
<<linux system calls>>=
#define __NR_yield               66   // not from Linux
#define __NR_exit                 1
#define __NR_fork                 2
#define __NR_read                 3
#define __NR_write                4
#define __NR_open                 5
#define __NR_close                6
#define __NR_waitpid              7
#define __NR_creat                8
#define __NR_link                 9
#define __NR_unlink              10
#define __NR_execve              11
#define __NR_chdir               12
#define __NR_time                13
#define __NR_mknod               14
#define __NR_chmod               15
#define __NR_lchown              16
#define __NR_break               17
#define __NR_oldstat             18
#define __NR_lseek               19
#define __NR_getpid              20
#define __NR_mount               21
#define __NR_umount              22
#define __NR_setuid              23
#define __NR_getuid              24
#define __NR_stime               25
#define __NR_ptrace              26
#define __NR_alarm               27
#define __NR_oldfstat            28
#define __NR_pause               29
#define __NR_utime               30
#define __NR_stty                31
#define __NR_gtty                32
#define __NR_access              33
#define __NR_nice                34
#define __NR_ftime               35
#define __NR_sync                36
#define __NR_kill                37
#define __NR_rename              38
#define __NR_mkdir               39
#define __NR_rmdir               40
#define __NR_dup                 41
#define __NR_pipe                42
#define __NR_times               43
#define __NR_prof                44
#define __NR_brk                 45
#define __NR_setgid              46
#define __NR_getgid              47
#define __NR_signal              48
#define __NR_geteuid             49
#define __NR_getegid             50
#define __NR_acct                51
#define __NR_umount2             52
#define __NR_lock                53
#define __NR_ioctl               54
#define __NR_fcntl               55
#define __NR_mpx                 56
#define __NR_setpgid             57
#define __NR_ulimit              58
#define __NR_oldolduname         59
#define __NR_umask               60
#define __NR_chroot              61
#define __NR_ustat               62
#define __NR_dup2                63
#define __NR_getppid             64
#define __NR_getpgrp             65
#define __NR_setsid              66
#define __NR_sigaction           67
#define __NR_sgetmask            68
#define __NR_ssetmask            69
#define __NR_setreuid            70
#define __NR_setregid            71
#define __NR_sigsuspend          72
#define __NR_sigpending          73
#define __NR_sethostname         74
#define __NR_setrlimit           75
#define __NR_getrlimit           76   /* Back compatible 2Gig limited rlimit */
#define __NR_getrusage           77
#define __NR_gettimeofday        78
#define __NR_settimeofday        79
#define __NR_getgroups           80
#define __NR_setgroups           81
#define __NR_select              82
#define __NR_symlink             83
#define __NR_oldlstat            84
#define __NR_readlink            85
#define __NR_uselib              86
#define __NR_swapon              87
#define __NR_reboot              88
#define __NR_readdir             89
#define __NR_mmap                90
#define __NR_munmap              91
#define __NR_truncate            92
#define __NR_ftruncate           93
#define __NR_fchmod              94
#define __NR_fchown              95
#define __NR_getpriority         96
#define __NR_setpriority         97
#define __NR_profil              98
#define __NR_statfs              99
#define __NR_fstatfs            100
#define __NR_ioperm             101
#define __NR_socketcall         102
#define __NR_syslog             103
#define __NR_setitimer          104
#define __NR_getitimer          105
#define __NR_stat               106
#define __NR_lstat              107
#define __NR_fstat              108
#define __NR_olduname           109
#define __NR_iopl               110
#define __NR_vhangup            111
#define __NR_idle               112
#define __NR_vm86old            113
#define __NR_wait4              114
#define __NR_swapoff            115
#define __NR_sysinfo            116
#define __NR_ipc                117
#define __NR_fsync              118
#define __NR_sigreturn          119
#define __NR_clone              120
#define __NR_setdomainname      121
#define __NR_uname              122
#define __NR_modify_ldt         123
#define __NR_adjtimex           124
#define __NR_mprotect           125
#define __NR_sigprocmask        126
#define __NR_create_module      127
#define __NR_init_module        128
#define __NR_delete_module      129
#define __NR_get_kernel_syms    130
#define __NR_quotactl           131
#define __NR_getpgid            132
#define __NR_fchdir             133
#define __NR_bdflush            134
#define __NR_sysfs              135
#define __NR_personality        136
#define __NR_setfsuid           138
#define __NR_setfsgid           139
#define __NR__llseek            140
#define __NR_getdents           141
#define __NR__newselect         142
#define __NR_flock              143
#define __NR_msync              144
#define __NR_readv              145
#define __NR_writev             146
#define __NR_getsid             147
#define __NR_fdatasync          148
#define __NR__sysctl            149
#define __NR_mlock              150
#define __NR_munlock            151
#define __NR_mlockall           152
#define __NR_munlockall         153
#define __NR_nanosleep          162
#define __NR_mremap             163
#define __NR_setresuid          164
#define __NR_getresuid          165
#define __NR_vm86               166
#define __NR_query_module       167
#define __NR_poll               168
#define __NR_nfsservctl         169
#define __NR_setresgid          170
#define __NR_getresgid          171
#define __NR_prctl              172
#define __NR_pread64            180
#define __NR_pwrite64           181
#define __NR_chown              182
#define __NR_getcwd             183
#define __NR_capget             184
#define __NR_capset             185
#define __NR_sigaltstack        186
#define __NR_sendfile           187
#define __NR_getpmsg            188     /* some people actually want streams */
#define __NR_putpmsg            189     /* some people actually want streams */
#define __NR_vfork              190
#define __NR_ugetrlimit         191     /* SuS compliant getrlimit */
#define __NR_mmap2              192
#define __NR_truncate64         193
#define __NR_ftruncate64        194
#define __NR_stat64             195
#define __NR_lstat64            196
#define __NR_fstat64            197
#define __NR_lchown32           198
#define __NR_getuid32           199
#define __NR_getgid32           200
#define __NR_geteuid32          201
#define __NR_getegid32          202
#define __NR_setreuid32         203
#define __NR_setregid32         204
#define __NR_getgroups32        205
#define __NR_setgroups32        206
#define __NR_fchown32           207
#define __NR_setresuid32        208
#define __NR_getresuid32        209
#define __NR_setresgid32        210
#define __NR_getresgid32        211
#define __NR_chown32            212
#define __NR_setuid32           213
#define __NR_setgid32           214
#define __NR_setfsuid32         215
#define __NR_setfsgid32         216
#define __NR_pivot_root         217
#define __NR_mincore            218
#define __NR_madvise            219
#define __NR_madvise1           219     /* delete when C lib stub is removed */
#define __NR_getdents64         220
#define __NR_fcntl64            221
/* 223 is unused */
#define __NR_gettid             224
#define __NR_readahead          225
#define __NR_tkill              238
#define __NR_sendfile64         239
#define __NR_futex              240
#define __NR_sched_setaffinity  241
#define __NR_sched_getaffinity  242
#define __NR_set_thread_area    243
#define __NR_get_thread_area    244
#define __NR_io_setup           245
#define __NR_io_destroy         246
#define __NR_io_getevents       247
#define __NR_io_submit          248
#define __NR_io_cancel          249
#define __NR_fadvise64          250
/* 251 is available for reuse (was briefly sys_set_zone_reclaim) */
#define __NR_exit_group         252
#define __NR_lookup_dcookie     253
#define __NR_epoll_create       254
#define __NR_epoll_ctl          255
#define __NR_epoll_wait         256
#define __NR_remap_file_pages   257
#define __NR_set_tid_address    258
#define __NR_timer_create       259
#define __NR_timer_settime      (__NR_timer_create+1)
#define __NR_timer_gettime      (__NR_timer_create+2)
#define __NR_timer_getoverrun   (__NR_timer_create+3)
#define __NR_timer_delete       (__NR_timer_create+4)
#define __NR_clock_settime      (__NR_timer_create+5)
#define __NR_clock_gettime      (__NR_timer_create+6)
#define __NR_clock_getres       (__NR_timer_create+7)
#define __NR_clock_nanosleep    (__NR_timer_create+8)
#define __NR_statfs64           268
#define __NR_fstatfs64          269
#define __NR_tgkill             270
#define __NR_utimes             271
#define __NR_fadvise64_64       272
#define __NR_vserver            273
#define __NR_mbind              274
#define __NR_get_mempolicy      275
#define __NR_set_mempolicy      276
#define __NR_kexec_load         283
#define __NR_waitid             284
/* #define __NR_sys_setaltroot  285 */
#define __NR_add_key            286
#define __NR_request_key        287
#define __NR_keyctl             288
#define __NR_ioprio_set         289
#define __NR_ioprio_get         290
#define __NR_inotify_init       291
#define __NR_inotify_add_watch  292
#define __NR_inotify_rm_watch   293
#define __NR_migrate_pages      294
#define __NR_openat             295
#define __NR_mkdirat            296
#define __NR_mknodat            297
#define __NR_fchownat           298
#define __NR_futimesat          299
#define __NR_fstatat64          300
#define __NR_unlinkat           301
#define __NR_renameat           302
#define __NR_linkat             303
#define __NR_symlinkat          304
#define __NR_readlinkat         305
#define __NR_fchmodat           306
#define __NR_faccessat          307
#define __NR_pselect6           308
#define __NR_ppoll              309
#define __NR_unshare            310
#define __NR_set_robust_list    311
#define __NR_get_robust_list    312
#define __NR_splice             313
#define __NR_sync_file_range    314
#define __NR_tee                315
#define __NR_dup3               330
#define __NR_pipe2              331
@
}%end small

<<kernel declarations>>=
<<linux system calls>>
<<ulix system calls>>
@

The system calls return arguments by storing the value
in [[ebx]].

<<kernel declarations>>=
void update_statusline ();
@


\subsection{SYSCALLS: fork}

<<syscall functions>>=
void syscall_fork (struct regs *r) {
  // int pid;
  // printf ("entering syscall fork\n");
  // pid = ulix_fork(r);
  // r->ebx = (uint)pid;
  r->ebx = (uint) ulix_fork(r);
  return;
};
@

We allow processes to set their own name via the [[setpsname]]
system call:

<<syscall functions>>=
void syscall_setpsname (struct regs *r) {
  memcpy (thread_table[current_task].cmdline, (char*)r->ebx, CMDLINE_LENGTH);
  return;
};
@

<<ulix system calls>>=
#define __NR_setpsname 0x5103
@

<<initialize syscalls>>=
insert_syscall (__NR_fork, syscall_fork);
insert_syscall (__NR_setpsname, syscall_setpsname);
@


\subsection{SYSCALLS: waitpid}

Often a process wants to wait for the completion of a child
process, a typical example is a shell which starts an external
program by [[fork]]ing, [[exec]]uting the program inside the
child process, and [[wait]]ing in the parent process.

Here we implement the [[waitpid]] system call which waits for
completion of a given child, the standard definition, taken from
the Linux manpage, is the following:

{\small
\begin{verbatim}
pid_t waitpid(pid_t pid, int *status, int options);
\end{verbatim}
}

Here,

\begin{itemize}
\item [[pid]] is the process ID of a child process ([[waitpid]]
cannot be used to wait for termination of arbitrary, non-child processes),
\item [[*status]] is the address of a status value which will be
used to store the exitcode of the child process (or an error
value if the child was aborted),
\item and [[options]] can be used to modify [[waitpid]]'s behavior;
our implementation will ignore any given options.
\end{itemize}

We need a blocked queue for processes that called [[waitpid]] since
they must not be picked by the scheduler.

<<kernel global variables>>=
blocked_queue waitpid_queue;
@

<<initialize system>>=
waitpid_queue.next = waitpid_queue.prev = 0;
@

Several things must be implemented for [[waitpid]] to work properly:

\begin{itemize}
\item We need the system call handler which moves the current (calling)
process from the ready queue to the new [[waitpid_queue]] and calls
[[yield]] (so that the scheduler picks a new process---the [[yield]] code
will be shown right after [[waitpid]]),
\item When a process [[exit]]s, it must store the [[exit]] argument
in the thread control block---this TCB must remain intact until the
parent process has had a chance to look up the value.
\item If the parent process is in the [[waitpid_queue]] we move it back
to the ready queue.
\item Once the parent process is picked by the scheduler, it will
continue its execution of [[waitpid]] and has to read the child's
exitcode, after that it can delete the TCB entry.
\end{itemize}

As long as the parent process could not be reactivated, the child's
TCB will remain intact. Note that it is not necessary for the parent
process to actually look at the exitcode.

First we add an [[exitcode]] entry and a [[waitfor]] entry to the 
[[TCB]] structure:

<<more TCB entries>>=
  int exitcode;
  int waitfor;    // in case of waitpid(): the pid of the child we wait for
@

Here's the system call code:

<<syscall functions>>=
void syscall_waitpid (struct regs_syscall *r) {
  // ebx: pid of child to wait for
  // ecx: pointer to status
  // edx: options (ignored)
  int chpid = r->ebx;
  int *status = (int*)r->ecx;
  debug_printf ("[%d] in syscall_waitpid, status (1) = 0x%x\n", current_task, status);
  
  thread_table[current_task].state = TSTATE_WAITFOR;
  thread_table[current_task].waitfor = chpid;
  remove_from_ready_queue (current_task);
  add_to_blocked_queue (current_task, &waitpid_queue);

  printf ("[%d] waitpid: waiting for pid %d; calling scheduler \n", current_task, chpid);
  // syscall_yield (r);   // here we yield
  inside_yield = true;
  scheduler (r, SCHED_SRC_WAITFOR);
  
  /*
  if (thread_table[current_task].state != TSTATE_WAITFOR) {
    printf ("[%d] in syscall_waitpid: wrong return!\n", current_task);
    return;
  };
  */
    
  // asm ("int $0x81");  // call scheduler
  
  // PROBLEM
  // We come back here after scheduler(), but with the memory and
  // stack of a different thread. This is bad...
  
  inside_yield = false;

  printf ("waitpid: returned from yield (pid=%d)\n", current_task);

  // now we've returned from syscall_yield, the child must have
  // finished
  
  // unblocking this process happens in syscall_exit() !
  // remove_from_blocked_queue (current_task, &waitpid_queue);
  // add_to_ready_queue (current_task);
  
  // return value of waitpid is the process id of the terminated
  // child. We expect that syscall_exit() has updated the waitfor
  // field of the parent's TCB:
  chpid = thread_table[current_task].waitfor;
  if (chpid>0 && chpid<MAX_THREADS && thread_table[chpid].used) {
    debug_printf ("current_task = %d\n", current_task);
    debug_printf ("chpid = %d\n", chpid);
    r->eax = chpid;
  
    // the exitcode is in the child's exitcode field:
    // debug_printf ("in syscall_waitpid, status (2) = 0x%x\n", status);
    // debug_printf ("in syscall_waitpid. exitcode = %d\n", thread_table[chpid].exitcode);
    *status = thread_table[chpid].exitcode;
    // debug_printf ("in syscall_waitpid. *status = %d\n", *status);
  
    // now remove child process
    thread_table[chpid].used = false;
  } else {
    // *status = -1;
  }  
  debug_printf ("going to return from syscall_waitpid\n");
  return;
}
@

As usual, we register the new system call:

<<initialize syscalls>>=
insert_syscall (__NR_waitpid, syscall_waitpid);
@


\subsection{SYSCALL: exit}

<<kernel declarations>>=
void syscall_yield (struct regs_syscall *r);
@

<<syscall functions>>=
void syscall_exit (struct regs *r) {
  // printf ("DEBUG: syscall_exit. current_task = %d\n", current_task);
  // exit code is in ebx register:
  thread_table[current_task].exitcode = r->ebx;
  // mark thread as finished:
  thread_table[current_task].state = TSTATE_EXIT;
  // remove thread from ready list
  remove_from_ready_queue (current_task);
  
  // check if we need to wake up parent process
  int ppid = thread_table[current_task].ppid;
  if ( (thread_table[ppid].state == TSTATE_WAITFOR) &&
       (thread_table[ppid].waitfor == current_task) ) {
    // wake up parent process
    debug_printf ("exit: remove_from_blocked_queue (%d,%x)\n", ppid, &waitpid_queue);
    remove_from_blocked_queue (ppid, &waitpid_queue);
    add_to_ready_queue (ppid);
    thread_table[ppid].state = TSTATE_READY;   // mark parent as ready
    thread_table[current_task].state = TSTATE_EXIT;
    // thread_table[current_task].used = false;
  } else {
    // parent is not waiting, make this process a zombie
    thread_table[current_task].state = TSTATE_ZOMBIE;
  }
  
  // remove memory and destroy address space
  destroy_address_space (current_as);
  
  // finally: call scheduler to pick a different task

  // printf ("DEBUG: syscall_exit, going to int 0x81\n");

  // return;
  // asm ("int $0x81");
  // asm ("sti; hlt");
  asm ("sti");

  scheduler ((struct regs_syscall *)r, SCHED_SRC_YIELD);    

  printf ("ERROR: NEVER REACH THIS LINE!!!!\n\n");

  // better: call scheduler explicitly
};
@

<<initialize syscalls>>=
insert_syscall (__NR_exit, syscall_exit);
@


\subsection{SYSCALL: yield}

The [[yield]] system call allows a process to give up the
CPU, so that the schedulers pick an other process immediately:

<<kernel declarations>>=
#define false 0
#define true 1
short int inside_yield = false;
@

<<syscall functions>>=
void syscall_yield (struct regs_syscall *r) {
  debug_printf ("entering syscall_yield\n");
  debug_printf ("r->esp = %x  r->eip = %x\n", r->esp, r->eip);
  inside_yield = true;   // note: we have just started yield() and
                         // don't want to be interrupted by the scheduler

  scheduler (r, SCHED_SRC_YIELD);

  debug_printf("inside syscall_yield: back from scheduler ()\n");
  
  // we do not want to return here
  // instead, after entering scheduler() we expect to jump back
  // into the timer handler (???)
  
  // printf ("pid =%2d yield (post-sched) r->esp = %x\n",current_task, r->esp);

  // asm ("sti");
  inside_yield = false;
  return;
}
@

<<initialize syscalls>>=
insert_syscall (__NR_yield, syscall_yield);
@



\subsection{SYSCALLS: getpid}

<<syscall functions>>=
void syscall_getpid (struct regs_syscall *r) {
  r->eax = current_task;
  return;
};
@

<<initialize syscalls>>=
insert_syscall (__NR_getpid, syscall_getpid);
@


\subsection{SYSCALL: 0x1001, put char}

<<syscall functions>>=
void syscall_0x1001 (struct regs *r) {
  // put character
  char c = (unsigned char) (r->ebx);
  if (c>31 || c=='\n' || c==0x08) {
    kputch (c);
  } else {
    kputch ('^'); kputch (c+64);
  }
  return;
}
@

<<initialize syscalls>>=
insert_syscall (0x1001, syscall_0x1001);
@


\subsection{SYSCALL: 0x1002, get char}

This is the system call that user mode programs use to read a character
from their console.

<<syscall functions>>=
void syscall_0x1002 (struct regs *r) {
  char c;
  int t = thread_table[current_task].terminal;
  // t = 0;
  terminal_t *vt = &terminals[t];
  
  // get character
  // return 0 if there is no new character in the buffer
  if (vt->kbd_count > 0) {
    vt->kbd_count--;
    vt->kbd_lastread = (vt->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
    c = vt->kbd[vt->kbd_lastread];
  } else {
    c = 0;
    if ((current_task > 1) && scheduler_is_active) {
      // block process
      thread_table[current_task].state = TSTATE_WAITKEY;
      remove_from_ready_queue (current_task);
      add_to_blocked_queue (current_task, &keyboard_queue);
        
      // calling yield (via syscall 66)
      asm {
        mov eax, 66;
        int 0x80;
      };
    }
    
  };
  // return value in ebx
  r->ebx = c;
  return;
};
@

<<initialize syscalls>>=
insert_syscall (0x1002, syscall_0x1002);
@


\subsection{SYSCALL: 0x1111, readline}


We're not using the following function:

<<syscall functions>>=
void syscall_0x1111 (struct regs *r) {
  // readline
  // ebx: address of buffer
  // ecx: number of characters
  kreadline ((char*)r->ebx, (int)r->ecx);
  return;
};
@

<<initialize syscalls>>=
insert_syscall (0x1111, syscall_0x1111);
@



<<kernel functions>>=
void putch(unsigned char c) {
  // calls kputch via a syscall
  __asm__ (" \
	movl $0x1001,%%eax; \
	movl %0,%%ebx; \
	int  $0x80; \
	" : : "r"((uint)c) : "eax", "ebx");
};
@


\subsection{SYSCALLS: getpsinfo}

The [[getpsinfo]] system calls lets a process read its
thread control block (the [[TCB]] structure). That way, a
non-privileged [[ps]] program can show the process list.
It is not possible to modify a TCB, but the TCB may contain
information that should be kept private.

<<ulix system calls>>=
#define __NR_getpsinfo 0x5101
@

<<syscall functions>>=
void syscall_getpsinfo (struct regs *r) {
  uint retval, pid;
  // getpsinfo
  // ebx: number of process
  // ecx: address of TCB block

  pid = r->ebx;
  // legal argument?
  if (pid > MAX_THREADS || pid < 1) {
    retval = 0;
    goto end;
  }

  // do we have this process?
  if (thread_table[pid].used == false) {
    retval = 0;
    goto end;
  }
  
  // found a process: copy its TCB  
  memcpy ((char*)r->ecx, &thread_table[pid], sizeof(TCB));
  retval = r->ecx;

  end:
  r->eax = retval;
  return;
};
@

<<initialize syscalls>>=
insert_syscall (__NR_getpsinfo, syscall_getpsinfo);
@


%struct regs
%{
%    uint gs, fs, es, ds;
%    uint edi, esi, ebp, esp, ebx, edx, ecx, eax;
%    uint int_no, err_code;
%    uint eip, cs, eflags, useresp, ss;    
%};




\codesection{A Standard Library for \UlixI{} Programs}

User mode applications will be compiled with a standard
C compiler (\texttt{gcc}), and developers will expect 
certain standard functions (such as [[printf]]) to be
available for their use.

In this section we present the \UlixI{} standard library
([[ulixlib]]) and show how programs can be written and
compiled with it.


\subsection{The [[ulixlib]] Library}

The library consists of two files, namely [[ulixlib.c]] and
[[ulixlib.h]]. The first one must be compiled (yielding
the object file [[ulixlib.o]], whereas the second one is
included in the source code of user mode programs so that
the library functions will be available.

The linker must combine the program's object file and the
library's object file into an ELF binary that can be loaded
by the \UlixI{} program loader.

<<ulixlib.c>>=
@

<<ulixlib.h>>=
@

IMPLEMENTATION: SEE SEPARATE DOCUMENT 
\path!/Users/esser/ulix/Code/Apps/C/ulixlib.nw!
-- to be included here later.




% --------------------------------------------------------------------------







\chapter{Memory Management}
\label{chap:ulix:mm}%


\section{Helper Functions}

\red
<<mm helper functions>>=
#define memcpy_debug(dest, src, count) \
  debug_printf ("DEBUG: memcpy() called in line %d\n", __LINE__); \
  memcpy (dest, src, count);

void *memcpy (void *dest, const void *src, size_t count) {
  // debug_printf ("DEBUG: memcpy (%x,%x,%x)\n", dest, src, count);
  const char *sp = (const char *)src;
  char *dp = (char *)dest;
  for (; count != 0; count--) 
    *dp++ = *sp++;
  return dest;
}

void *strncpy (void *dest, const void *src, size_t count) {
  // like memcpy, but copies only until first \0 character
  const char *sp = (const char *)src;
  char *dp = (char *)dest;
  for (; count != 0; count--) {
    *dp = *sp;
    if (*dp == 0) break;
    dp++; sp++;
  }
  return dest;
}

/*  already defined elsewhere
int strlen (const char* str) {
  int len;
  while (*str++ != 0) 
    len++;
  return len;
}
*/

// the following is a memcpy wrapper which logs to bochs output
void *bochs_memcpy(void *dest, const void *src, size_t count) {
  bochs_puts ("memcpy: "); bochs_printhex ((uint)(dest));
  bochs_puts (" <- ");     bochs_printhex ((uint)(src));
  bochs_puts (", size: "); bochs_printhex ((uint)(count));
  bochs_putch ('\n');  
  return memcpy(dest, src, count);
}

void *memset(void *dest, char val, size_t count) {
  char *temp = (char *)dest;
  for( ; count != 0; count--) *temp++ = val;
  return dest;
}

unsigned short *memsetw(unsigned short *dest, unsigned short val, size_t count) {
  unsigned short *temp = (unsigned short *)dest;
  for( ; count != 0; count--) *temp++ = val;
  return dest;
}
@
\black

... add to kernel functions:

<<kernel functions>>=
<<mm helper functions>>
@






\green



\section{Motivation}

A \emph{\vindex{virtual memory}} is an abstraction of physical
memory. Roughly speaking, a virtual memory is an array of memory
cells. Usually the size of the virtual memory corresponds to the
maximum addressable space allowed by the hardware.  A computer may
handle multiple such address spaces (and therefore virtual memories)
at the same time.  Virtual memories are used to encapsulate effects of
programs on memory. Briefly spoken, every program has its own virtual
memory and no program can (easily) access the virtual memory of
another program.

Physical memory is \emph{physical}, i.e., it consists of hardware
circuits that must be produced, bought and installed on the main board
of the computer.  Virtual memory can be created and destroyed on
demand. This is its main distinguishing feature from physical memory.
Virtual memory is \emph{virtual}, i.e., it is a construct which exists
only in software. A computer can have much more virtual memory than
physical memory. In such cases, a mechanism ``multiplexes'' the
available physical memory resources to possibly multiple virtual
memories.

In this chapter we will have a look at how virtual memory can be
implemented. We will look at the idea of address translation in
Section~\ref{sec:address:translation} and sketch the requirements for
virtual memory from a user's point of view in
Section~\ref{sec:virtual:memory:requirements}. We will then go through
the three historic stages of virtual memory development. In essence,
these stages reflect the increasing hardware support for virtual
memory in computer architecture. We start with approaches which have
to live without hardware support in
Section~\ref{sec:physical:memory}. These approaches basically organize
physical memory in a slightly more convenient way, but the
transparency of this mechanism is naturally limited. In
Section~\ref{sec:segment:based:virtual:memory} we investigate virtual
memory based on the concept of memory segments which are supported by
special segment registers in the CPU. Finally, in
Sections~\ref{sec:page:based:virtual:memory} and
\ref{sec:page:replacement} we discuss virtual memory implemented with
the help of an external \vindex{memory management unit} (MMU). This
approach is maybe the most common one and is also the approach chosen
in the implementation of \Ulix{} which is described in
Section~\ref{sec:paging:ulix}.


\section{Address Translation}
\label{sec:address:translation}

The term \emph{\vindex{address space}} refers to a space of
addressable units in a computer. Every computer based on the
Von-Neumann architecture has at least one (physical) address space.
Its size depends on the size of the address bus (see
Section~\ref{sec:von:neumann:architecture}). If the computer has 32
Bits on the address bus, the hardware can address $2^{32}$ distinct
units of memory. If one such unit is a Byte, the architecture supports
an address space of 4 Gbytes.

Having 32 Bits on the address bus, addresses are 32-Bit values between
\hexaddr{0000.0000} and \hexaddr{FFFF.FFFF}.  In physical memory, not all
addresses may be backed by real memory cicuits on the main
board. (Access to such an address usually causes a specific type of
interrupt on the CPU or returns an undefined value when it is accessed.)
If we view the physical address space of a computer it therefore
may have ``holes'' (see left side of Figure~\ref{fig:address:decoder}).

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/address-decoder.jpg}
  \caption{Logical view of physical address space (left) and address
    translation via address decoder logic (right).}
  \label{fig:address:decoder}
\end{figure}

But how does the machine ``know'' where memory circuits are and where
not? The hardware internally stores a mapping of parts of the address
space to memory circuits in the form of an \emph{\vindex{address
    decoder logic}}. This logic is a simple boolean circuit that
translates an address on the address bus into one-out-of-$n$
bits. This bit is used to select the particular memory circuit on the
main board via its \emph{\vindex{chip select}} pin. Only a circuit
with an enabled chip select pin will load or store data which travels
over the data bus. For example, if the address \hexaddr{0000.0000} is put
on the address bus, the logic enables (only) the memory chip that is
responsible for serving that address (see right side of
Figure~\ref{fig:address:decoder}).

Not only memory chips can be activated through such a logic. Also
external devices can be mapped into the physical address space.
Through this mechanism, they can provide their programming registers
just like normal memory cells which can be read and written by the CPU
using normal load and store commands. This is the basis for
\emph{\vindex{memory mapped I/O}} (see
Section~\ref{sec:memory:mapped:io}).

The effect of such an address decoder logic is that the mapping of
memory chips to physical address is literally \emph{hardwired} into
the system. This mapping cannot easily be changed. Therefore,
programming physical memory directly makes it necessary to know the
precise whereabouts of the structure of physical memory. This is only
advisable where the physical address space is rather small and
well-structured. In the old days with less memory, operating systems
like \vindex{MS-DOS} could afford to work directly on physical memory:
Their programming manuals contained detailed accounts of where RAM and
ROM were placed in the physical address space. With today's 32 or 64
Bit desktop systems this is not advisable anymore. It is far better to
use a homogeneous \emph{virtual} address space which is independent of
the precise placing of memory chips in the physical address space.
This can be achieved through an \emph{\vindex{address translation}}
step performed before the address decoder logic kicks in.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/address-translation.jpg}
  \caption{Address translation for virtual memory.}
  \label{fig:address:translation}
\end{figure}

Address translation needs some form of hardware support. The idea is
depicted in Figure~\ref{fig:address:translation}: The virtual address
put on the address bus is taken and translated by the hardware using
some translation table to a physical address which is fed into the
decoder logic to select the right memory chip. This translation
required additional hardware/software effort. But from general experience
this pays off quickly given the simplicity and homogenity of the virtual 
address space. Program execution can now be performed entirely in the
virtual space. An additional advantage is that the address translation
is flexible: It can be redefined in \emph{software}.




\section{Virtual Memory Requirements}
\label{sec:virtual:memory:requirements}

A \emph{\vindex{virtual memory}} is a homogeneous sequence of memory
cells together with their content. A virtual memory can be regarded as
a ``well-behaved'' address space with its content.  The homogeniety is
what makes the address space nice: All memory cells are considered to
return well-defined values. So in contrast to physical memory there
are no ``undefined'' regions of storage in a virtual memory.



\subsection{Types of Data}


A virtual memory completely defines the memory context of a running
application. This means that it has to provide all necessary data for
executing the program. Three types of data are commonly distinguished:
%
\begin{enumerate}

\item Program code\pindex{program code}\pindex{code region} (also
  called \emph{\vindex{text}}). This refers to all instructions to be
  executed by the CPU.

\item Data.\pindex{data region} This refers to the contents of all
  variables used by the program.

\item Stack.\pindex{stack region} This refers to data used to manage
  subroutine calls (see Section~\ref{sec:stack}).

\end{enumerate}
%
Usually these different types of data are collected and stored in
different regions of the virtual memory.

The data region is further separated into two areas. The first area is
for \emph{\vindex{static data}}. Static data are variables and data
structures which are known at compile time of a program and exist
throughout the execution of the program. Examples of static data are
global variables. The second area is for \emph{\vindex{dynamic data}}
which is usually called the \emph{\vindex{heap}}. The heap holds
variables which are dynamically allocated at runtime by the program
(e.g., using [[malloc]] in C or [[new]] in C++ or Java). Data 
on the heap usually depends on program parameters which are only known
at runtime.

For completeness we note that a certain form of dynamic data is also
stored on the stack. Compilers often generate code that stores local
variables of subroutines on the stack. This is especially noteworthy
for recursive functions. Also, parameters are often passed to
subroutines via the stack.

\subsection{Address Space Organization}
\label{sec:address:space:organization}

From a user's point of view we would like to organize virtual memory
in a clear and tidy way. In practice, text, stack and data areas are
located in virtual memory in a fixed order (see
Figure~\ref{fig:address:space:organization}). Starting at address 0 we
find the text area with all program code followed by static
data. These areas are both fixed in size throughout the lifetime of
the program. The remaining part of virtual memory is divided up
between the more dynamic parts: heap and stack. The heap is usually
placed right behind static data at the ``lower'' end of the free
space. The stack is located on the opposite side. Note that while the
heap grows in an intuitive way towards rising addresses, the stack
grows rather unintuitively into the direction of falling addresses
(see also Section~\ref{sec:stack}). In this way, the free space
between heap and stack is utilized in the most effective way since any
memory cell can either be used by the stack or by the heap.  Imagine
the alternative where the stack would have been placed ``half way'' up
the virtual memory just to allow it to grow in the direction of rising
addresses. In such a case, the free memory cells could only be used by
either stack \emph{or} heap.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/address-space-organization.jpg}
  \caption{Organization of the virtual address space.}
  \label{fig:address:space:organization}
\end{figure}

As we see later in Chapter~\ref{chap:threads}, it may be necessary to
provide multiple stacks in virtual memory (for the same program).
In such a case we try to utilize the virtual memory as efficiently
as possible by dividing up the remaining space into equal parts for
each stack. This maximizes the distance between each stack. 

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/address-space-organization-multiple-stacks.jpg}
  \caption{Organization of the virtual address space with multiple stacks.}
  \label{fig:address:space:organization:multiple:stacks}
\end{figure}

Looking at Figure~\ref{fig:address:space:organization} and especially
Figure~\ref{fig:address:space:organization:multiple:stacks}
immediately shows a problem which arises with this memory layout:
Dynamic data areas can grow to such an extent that they collide with
others. In normal circumstances (i.e., one heap and one stack) this is
not a problem because the free space between them is very large.  As
an example, consider the classic 4 Gbytes of virtual memory, a 20 Mbyte
program (text and data) and initially empty stack and heap. The gap
which opens up between them has a size of 4076 Mbyte. This is quite
some memory to allocate in heap and stack. Of course, the probability
that heap and stack collide multiplies with the number of stacks.  If
a collision is not avoided it usually causes strange and hard to track
down runtime errors. As we will see later, it is possible to
effectively protect from such collisions with hardware support.

\subsection{Amount of Useable Virtual Memory}
\label{sec:useable:virtual:memory}

Without any additional help, the amount of effectively useable virtual
memory cannot be larger than the amount of physical memory installed
in the computer. Fortunately, most programs do not really use a lot of
the available virtual memory so that you don't always have to equip
your system with a full (e.g., 4 Gbytes) of main memory. However, using
some tricks it is possible to ``simulate'' more physical memory using
secondary storage. The details of this mechanism will become clear
later when we discuss paged-based virtual memory. The main idea
however is to add special information to the translation table and use
main memory as a \emph{cache} for secondary storage. If a part of
virtual memory is not in the cache, program execution is interrupted,
the missing data is brought into the cache, and the program resumes
operation thereafter. Note that if something is brought in to main
memory in this process, other information may have to be written out
of the cache, i.e., from main memory to secondary storage. This
performance overhead is the price you have to pay. The advantage of
this scheme is that secondary storage hardware is much cheaper than
main memory chips. In well designed systems it is possible to
simulate a substantial amount of main memory using secondary storage
without much performance overhead.


\subsection{Address Space Fragmentation}

\begin{work}
  Ch 4, slide 17--20
\end{work}

\subsection{Protection of Code, Data and Stack}
\label{sec:protection:of:code:data:stack}

\begin{work}
  Zugriffskontext definiert den Inhalt einer Speicherzelle.
  Oft werden Instruktionen in anderer Phase geholt als Daten.
  Die Phase im instruction cycle definiert also die art der
  Daten.

  Ch 4, slide 21
\end{work}

\subsection{Summary of Requirements}
\label{sec:virtual:memory:requirements}

To summarize, here are the main requirements we have for virtual
memory from a user's perspective:
% 
\begin{itemize}

\item Virtual memory should provide a homogeneous address space.

\item The size of virtual memory should be independent of the size of
  physical memory in the system.

\item Virtual memory should be able to protect different types of
  data from certain forms of access (e.g., text from being written).

\item Collisions of heap and stack should be detected and avoided
  whenever possible.

\end{itemize}
%
If the system provides multiple virtual memories (one for each
program), then we have the additional requirements:
%
\begin{itemize}

\item Virtual memories should be protected from one another, i.e., a
  program running in one address space should not be able to access
  the other address space and vice versa.

\item The physical resources of the system should be distributed in a
  fair manner between the existing virtual memories.

\item Physical memory should be used efficiently. Especially any type
  of fragmentation should be avoided.

\end{itemize}

As a glimpse on to the implementation of the above requirements we
return to the idea of a translation table which was previously
discussed in Section~\ref{sec:address:translation}, this time with
some more details. Figure~\ref{fig:translation:table} depicts the idea
of a translation table with the additional information necessary to
implement all above requirements. The table not only holds information
about the physical address which belongs to the virtual address. It
also contains flags that indicate access restrictions (like read,
write, execute) as well as pointers to secondary storage should this
memory location be stored there. Note that the figure only gives a
schematic view which is very simplistic, even impossible to realize.
After all, the translation table must somehow fit into (physical) main
memory to be useable. If we need one (physical) memory cell (at least)
to store the translation information for every (virtual) memory cell,
we could never simulate more virtual memory than we have physical
memory available. The main challenge therefore lies in implementing
this concept in a way sich that the usage of memory as well as the
translation time is minimized.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/translation-table.jpg}
  \caption{Schematic view of a refined translation table for virtual memory.}
  \label{fig:translation:table}
\end{figure}



\section{Physical (Non-Virtual) Memory}
\label{sec:physical:memory}

\begin{work}
  Ch 4, slides 25--32
\end{work}


\section{Segment-based Virtual Memory}
\label{sec:segment:based:virtual:memory}

\begin{work}
  Ch 4, slides 34--43
\end{work}


\section{Page-based Virtual Memory}
\label{sec:page:based:virtual:memory}

\begin{work}
  Intro from Chy 4, slide 45
\end{work}

\subsection{Pages and Page Frames}

In page-based virtual memory the virtual address space is divided into
a sequence of memory ``chunks'' of equal size called
\emph{pages}.\vindex{page} Similarly, the physical memory is divided
into a set of chunks called \emph{page frames} (or simply
\emph{frames})\pindex{frame}\pindex{page frame} As we will see, page
frames will be ``containers'' for pages and therefore both have the
same size. The mapping between pages and page frames is dynamic and
defined via a table in stored in main memory (see
Figure~\ref{fig:pages:and:page:frames}).

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/pages-and-page-frames.jpg}
  \caption{Pages and page frames.}
  \label{fig:pages:and:page:frames}
\end{figure}

Allthough page frames and pages have the same size, they are totally
different concepts. A page is a logical unit of virtual memory. Any
virtual address resides in some page. A frame is a concrete area of
physical memory waiting to hold some page. A large part of physical
memory will consist of frames, i.e., will be devoted to store
pages. But not \emph{all} physical memory is part of some frame.


\subsection{Hardware Support}

In contrast to segment-based virtual memory, page-based virtual memory
needs no hardware support on the CPU, i.e., no special registers. This
means that this type of virtual memory can (at least in principle) be
implemented with any CPU on the market. In a sense, the hardware
support is ``outsourced'' to a dedicated device called the
\emph{\vindex{memory management unit}} (MMU)\pindex{MMU (memory
  management unit)}.

The MMU can be thought of as a hardware address translator that sits
on the address bus and divides it into two parts. One part between the
CPU and the MMU is considered the ``virtual address'' part of the
address bus, the other (between MMU and main memory) is the ``physical
address'' part. When the CPU issues a virtual address on to the
address bus, the MMU transparently translates it into a physical
address on the other side, i.e., it changes the value of the
bits as the address passes through the MMU from one to the
other side.

To tell the truth, the MMU doesn't change \emph{all} the address bus
bits, only the higher oder bits. The $k$ lower order bits remain
unchanged. The value $d$ represented by the $k$ lower order bits is
called the \emph{\vindex{offset}} of the address (see
Figure~\ref{fig:virtual:address}). The idea of this separation is the
following: The higher order bits of the virtual address implicitly
refer to the \emph{page} that the virtual address is located in. The
$k$ lower order bits then are interpreted as the \emph{offset} of the
address within the page, i.e., the distance from the beginning of the
page to the address.


\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/virtual-address.jpg}
  \caption{Structure of virtual address.}
  \label{fig:virtual:address}
\end{figure}

The interpretation of the address in page number and offset has
several consequences. The main one is that the size of a page must be
a power of 2. If the $k$ lower order bits represent the offset within
a page, the number of addresses in a page is exactly $2^k$. For a
value of $k=10$, a page would contain exactly $2^{10}=1024$ Bytes.
The value of $k=10$ is a typical value in practice where there are 32
bits on the address bus. This case is depicted in
Figure~\ref{fig:virtual:address:k10}. It shows that the $k$ lower
order bits (those with index 0 to 9) define the offset $d$ and the
remaining $32-10=22$ bits (with indexes 10 to 31) define the page
number $p$.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/virtual-address-k10.jpg}
  \caption{Virtual address example with $k=10$.}
  \label{fig:virtual:address:k10}
\end{figure}


\subsection{Page Descriptors and Address Translation}
\label{sec:page:descriptors}

The central data structure to manage pages in virtual memory is the
\emph{\vindex{page descriptor}}. There is exactly one page descriptor
per page in virtual memory. All page descriptors are held within the
operating system in a big internal table called the \emph{\vindex{page
    table}}. The page descriptor contains all information necessary to
locate the contents of the (virtual) page in physical memory,
therefore knowledge of the starting address of the page table is the
key to performing address translation. So to enable address
translation, the \vindex{page table register} [[PTR]] of the MMU is
pointed to that starting address (see
Figure~\ref{fig:address:translation:using:page:descriptors}). Assuming
that there is just one big table, the MMU can now directly locate the
page descriptor of page $p$ by doing a small address calculation:
Given the size of a page descriptor to be $P$ bytes, then the page
descriptor of page $p$ has the address:
%
$$[[PTR]] + p\cdot P$$

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/address-translation-using-page-descriptors.jpg}
  \caption{Address translation using page descriptors.}
  \label{fig:address:translation:using:page:descriptors}
\end{figure}

As mentioned above, a page descriptor is a data structure that holds
all necessary information to manage the associated virtual page.  Here
is an overview over the types of information that can be stored in a
page descriptor of page $p$:
%
\begin{itemize}

\item Since the page descriptor is used to perform address
  translation, it must contain a pointer to the \emph{physical} page
  frame of page $p$. The MMU adds the offset of the virtual address to
  this pointer to yield the actual physical address of the virtual
  address in question.

\item Since page frames act as a \emph{\vindex{cache}} for the
  contents of pages, certain management bits must be present to handle
  cache contents. Recall that main memory is regarded as a cache for
  pages stored on secondary storage (see
  Section~\ref{sec:useable:virtual:memory}). The first such bit is the
  \emph{\vindex{presence bit}} (P bit)\pindex{P bit (presence
    bit)}. The P bit indicates whether or not the page contents are
  present in main memory or not.

\item The next management bit is the \emph{\vindex{reference bit}} (R
  bit)\pindex{R bit (reference bit)}. Roughly speaking, it indicates
  whether or not the page descriptor was referenced within some period
  of time or not. The R bit is set by the MMU with every access to the
  page descriptor in main memory. Technically speaking, the reference
  bit is not actually an essential management bit of the cache, but
  rather a bit which is used to optimize the cache performance. This
  will be discussed later in Section~\ref{sec:page:replacement}.

\item A vital cache management bit is the \emph{\vindex{dirty bit}} (D
  bit)\pindex{D bit (dirty bit)}, sometimes called
  \emph{\vindex{written bit}}. It is set by the MMU whenever the
  contents of page $p$ are written. The D bit is important since it
  solves the \emph{\vindex{cache coherence problem}}: Contents of the
  cache (i.e., main memory) and secondary storage can diverge if main
  memory is written and secondary storage not (due to performance
  reasons). The D bit indicates exactly when this divergence exists.
  Pages which have diverged in main memory eventually have to be made
  coherent with secondary storage again.

\item The page descriptor also contains \emph{\vindex{protection
      bits}} used to manage the type of access allowed to this
  page. 

  \begin{work}
    Refer to Section~\ref{sec:protection:of:code:data:stack}.  It will
    become clear later how this can be used
  \end{work}

\item The page descriptor usually also contains several multi purpose
  bits which can be used by the operating system for different means.

\end{itemize}

Ignoring protection and multi purpose bits, this is what a page
descriptor could look like in code:

<<tentative declaration of page descriptor>>=
typedef struct page_desc_struct {
  void* frame_addr;     // address of page frame for this page
  uint present : 1;     // presence bit
  uint referenced : 1;  // reference bit
  uint written : 1;     // dirty bit
} page_desc;
@

To summarize, we now recall how a successful page translation finally
happens (see Figure~\ref{fig:successfull-page-translation}): 
%
\begin{enumerate}

\item The CPU accesses a virtual address $v$ on the address bus. The
  virtual address consists of a page address $p$ and an offset $d$ in
  the page.

\item The MMU uses the page number $p$ and the base address of the
  page table (stored in [[PTR]]) to locate the page descriptor of the
  page.

\item Using the page frame address $k$ stored in the page descriptor,
  the MMU adds the offset $d$ to form the final physical address in
  main memory.

\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/successfull-page-translation.jpg}
  \caption{Successfull page translation.}
  \label{fig:successfull:page:translation}
\end{figure}

What can potentially go wrong during page translation? The simplest
error condition is that the virtual memory location doesn't (yet)
exist in physical memory. This means that the page table doesn't know
where it should point to. This information is encoded in a special
\emph{\vindex{null page descriptor}}. If the MMU tries to translate an
address and finds such a null page descriptor in the page table it
signals an interrupt to the CPU which must be handled immediately.

The next error condition concerns the protection bits. The MMU checks
whether the current access context is allowed by the protection bits.
For example, if the CPU wants to write something to a virtual address
and the protection bits don't allow write access, then again the MMU
raises an interrupt with the CPU.

The final error condition which we discuss here refers to the fact
that main memory is just a cache for secondary storage: a
\emph{\vindex{cache miss}} may happen. What is a cache miss in this
context? It means that the page accessed by the current instruction
exists but it currently isn't in main memory (the cache). This is
indicated by the \vindex{presence bit} (\vindex{P bit}) in the
page descriptor. If the P bit is not set, an interrupt is raised
by the CPU. In effect the interrupt handler must try and load
the page contents back in to main memory so that the application
that wished to access the page contents can continue to operate.
More details on how this works will follow later.



\subsection{Page Descriptor Trees}
\label{sec:page:descriptor:trees}

In contrast to the naive page translation described at the end of
Section~\ref{sec:virtual:memory:requirements} where we had one entry
in the page table per virtual address, the idea of pages reduces the
size of the page table dramatically. The larger the page size, the
smaller the page table because translation information and protection
bits etc.~are stored per page. However, page tables still have
considerable size. The problem is partly a result of the memory layout
sketched in Section~\ref{sec:address:space:organization} because code,
data and heap reside on one end of virtual memory and the stack on the
other end. This means the page table must \emph{always} cover
\emph{all} pages in virtual memory. As an example, imagine you have 8
Byte per page descriptor (which is not much), a 12 bit offset for
pages (giving a page size of 4 kbyte, rather large), and a 32 bit
address bus. In total you have $2^{20}$ entries in the page table,
each is 8 Bytes, yielding a page table size of 8 Mbyte. Small computer
systems with only 16 or 64 Mbyte physical memory could only hold
one or two page tables (at most), given the fact that additionally
the \emph{contents} of pages also must be stored in main memory.

Given the fact that most programs have a large void space in virtual
memory between heap and stack, there is much potential to save
storage space here. Recall the example we discussed in
Section~\ref{sec:address:space:organization} where a program
of 20 Mbytes had a gap of almost 4 Gbytes in virtual memory.
If a page had the size of 1 kByte, then this program would need
``only'' 2000 entries (out of $2^{20}$), meaning that more than
99,5\% of the page table is not used.

The common solution employed in operating systems is to have
\emph{\vindex{hierarchic page tables}} or \emph{\vindex{page
    descriptor trees}}. A single page table is regarded as a special
case of a hierarchic page table. Each entry in the page table is
either a page descriptor or a pointer to another page table.

The idea is to start with a small page table (i.e., a page table with
a small number of entries). Each such entry is responsible for
covering a relatively large part of the virtual address space. Each
entry can be refined by another page table in a similar way. For
example in Figure~\ref{fig:multi:level:page:table}, virtual memory has
16 addresses. The first level page table has four entries. Each entry
is responsible for handling a quarter of the entire virtual address
space, i.e., 4 addresses.  An entry at the first level then points to
a second level page table with again four entries but which deals with
the details of address translation. In this example already you can
see that a full (single level) page table would have needed 16 page
descriptors. In the hierarchic version we need only three small tables
with four entries each, i.e., 12 page descriptors alltogether.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/multi-level-page-table.jpg}
  \caption{Example of a multi-level page table.}
  \label{fig:multi:level:page:table}
\end{figure}

\subsubsection{Page Descriptors and Page Table Descriptors}

In general, a hierarchic page table is a tree of
descriptors. Descriptors can be of two forms: 
%
\begin{itemize}

\item \emph{Page descriptors}\pindex{page descriptor} (PD)\pindex{PD
    (page descriptor)} are the ``leaves'' of the tree. They are page
  descriptors in their original sense, including information about the
  location of the page frame and protection bits.

\item \emph{Page table descriptors}\pindex{page table descriptor}
  (PTD)\pindex{PTD (page table descriptor)} are the ``inner nodes'' of
  the tree. They basically are pointers to descriptors (either page
  descriptors or page table descriptors).

\end{itemize}
%
The resulting tree-like structure is visualized in
Figure~\ref{fig:tree:structure:of:descriptors}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/tree-structure-of-descriptors.jpg}
  \caption{Tree structure of descriptors.}
  \label{fig:tree:structure:of:descriptors}
\end{figure}

Since we know what is part of a page descriptor already (see
Section~\ref{sec:page:descriptors}), what is part of a page table
descriptor? Generally we can find these entries:
%
\begin{itemize}
\item A flag indicating the \emph{type} of the descriptor, i.e., 
  is it a page descriptor or a page table descriptor. In fact, also
  every page descriptor needs this field.

\item The address of the page table which this page table descriptor
  points to.

\item In case it is not clear from the hardware architecture, a page
  table descriptor may also store the \emph{size} of the page table.
  This is analogous to the size of a segment in segment-based virtual
  memory.

\item A \emph{\vindex{presence bit}} (P bit)\index{P bit (presence
    bit)} which indicates whether the page table pointed to by the
  descriptor is in main memory or not. This indicates that also page
  tables can themselves be paged out into secondary storage. We will get back
  to the problems this may cause later in
  Section~\ref{sec:paging:ulix}.

\item Multi purpose bits, just like in a page descriptor.

\end{itemize}



\subsubsection{Structure of a Virtual Address}
\label{sec:structure:of:virtual:address}

In a hierarchic page table, the virtual address is used in a special
way to traverse the tree of descriptors. If there are $L$ levels in
the page descriptor tree, the $p$ bits of the page address within a
virtual address are subivided into $L$ parts $p_1,p_2,\ldots,p_L$ such
that 
%
$$p=p_1+p_2+\ldots+p_L.$$
%
The address translation starts with the leftmost (highest order)
bits. Briefly spoken, the first $p_1$ bits are an index into the first
level page table, the next $p_2$ bits an index into the second level
page table and so on. Therefore the number of bits per level
determines the size of the page table at that level. 

As an example, consider the division of $p$ into parts in
Figure~\ref{fig:virtual:address:structure}. The first $p_1=7$ bits
allow a first level table size of $2^7=128$ entries. In a 32 bit
system, each entry covers an area of 32 Mbytes. The second level
$p_2=7$ bits handle again 128 entries, each of them now covering 256
kByte. Finally, the third level $p_3=7$ bits are an index into a page
table with 128 entries, each entry finally covering a full page of
2kByte (11 bits remain for the offset). As in this example, it is
common to have two or three distinct levels in the page descriptor
tree of a virtual address space.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/virtual-address-structure.jpg}
  \caption{Example structure of a multi-level virtual address.}
  \label{fig:virtual:address:structure}
\end{figure}

\subsubsection{Multi-Level Address Translation}

We now discuss several examples of how address translation works using
hierarchic page tables. The first example is depicted in
Figure~\ref{fig:two:level:address:translation}. It shows a two-level
descriptor tree. How does the MMU perform address translation here?
It starts with the ``root'' page table, pointed to by the MMU register
[[PTR]]. This is the first level page table. The MMU takes the first
part $p_1$ of the virtual address as an index into this table where it
finds a page table descriptor. This points to the relevant second
level page table. Within this page table, the second part $p_2$ of the
virtual address is used as an index.  Since we are at the highest
level of the tree, the descriptor at index $p_2$ in the second level
page table is a real page descriptor allowing to perform the address
translation into a physical address.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/two-level-address-translation.jpg}
  \caption{Address translation using a two-level page descriptor tree.}
  \label{fig:two:level:address:translation}
\end{figure}

In the next example, which is depicted in
Figure~\ref{fig:two:level:address:translation:extended}, we discuss a
possible but rather uncommon variant of the two-level example. Here,
the notion of a tree is taken literally. In a tree, not all leaves are
at the same level. Leaves (i.e., page descriptors) can already reside
at lower levels, not necessarily all at the topmost level (in this
case level two). In such cases, you have to be careful though how to
interpret the contents of the page descriptor. The example shows again
a two-level virtual address, however, in a page descriptor is located
already at level one of the descriptor tree. In such cases, the
remaining bits of the virtual address are interpreted as offset (here
the rightmost $p_2+d$ bits). Correspondingly, the ``page'' pointed to
by the page descriptor is much larger than if it were located at level
two. In fact, it points to an array of $2^{p_2}$ consecutive
``level-two'' page frames in physical memory. Recall again that the
final $p_2+d$ bits of the virtual address are interpreted as
offset. Note that this is also the reason why the beginning of this
physical memory area must be aligned specially in physical memory.
Both the alignment and the large amount of consecutive physical memory
complicate the handling of such cases in real systems. This is why
this case is rather uncommon.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/two-level-address-translation-extended.jpg}
  \caption{Address translation using a two-level page descriptor tree
    and a page descriptor at level 1.}
  \label{fig:two:level:address:translation:extended}
\end{figure}

The examples above can easily be extended to three-level page
descriptor trees. As an example consider
Figure~\ref{fig:three:level:address:translation}. In contrast to the
first example, the level two page table does not pint to the page
frame but to a level three page table. The virtual address has a third
part $p_3$ which is used as an index into this table where we find the
page descriptor finally pointing to the page frame. 

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/three-level-address-translation.jpg}
  \caption{Address translation using a three-level page descriptor tree.}
  \label{fig:three:level:address:translation}
\end{figure}

We can save a little storage space in the descriptor
if its type is clear from the context. For example, the \Ulix{} MMU
assumes a three-level descriptor tree. Any descriptor found at level
one or two is automatically a page table descriptor. All other descriptors
(i.e., those at level three) must be page descriptors. Note that in
the setting of \Ulix{} hardware the second example from above does
not work.

\subsubsection{Discussion}

The advantage of hierarchic page tables is their potential to save
significantly on main memory. Unused parts of virtual address
spaces can be ``removed'' from the page table using \emph{\vindex{null
    page descriptors}}. A null descriptor is a special descriptor
indicating that the virtual memory at this location is void or unused.
Usually it is encoded by a special flag or value in a field of the
descriptor (either page descriptor or page table descriptor).
By placing a null descriptor into the descriptor tree,
all pages below this descriptor are effectively removed from
virtual memory. The lower the level of the null descriptor, the
larger the part of virtual memory which is mapped out.

To see how effectively null descriptors can be used, we reconsider the
example we introduced in Section~\ref{sec:address:space:organization}
and revisited in Section~\ref{sec:page:descriptor:trees}: The classic
organization of virtual memory with a 20 Mbyte program, an empty heap
and an empty stack. Recall that a single page table would need roughly
8 Mbytes of main memory. Using hierarchic page tables and null
descriptors we can reduce the amount of necessary storage to 5 Kbytes,
as is shown in Figure~\ref{fig:using:null:descriptors}. Here the example
is simplified to the situation where the program has no code and
data pages to show the effect more clearly. Remember that
on each level of the descriptor tree we had 128 entries per table,
each entry having 8 bytes. This means each table has a size of 1
kbyte.  By placing null descriptors in all places which point to empty
virtual memory, we end up with page tables only for those parts of the
system which really exist. Since the \Ulix{} hardware places page
descriptors only on level three, we need to extend the descriptor
tree up to level three for the two page descriptors necessary
to point to heap and stack. If you count the number of page tables,
you end with 5. Hence we need only 5 kbytes instead of 8 Mbytes.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/use-of-null-descriptors.jpg}
  \caption{Saving main memory using null descriptors in hierarchic page tables.}
  \label{fig:using:null:descriptors}
\end{figure}

The disadvantage of a multi-level page tables is that address translation
takes slightly longer. This is because the MMU has to traverse the
tree (i.e., follow the pointers) when doing the address translation.
A multi-level page table needs one main memory lookup per level,
which takes longer than a single memory lookup if there were only
a single page table. The memory savings however usually outweigh the
performance drawback. Furthermore, performance can still be in the
range of a single memory lookup (or less) by using caching, as
we explain in the following section.


\subsection{Transfer Lookaside Buffer}

\begin{work}
  Ch 4, slides 63, 64, 65, 67
\end{work}

\subsection{Summary}

\begin{work}
  Ch 4, slide 70
\end{work}

\section{Page Replacement Algorithms}
\label{sec:page:replacement}


\subsection{Main Memory as Cache}

Page-based virtual memory has one main advantage: paging the
information in and out of main memory is extremely simple because of
the fixed size data chunks. Ideally these chunks have the same size as
the data blocks on secondary storage. Then main memory can be regarded
as a \emph{\vindex{cache}} for secondary storage and all the
corresponding techniques can be used (see
Section~\ref{sec:useable:virtual:memory}). 

Roughly speaking, the cache is implemented using the \vindex{presence
  bit} in the page descriptors. If the presence bit is set, the page
contents are ``paged in'' and available for access. In other contexts,
this is called a \emph{\vindex{cache hit}}. If the presence bit is not
set, then the data must be fetched from secondary storage (this
corresponds to a \emph{\vindex{cache miss}}). In such cases, the MMU
generates a \vindex{page fault}. The \vindex{page fault handler} then
does the fetching. Of course, the page fault handler has to know what
page to load into what page frage. This must be communicated by the
MMU. This can be done by placing information on the system stack for
example or putting it into well-known registers on the CPU.

Access to secondary storage is very slow, while access to main memory
is rather fast. At time of writing, good hard disks has an average
access time of about 8 milliseconds, main memory of about 8
nanoseconds. This is a difference of $10^6$, i.e., 6 orders of
magnitude. To make this huge difference more evident, assume that
access to main memory needs one \emph{second}. Then the access to
secondary storage would have to take $10^6$ seconds, which is roughly
11,5 days, to stay in the same relation.

Well-tuned main memory caches can achieve a performance which is very
close to the speed of main memory. The decisive parameter is the
probability $p$ of not finding the requested information in the cache
(i.e., the probability of a page fault).  Given that $t_{mm}$ is the
time necessary to access main memory and $t_{pf}$ the time to handle a
page fault, the average time $t_{vm}$ to access virtual memory using
main memory as a cache is:
%
$$t_{vm} = (1-p)\cdot t_{mm} + p\cdot t_{pf}$$
%
Since $t_{pf}$ is dominated by the access time to secondary storage,
we need to keep $p$ as low as possible.

There are couple of good strategies to keep the page fault rate
low. The first is to \emph{avoid} page faults as much as possible.
This is possible by using effective page replacement strategies
and by using techniques like \emph{\vindex{pre-paging}} explained
later. Clearly it is not (always) necessary to write back frame
contents if they have not been written which also saves on 
accesses to secondary storage. Finally, if there are multiple
types of secondary storage devices, it makes sense to use the
fastest one for the paging mechanism.


\subsection{Page Locking}

Page replacement is a good idea, but some pages must sometimes be
protected from being paged out. For example, certain parts of the
operating system are so critical that they should never be paged out
to secondary storage. The most striking example is the code that
contain the interrupt handlers. If a page fault occurs and the code
for the page fault handler is not be present, then we are be in big
trouble. Also, most parts of the page tables for the kernel
should always be present, as well as pages that are located
in special frames for \vindex{memory-mapped I/O}. In such cases
the pages should be \emph{locked} into their frames and page
replacement algorithms should ignore these pages.

Another case where \vindex{page locking} makes sense is
\emph{\vindex{I/O locking}}. If the contents of a frame are currently
paged out using asynchronous I/O, then the page should remain locked
into the frame so that no inconsistencies occur.



\subsection{Reference String and Working Set}

\begin{work}
  Ch 4, slide 77, 78, 79
\end{work}

\subsection{Optimal Page Replacement}

\begin{work}
  Ch 4, slide 80, 81
\end{work}

\subsection{FIFO}

\begin{work}
  Ch 4, slide 82
\end{work}


\subsection{Second Chance}

\begin{work}
  Ch 4, slide 86
\end{work}

\subsection{Clock Algorithm}

\begin{work}
  Ch 4, slide 87, 88
\end{work}

\subsection{LRU}

\begin{work}
  Ch 4, slide 83, 84, 85
\end{work}


\subsection{Demand-Paging and Pre-Paging}

\begin{work}
  Ch 4, 89
\end{work}

\subsection{Thrashing}

\begin{work}
  Ch 4, 90, 91, 92
\end{work}

\subsection{Swapping}
\label{sec:swapping}

\begin{work}
  Ch 4, slide 94
\end{work}




\codesection{Page-based Virtual Memory in \Ulix{}}
\label{sec:paging:ulix}

In the previous sections we have described how a single virtual
address space is managed for a single process. \Ulix{} can handle
multiple virtual address spaces simultaneously, one per running process.
In this section we discuss in detail how this is implemented.


\black


\subsection{Paging on the Intel Architecture}

Since we implement \Ulix{}-i386 for Intel chips, we need to have a 
look at the Intel architecture which uses a two-layer design.

When paging is active, register {\tt CR3} (control register 3) points to
a page directory which is a collection of 1024 page directory entries.
Each of those entries is 4 bytes large, so the whole page directory
has a size of 4 KByte (one page).

Each page directory entry points to a page table (its address is given
via bits 31..12).

Page tables have the same size as page directories (4 KByte), and they
also hold 1024 entries, the page table entries. Such an entry points
to a frame (again using bits 31..12).

We will look at these data structures in detail in the following sections.
While---as an OS designer---you are free to implement many things in any
way you can conceive, the Intel processor expects page directories and
page tables to have a well-defined form that cannot be changed.


\green



\subsection{Design Principles}


Virtual memory in \Ulix{} is designed along the following principles:
%
\begin{itemize}

\item Every process will have its own virtual address space, i.e., an
  own page table (tree). Adress spaces of processes are protected from
  one another, i.e., it is not possible to access address space $a$
  from address space $b$ and vice versa.

\item Pages are stored in a set of page frames. Pages can be locked
  in physical memory. Locked pages cannot be paged out. 

\item Page replacement is done on a global basis, i.e., page
  replacement algorithms treat all frames in the same way irrespective
  of what pages reside in the frames (unless, of course, they are
  locked).

\item The kernel has its own virtual address space. The virtual address
  space of every process is accessible from the virtual address space of
  the kernel. (For details, see below.)

\end{itemize}


\subsubsection{Main Memory as a Cache}

The best way to think about physical memory in \Ulix{} is that most of
it is simply a \emph{cache} for physical memory. This idea is depicted
in Figure~\ref{fig:physical:memory:as:cache}: The entire physical
memory is being divided into equal size page frames. These can be
potentially filled with pages.  Page replacement is done on a global
basis so all pages in virtual memory are equal candidates for page
frames in physical memory (even some of the pages of the
kernel). There are three notable exceptions however.

Firstly and as will become clear later in Chapter~\ref{chap:threads},
certain parts of kernel code and data cannot be paged out because they
are so vital for correct execution (imagine for example important
parts of the code responsible for paging data into main memory being
paged out). These pages must be permanently locked down in
memory\pindex{I/O locking}\pindex{locked pages} and excluded from page
replacement considerations. Secondly, not the entire physical memory
is freely useable. Parts of the RAM hold interrupt vectors or are used
for \vindex{memory-mapped I/O} (see
Chapter~\ref{chap:hardware}). These pages also must be locked down
permanently.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/physical-memory-as-cache.jpg}
  \caption{Physical memory as cache for multiple virtual address
    spaces. Pages can be locked down in page frames for several
    reasons.}
  \label{fig:physical:memory:as:cache}
\end{figure}

The third reason, why certain pages must be excluded from page
replacement is more intricate and will become clear during the
following implementation. Roughly speaking, a page must be locked
while it is ``in transfer'', i.e., while it is fetched from or written
to secondary storage with \vindex{DMA}. Locking here is simply a
synchronization requirement since DMA happens concurrently to the
execution of the kernel. In contrast to the first two reasons, this
type of locking however is only temporary.


\subsubsection{Outline}

The remaining code parts basically implement a cache with a locking
mechanism. We will also provide functions to create and manage virtual
address spaces which can be called at a higher level by the thread
handling routines discussed in the next chapter.  Finally we will look
at the bootstrapping and initialization mechanisms in \Ulix{}, which
are a little more intricate but also unnecessary if you want to
understand most of the code which follows now. It suffices to assume
that main memory has been nicely set up, secondary storage holds all
important information ready to be accessed, important pages are locked
and the rest of the frames are free to use in our caching application
called virtual memory.



\subsection{Address Space Descriptors in \Ulix{}}
\label{sec:address:space:descriptors}

Every address space has an \emph{\vindex{address space descriptor}},
a compact representation of the most important information about
the virtual address space. We define the [[addr_space_descr]]
structure as a container for this information.

<<kernel declarations>>=
typedef struct {
} addr_space_descr;

@ 

\subsection{Address Space Table}
\label{sec:address:space:table}

Address space descriptors are stored in one large
\emph{\vindex{address space table}}. This table must be finite,
i.e., there must exist a maximum number of address spaces for
the system. This must somehow correspond to the maximum number
of threads [[MAX_THREADS]] which will be defined later in
Chapter~\ref{chap:threads}. 

<<kernel declarations>>=
#define MAX_ADDR_SPACES 1024

@ Here's the actual address space table.

<<kernel declarations>>=
addr_space_descr addr_space_table[MAX_ADDR_SPACES];

@ As we will see later, every thread may have its own virtual address
space and needs to own a reference to an address space descriptor.
Even the kernel will have to do that.  Since there can be so many
address spaces, we need a shorthand to identify virtual address
spaces. We introduce the type [[addr_space_id]] to do this.  It is
declared as [[unsigned int]]. Basically, an [[addr_space_id]] can
be thought of as an index into the address space table. So rather
than storing a complete address space descriptor per thread, we
will rather store an address space identifier.

<<kernel declarations>>=
typedef uint addr_space_id;

@ 




\subsection{Page Descriptors in \Ulix{}}

We now define the structure [[page_desc]] for page descriptors.  The
structure follows the layout required \black
by the Intel CPU. Recall that it expects that the page table tree has exactly two
levels. Descriptors at level 2 are either null descriptors or page
descriptors. Descriptors at level 1 are either null descriptors
or page table descriptors.

Intel uses a different vocabulary: In the Intel terminology,

\begin{itemize}
\item a page descriptor is a \emph{page table entry} (within a page table), and
\item a page table descriptor is a \emph{page directory entry} (in a page directory).
\end{itemize}

Each entry (for both page tables and page directories) is four bytes
long; a page table or page directory contains 1024 such entries,
filling exactly one page (of size 4 KByte).

A virtual address is always split in three parts: the page table
number (bits 31--22), the page number (21--12), and the offset (11--0).

\begin{verbatim}
/---------------+------------+-----------\
| 31 ....... 22 | 21 .... 12 | 11 .... 0 |
|   page table  |    page    |   offset  |
\---------------+------------+-----------/
\end{verbatim}

Page table number and page number are similar to the general concept of
split page table numbers where each portion corresponds to some level
of page tables.

The system must associate a page directory with each process, the
start address of the page directory must be stored in the
process descriptor base register ({\tt PDBR}) (the upper 20 bits
of control register 3 ({\tt CR3}).

\includegraphics[width=14cm]{pics/X86_Paging_4K.png}

source: \url{http://en.wikipedia.org/wiki/Control_register}

20 bits are sufficient to store an address because pages are 
page-size-aligned, i.\,e., they all start at addresses with zeroes
in the lower 12 bits. (A page has size 4 KByte = $2^{12}$ bytes,
which is why the offset length is 12.)


%%% BEGIN LITERATE TEACHING %%%

\subsubsection{Page Table Entries}

The upper 20 bits of a page descriptor contain the upper bits of a
frame address (in RAM); the remaining bits of that address are zeroes
for the same alignment reason as already described above: In RAM,
no frame starts at an ``odd'' address which is not a multiple of the
page size. Thus the frame address can easily be extracted from the
page descriptor by setting the lower 12 bits to zero:

<<get frame address from page descriptor>>=
frame_address = page_descriptor & 0xFFFFF000;  
// F (hex) = 1111 (bin);  0 (hex) = 0000 (bin)
@

The remaining bits in the page descriptor are either unused and can be
used by the operating system for its own purposes (bits 9--11) or 
store attributes of this page descriptor:

\begin{itemize}
  \item Bits 8 and 7 must always be 0.
  \item Bit 6 holds the dirty flag.
  \item Bit 5 holds the accessed flag. It is automatically set by the MMU
    when this page is accessed.
  \item Bit 4 is called Page Cache Disabled (PCD) -- if set, data from
    this page must not be cached.
  \item Bit 3 is called Page Write Transparent (PWT), we will ignore
    this one and always set it to 0.
  \item Bit 2 holds the User Accessible (U) flag.
  \item Bit 1 holds the Writeable (W) flag.
  \item Bit 0 holds the Present (P) flag.
\end{itemize}

So we can now describe the page descriptor in C:

<<kernel declarations>>=
typedef struct {
  uint present         : 1;  //  0
  uint writeable       : 1;  //  1
  uint user_accessible : 1;  //  2
  uint pwt            :  1;  //  3
  uint pcd            :  1;  //  4
  uint accessed       :  1;  //  5
  uint dirty          :  1;  //  6
  uint zeroes         :  2;  //  8.. 7
  uint unused_bits    :  3;  // 11.. 9
  uint frame_addr     : 20;  // 31..12
} page_desc;
@

We immediately repeat the code for calculating the physical
address from this page descriptor, but now in a proper function
that we can use later:

<<kernel functions>>=
uint page_desc_2_frame_address (page_desc pd) {
  uint address;
  /* pointer magic/cast: a page descriptor is not really an unsigned  *
   * int, but we want to treat it as one                              */
  address = *(uint*)(&pd);
  return address & 0xFFFFF000;   // set lowest 12 bits to zero
}
@

The following function fills a page descriptor with values;
its address must be provided (the space must be reserved by
the caller):

<<kernel functions>>=
#define KMAP(pd,frame) fill_page_desc (pd, true, true, false, false, frame)
#define UMAP(pd,frame) fill_page_desc (pd, true, true, true,  false, frame)

page_desc* fill_page_desc (page_desc *pd, uint present,
                           uint writeable, uint user_accessible,
                           uint dirty, uint frame_addr) {
  // /--> pd: pointer to page descriptor <--/ //

  /*
  if (DEBUG) {
    kputs ("DEBUG: fill_page_desc:\n"); 
    kputs ("  vaddress: "); printhex ((uint)pd); putnl();
    kputs ("  frame:    "); printhex (frame_addr); putnl();

    if ((uint)pd==0x401000) {
      kputs ("WARNUNG! virtaddr. < 0xc0000000 \n");
    };
  };
  */
  
  // first fill the four bytes with zeros
  memset (pd, 0, sizeof(pd));
  
  // now enter the argument values in the right elements
  pd->present = present;
  pd->writeable = writeable;
  pd->user_accessible = user_accessible;
  pd->dirty = dirty;
  pd->frame_addr = frame_addr >> 12;   // right shift, 12 bits
    /* Note: This assumes that the frame address is well-formed, i.e., *
     * it has zeroes in its lowest 12 bits                             */
  return pd;
};
@

We have used the right shift operator \verb#>># in this function which
takes the 32 bits from the \verb#unsigned int# variable [[frame_addr]], 
right shifts them and fills the hole on the left side with zeroes.


To simplify life (and because we will often think ``I would like
to map page number x to frame number y'') we will add a function
that does just that: map a page to a frame:

<<kernel functions>>=
//
//
// THIS CODE DOES NOT WORK... WHY????
//
//


int map_page_to_frame (uint pageno, uint frameno) {
  int pdindex = pageno/1024;
  int ptindex = pageno%1024;
  if (! current_pd->ptds[pdindex].present) {
    // TODO: Pagetable nachladen/erzeugen, wenn nicht present!
    return false;
  } else {
    page_table* pt;
    // TODO:  Ummm, that's a pointer. Where's the memory for that page table?
    // 
    pt = (page_table*)(
      PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12)
    );
    // fill_page_desc ( &(pt->pds[ptindex]), true, true, true, false,
    //  frameno << 12 );
    KMAP ( &(pt->pds[ptindex]), frameno << 12 );
    return true;
  };
}
@

It works only if the page table exists. Its return value is
[[true]] if it was successful, [[false]] otherwise.



A page table contains 1024 page descriptors:

<<kernel declarations>>=
typedef struct {
   page_desc pds[1024];
} page_table;
@

We have to make this a {\tt struct} so that we can easily create a
pointer to such a page table.


%%% END LITERATE TEACHING %%%


\subsubsection{Page Directory Entries}

A page table descriptor or page directory entry looks similar to a page table 
entry: it has the same size and shares many common fields with the other one.

The upper 20 bits contain---again---the upper bits of a
frame address (in RAM), the same alignment argument allows us to 
leave out the lowest 12 bits of the address.

The remaining bits in the page descriptor are either unused and can be
used by the operating system for its own purposes (bits 9--11) or 
store attributes of this page descriptor:

\begin{itemize}
  \item Bits 8 and 7 must always be 0. (Actually if bit 7 is set, this
    declares that the page described by this entry is a 4 MByte, not 4 KByte,
    page. We will not discuss 4 MByte pages.)
  \item Bit 6 is undocumented, we will always set it to 0.
\end{itemize}

The remaining fields are identical to those of a page table entry:

\begin{itemize}
  \item Bit 5 holds the accessed flag.
  \item Bit 4 is called Page Cache Disabled (PCD) -- if set, data from
    this page must not be cached.
  \item Bit 3 is called Page Write Transparent (PWT), we will ignore
    this one and always set it to 0.
  \item Bit 2 holds the User Accessible (U) flag.
  \item Bit 1 holds the Writeable (W) flag.
  \item Bit 0 holds the Present (P) flag.
\end{itemize}

So we can now describe the page table descriptor in C:

<<kernel declarations>>=
typedef struct {
  uint present         : 1;  //  0
  uint writeable       : 1;  //  1
  uint user_accessible : 1;  //  2
  uint pwt            :  1;  //  3
  uint pcd            :  1;  //  4
  uint accessed       :  1;  //  5
  uint undocumented   :  1;  //  6
  uint zeroes         :  2;  //  8.. 7
  uint unused_bits    :  3;  // 11.. 9
  uint frame_addr     : 20;  // 31..12
} page_table_desc;
@

For extracting the frame address from a page table descriptor
we rewrite [[page_desc_2_frame_address]] by simple using the new
[[page_table_desc]] type instead of [[page_desc]]:

<<kernel functions>>=
uint page_table_desc_2_frame_address (page_table_desc ptd) {
  uint address;
  address = *(uint*)(&ptd);
  return address & 0xFFFFF000;
}
@

And we also duplicate [[fill_page_desc()]] as [[fill_page_table_desc()]].
Note that the function has one argument less since the [[dirty]] attribute
does not exist in page table descriptors:

<<kernel functions>>=
page_table_desc* fill_page_table_desc (page_table_desc *ptd, uint present,
                           uint writeable, uint user_accessible,
                           uint frame_addr) {
  // /--> ptd: pointer to page table descriptor <--/ //
  
  // first fill the four bytes with zeros
  memset (ptd, 0, sizeof(ptd));
  
  // now enter the argument values in the right elements
  ptd->present = present;
  ptd->writeable = writeable;
  ptd->user_accessible = user_accessible;
  ptd->frame_addr = frame_addr >> 12;   // right shift, 12 bits
  return ptd;
};

#define UMAPD(ptd, frame) fill_page_table_desc (ptd, true, true, true,  frame)
#define KMAPD(ptd, frame) fill_page_table_desc (ptd, true, true, false, frame)
@

A page directory contains 1024 page table descriptors:

<<kernel declarations>>=
typedef struct {
   page_table_desc ptds[1024];
} page_directory;
@


\subsection{Identity Mapping the Kernel Memory}

We will now use a trick that allows a smooth transition from
non-paging mode to paging mode: \emph{identity mapping} creates
a page directory for the kernel that maps the first virtual
addresses to identical hardware addresses. When we later switch
on paging, nothing changes for the kernel, because the MMU
will ...

...

\subsubsection{First Attempt at a Kernel Layout}

We now present a first and intuitive approach to placing the
kernel in memory---both real memory and virtual memory; we will
soon see that this approach is not the best possible choice and
use a different layout.

Here are some general considerations that will lead us in the
following steps:

\begin{itemize}
\item When the machine starts it must load the kernel into RAM. At
that time paging is not yet enabled, so when the computer begins
executing our kernel it uses physical memory addresses.
\item Since we cannot know how much physical memory will be installed
in a machine, it makes sense to place the kernel in some area with
low memory addresses, such as the first megabyte of RAM.
\item At some point in time during initialization of the operating
system we will enable paging. However, code execution must logically
continue at the next instruction and must not become confused by
the fact that addresses are now translated by the MMU.
\end{itemize}

The easiest thing to do is compiling and linking the kernel with
adresses starting at 0x0. If we assume that the kernel (and its
stack) fit in 1 MByte of memory, we can reserve this physical
memory area (\hexaddr{0000.0000}--\hexaddr{000F.FFFF}). The instruction that is 
going to enable paging will be sitting somewhere in this area, so
we have to make sure that after paging is turned on, the instruction
pointer will point to the instruction that follows immediately.

We need to identify
the virtual addresses \hexaddr{0000.0000} to \hexaddr{000F.FFFF} with
the same physical addresses. This amounts to 256 page table
entries; they all fit in one page table ([[kernel_pt]]), and the page 
directory ([[kernel_pd]]) will have exactly one non-null entry pointing 
to that one page table.

This way, when the kernel has enabled paging, the first megabyte
of virtual addresses will be in use (and reserved for the kernel),
whereas the rest will have null pointers in the page directory and
the page tables. So when we later talk about processes and threads,
we can create processes which use virtual memory addresses starting
at (virtual) address \hexaddr{0010.0000} (just after the first MByte),
and those processes will have the first $2^{20}$ addresses unmapped.
That way, when the process makes a syscall, we can modify the
page tables so that the kernel's address space is added---then all
addresses (\hexaddr{0000.0000}--\hexaddr{000F.FFFF}: kernel; 
\hexaddr{0010.0000} and above: process) will be available so that
data can be copied between process and kernel memory (see figure
\ref{fig:identity-mapping-1}).

\begin{figure}
\centering
\includegraphics[trim=1.5cm 14cm 1cm 1.5cm, width=10cm]{pics/identity-mapping-1.pdf}
\caption{Identity Mapping: First MByte virtual memory = first MByte RAM.}
\label{fig:identity-mapping-1}
\end{figure}

<<kernel declarations>>=
page_directory kernel_pd  __attribute__ ((aligned (4096)));
page_table kernel_pt      __attribute__ ((aligned (4096)));

// prefer to work with pointers
page_directory* current_pd = &kernel_pd;
page_table*     current_pt = &kernel_pt;
@

We need to declare these with \verb#__attribute__ ((aligned (4096)))#
so that the C compiler aligns them properly in pages.

<<setup identity mapping for kernel 1st attempt>>=
for (int i=1; i<1024; i++) {
  // Note: loop starts with i=1, not i=0
  fill_page_table_desc (&current_pd->ptds[i], false, false, false, 0);
};

// make page table kernel_pt first entry of page directory kernel_pd
/*
fill_page_table_desc (
  &(kernel_pd.ptds[0]), // address of first page directory entry
  true,                 // present
  true,                 // writeable
  true,                 // user_accessible, must later be changed
  (uint)(&kernel_pt)    // pointer to the page table
);
*/
KMAPD ( &(kernel_pd.ptds[0]), (uint)(&kernel_pt) );

for (int i=0; i<1024; i++) {
  // map 1024 pages (4 MB)
  <<identity map page i in [[kernel_pt]]>>
};
kputs("Kernel page directory setup.\n");
@

In order to identity map page [[i]] in [[kernel_pt]] we need to fill
the $i^{\text{\scriptsize th}}$ entry:

<<identity map page i in [[kernel_pt]]>>=
/*
fill_page_desc (
  &(current_pt->pds[i]), // address of i-th entry
  true,                  // present: yes
  true,                  // writeable: yes
  true,                  // user accessible: yes
  false,                 // dirty: no
  i*4096                 // physical address: start of i-th frame
);
*/
KMAP ( &(current_pt->pds[i]), i*4096 );
@

%We'll add the identity mapping code to the system initialization:
%
%< < initialize system > >=
%< < setup identity mapping for kernel > >
@

Finally, we have to enable paging in the CPU. That can be achieved
by making some changes to the control registers [[CR0]] and [[CR3]]
as follows:

\begin{itemize}
  \item Control register 3 (CR3) must contain the address of the page
    directory ([[kernel_pd]]),
  \item in control register 0 (CR0) we must set the PG (paging) bit
    which is bit 31. Setting this single bit is done by calculating
    \verb#cr0 = cr0 | (1@<<31)#. 
\end{itemize}

<<enable paging for the kernel 1st attempt>>=
uint cr0;
char *kernel_pd_address;
kernel_pd_address = (char*)(&kernel_pd);
__asm__ __volatile__ ("mov %0, %%cr3" :           : "r"(kernel_pd_address)); // write CR3
__asm__ __volatile__ ("mov %%cr0, %0" : "=r"(cr0) :                ); // read  CR0
cr0 |= (1<<31);                       // Enable paging by setting PG bit 31 of CR0
__asm__ __volatile__ ("mov %0, %%cr0" :           : "r"(cr0)       ); // write CR0
@

We call this code block [[<<enable paging for the kernel 1st attempt>>]] 
because we're 
not done yet: in order to have processes or threads we will have to
implement a function that loads the address of the page directory for 
that process into [[CR3]].

//// ???? the code \emph{does} load CR3...

%page_desc* fill_page_desc (page_desc *pd, uint present,
%                           uint writeable, uint user_accessible,
%                           uint dirty, uint frame_addr)


We need to tell the linker (\shellcmd{ld}) about the layout of the
kernel. For that purpose the GNU linker accepts a link layout
specification. We use the following linker file:

\red
<<ulix.ld 1st attempt>>=
OUTPUT_FORMAT("elf32-i386")
ENTRY(start)
phys = 0x00000000;
SECTIONS
{
  .text phys : AT(phys) {
    code = .;
    *(.text)
    *(.rodata)
    . = ALIGN(4096);
  }
  .data : AT(phys + (data - code))
  {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }
  .bss : AT(phys + (bss - code))
  {
    bss = .;
    *(.bss)
    . = ALIGN(4096);
  }
  end = .;
}
@
\black

(This linker file is a modified version of the one provided in Bran's Kernel Development Tutorial \cite{brans-tutorial:200x}; we changed the output format
to [[elf32-i386]] and the start address to 0.)

The linker file basically tells the linker to translate the addresses in
all object files so that they start at address 0, and it defines three
sections for the kernel file:

\begin{itemize}
\item [[text]] is the code section, it will contain everything that gets
executed.
\item [[data]] and [[bss]] contain program data structures which can be read and
written, but not executed. The difference between the two is that variables
in [[data]] have an explicit non-zero initialization in the code, whereas
the ones in [[bss]] do not---the linker initially sets them up with zeroes.
\end{itemize}

The [[.ALIGN]] statements force the linker to align each section to the start of a page (or page frame) of size 4096.

\subsubsection{Second Attempt at a Kernel Layout}

For several reasons (which we will not dig into), legacy properties
of Intel machines suggest to keep the first megabyte of RAM unused.
So we will physically store the kernel in the second MByte.
However, once paging is turned on, the kernel's addresses shall be
found in the last of the four gigabytes (starting at \hexaddr{0xc000.0000}).

Now differently:

0..3 GB process

3..4 GB kernel

see figure \ref{fig:identity-mapping-2}.

\begin{figure}
\centering
\includegraphics[trim=1cm 14cm 1cm 1.5cm, width=10cm]{pics/identity-mapping-2.pdf}
\caption{Second Mapping: Kernel starts at 3 GB (virtual) or 1 MB (physical).}
\label{fig:identity-mapping-2}
\end{figure}

This is not an identity mapping, so when we start the system we run
into a problem: We could link the kernel twice und also physically load it 
twice, into the ranges (1MB..2MB) and (3 GB..3GB+1MB) -- but that would
require our physical memory to be big enough.


The solution will be to work with a double mapping, as can be seen
in figure \ref{fig:identity-mapping-3} (during initialization).


\begin{figure}
\centering
\includegraphics[trim=1cm 14cm 1cm 1.5cm, width=10cm]{pics/identity-mapping-3.pdf}
\caption{Second Mapping: Kernel starts at 3 GB (virtual) or 1 MB (physical).}
\label{fig:identity-mapping-3}
\end{figure}


So we do the following:

\begin{enumerate}
\item Load the kernel to physical addresses 1MB..2MB
\item Setup an identity mapping from 1MB..2MB (virtual) to 1MB..2MB (physical)
\item Activate paging
\item Additionally setup a mapping from 3GB..3GB+1MB (virtual) to 1MB..2MB (physical) -- the corresponding page table has the same contents as the first
one, it just gets pointed to from a different page directory entry.
\item Update paging
\item Jump into the kernel area at 3GB and above
\item Get rid of the initial paging for 1MB..2MB (virtual)
\end{enumerate}

After that the kernel sees virtual addresses starting at 3 GB only.
We've found this trick in an online manual:
\url{http://wiki.osdev.org/Higher_Half_With_GDT} \cite{higher-half-with-gdt}.

We'll start with a presentation of the new linker file because we can
use it to explain the memory setup:

<<ulix.ld>>=
OUTPUT_FORMAT("elf32-i386")
ENTRY(start)
phys = 0x00100000;
virt = 0xC0000000;
SECTIONS {
  . = phys;
  
  .setup : AT(phys) {
    *(.setup)
  }

  . += virt;

  .text : AT(code - virt) {
    code = .;
    *(.text)
    *(.rodata*)
    . = ALIGN(4096);
  }

  .data : AT(data - virt) {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }

  .bss : AT(bss - virt) {
    bss = .;
    *(COMMON*)
    *(.bss*)
    . = ALIGN(4096);
  }
  end = .;
}
@

There's a new section called [[setup]], and it's the one which
contains the code that runs before paging is enabled. It will
be located at \hexaddr{10.0000} (physically; 1 M) and is responsible for steps
1--6 from the above list of actions.

The line

\begin{verbatim}
. += virt
\end{verbatim}

\noindent
changes the base address that the linker uses to create addresses:
In our case it adds \hexaddr{C000.0000} to the current output location 
counter ([[.]]).

If this line was not followed by

\begin{verbatim}
.text : AT(code - virt) {
  code = .;
\end{verbatim}

\noindent
it would have the effect to generate code and data which would be
loaded at addresses beyond \hexaddr{C000.0000}, but the [[AT]] statement
says that it shall be placed in a different location:
[[code]] is set to [[.]] which is the current location, and [[AT]]
calculates [[code - virt]] which is just the next address behind
the [[setup]] section. The consequence is that the [[text]] section
will be loaded within the second MByte of physical RAM, and---without
enabling paging---it will not be executable in that place because
all addresses in the code will have an additional offset of 
\hexaddr{C000.0000}. This must later be corrected before jumping into
that section.

The [[data]] and [[bss]] sections are created in the same way as the
[[text]] section.


((( More about the linker: see \cite{using-ld:2004} )))


Now we have to modify the setup of the identity mapping:

<<setup identity mapping for kernel>>=
// file page directory with null entries
for (int i=1; i<1024; i++) {
  // Note: loop starts with i=1, not i=0
  fill_page_table_desc (&(current_pd->ptds[i]), false, false, false, 0);
};

// make page table kernel_pt first entry of page directory kernel_pd
/*
fill_page_table_desc (
  &(current_pd->ptds[0]), // address of first page directory entry
  true,                   // present
  true,                   // writeable
  true,                   // user_accessible, must be changed later 
  (uint)(current_pt)-0xC0000000      // pointer to the page table
);
*/
KMAPD ( &(current_pd->ptds[0]), (uint)(current_pt)-0xC0000000 );

// make page table kernel_pt also 768th entry of page directory kernel_pd
/*
fill_page_table_desc (
  &(kernel_pd.ptds[768]), // address of 768th page directory entry
  true,                   // present
  true,                   // writeable
  true,                   // user_accessible
  (uint)(current_pt)-0xC0000000      // pointer to the page table
);
*/
KMAPD ( &(kernel_pd.ptds[768]), (uint)(current_pt)-0xC0000000 );

for (int i=0; i<1022; i++) {
  // map 1023 pages (4 MB minus 1 page)
  <<identity map page i in [[kernel_pt]]>>
};

// TODO: WHAT'S Going on here? This maps 1022 pages, not 1023...

/*
for (int i=1022; i<1024; i++) {
  fill_page_desc ( &(current_pt->pds[i]), false, false, false, false, 0 );
};
*/

kputs("Kernel page directory setup.\n");
@

Note that we're leaving one entry free (mapping only 1023 pages)---we'll
later need this one to create the next page table.

Also:

<<enable paging for the kernel>>=
uint cr0;
char *kernel_pd_address;
kernel_pd_address = (char*)(current_pd) - 0xC0000000;
__asm__ __volatile__ ("mov %0, %%cr3" :           : "r"(kernel_pd_address)); // write CR3
__asm__ __volatile__ ("mov %%cr0, %0" : "=r"(cr0) :                ); // read  CR0
cr0 |= (1<<31);                       // Enable paging by setting PG bit 31 of CR0
__asm__ __volatile__ ("mov %0, %%cr0" :           : "r"(cr0)       ); // write CR0
@


After paging is enabled, we can get rid of the identity mapping which
works with low addresses


This one will hold the video stuff \hexaddr{B8000} + 4 K)

<<kernel declarations>>=
page_table video_pt __attribute__ ((aligned (4096)));  /* must be aligned! */
@

We create a new page table (intitialized with null entries) and from
there we only create a mapping of 8 KByte (starting at \hexaddr{B8000}).

<<initialize system>>=
for (int i=0; i<1024; i++) { 
  // null entries:
  fill_page_desc ( &(video_pt.pds[i]), false,false,false,false,0 );
};
  
for (int i=184; i<186; i++) { 
  /*
  fill_page_desc (
    &(video_pt.pds[i]),      // address of 184th/185th entry
    true,                    // present: yes
    true,                    // writeable: yes
    true,                    // user accessible: yes
    false,                   // dirty: no
    i*4096                   // physical address: start of 184/185th frame
  );
  */
  KMAP ( &(video_pt.pds[i]), i*4096 );
};

// enter new table in page directory
/*
fill_page_table_desc (
  &(current_pd->ptds[0]), 
  true, 
  true,
  true, 
  (uint) (&video_pt) - 0xC0000000  // pointer to page table
);
*/
KMAPD ( &(current_pd->ptds[0]), (uint) (&video_pt) - 0xC0000000 );

gdt_flush();
@


Later we will get rid of the video mapping, so here comes the code
that deletes those two page table entries:

<<remove video mapping>>=
for (int i=184; i<186; i++) { 
  // null entries:
  fill_page_desc ( &(video_pt.pds[i]), false,false,false,false,0 );
};

/*
fill_page_table_desc (
  &(current_pd->ptds[0]), 
  false, 
  false,
  false, 
  0
);
*/
gdt_flush();
@


\subsection{Page Frames in \Ulix{}}
\label{sec:page:frames}


The physical memory consists of page frames, some of which are already
in use. When we dynamically assign frames to pages (i.\,e. change some
page table), we need to know which frames are free and which are in use.
For that purpose we use a bitmap (that we will call the frame table)
which holds the current usage state
of every frame. Since we have just setup the initial memory usage, we
know exactly what our memory looks like at this point in time, so now is
a good time to create and initialize that bitmap.

We assume that our system has 64 MBytes of physical RAM.
\green
The size of
the frame table depends on the size of the available physical memory
which we defined to contain [[MAX_ADDRESS]] many addresses. Dividing
this by the [[PAGE_SIZE]] gives us the number of page frames.  This of
course assumes that [[MAX_ADDRESS]] is larger than [[PAGE_SIZE]] and
both values are powers of two.
\black

<<kernel declarations>>=
#define MEM_SIZE 1024*1024*64        // 64 MByte
#define MAX_ADDRESS MEM_SIZE-1       // last valid physical address
#define PAGE_SIZE 4096               // Intel: 4K pages
#define NUMBER_OF_FRAMES MEM_SIZE/PAGE_SIZE
@

\green

The usage of main memory is directly reflected in the amount of
frames which are not free. We will try to keep track of the
number of free frames throughout the lifetime of the system
in a global variable [[free_frames]].

<<kernel global variables>>=
uint free_frames = NUMBER_OF_FRAMES;
@

\black

So [[NUMBER_OF_FRAMES]] is the number of bits we need to store in
the frame table. Since a byte holds eight bits, we need a structure
that is [[NUMBER_OF_FRAMES/8]] bytes large:

<<kernel global variables>>=
char place_for_ftable[NUMBER_OF_FRAMES/8];
uint* ftable = (uint*)(&place_for_ftable);
@

<<initialize system>>=
memset(ftable, 0, NUMBER_OF_FRAMES/8);  // all frames are free
@

Now we need to tell the frame table that some of our frames are
already in use: We have two mappings for the first 4 MByte of physical
RAM (even though we don't use the first MByte at all). So we
declare the first 4 MByte as used. 4 MByte contain 1024 pages,
thus the first 1024 frames must be marked used.
1024/8 = 128; we set the first 128 bytes to 0xff:

<<initialize system>>=
memset(ftable, 0xff, 128);
@

We also subtract the frames in these 4 MByte from [[free_frames]]:

<<initialize system>>=
free_frames -= 1024;
@


This was simple 

....






\subsubsection{Bitwise Manipulation}

We want to be able to set / clear single entries in our 
frame table, so we have to access single bits: read them, write
them, and test them.

We can think of a frame number as consisting of

\begin{itemize}
\item an upper part that is an index into the frame table (which
  is built from 32-bit [[uint]]s). Every such [[uint]] stores
  32 bits.
\item and a lower part that is an offset whose value can lie
  between 0 and 31, giving a precise position within one such indexed [[uint]].
\end{itemize}

So we get \emph{frameno} = 32 $\times$ \emph{index} + \emph{offset}, like this:

\[ \textsl{frameno} = \dots i_4\, i_3\, i_2\, i_1\, i_0\, o_4\, o_3\, o_2\, o_1\, o_0 \]

When we divide a frame number by 32, we find the [[uint]] which stores
the bit we're searching for. The modulo function gives us the offset:\footnote{
The macros [[INDEX_FROM_BIT]] and [[OFFSET_FROM_BIT]] and the functions
[[set_frame]], [[clear_frame]], and [[test_frame]] have been taken from 
\url{http://www.jamesmolloy.co.uk/tutorial_html/6.-Paging.html}, they were
slightly modified and adapted to \UlixI{}.}

<<kernel declarations>>=
#define INDEX_FROM_BIT(b) (b/32)   // 32 bits in an uint
#define OFFSET_FROM_BIT(b) (b%32)
@

The following two functions allow us to set or clear individual
bits in the frame table:

<<kernel functions>>=
static void set_frame(uint frame_addr)
{
   uint frame = frame_addr / PAGE_SIZE;
   uint index = INDEX_FROM_BIT(frame);
   uint offset = OFFSET_FROM_BIT(frame);
   ftable[index] |= (1 @<< offset);
}

static void clear_frame(uint frame_addr)
{
   uint frame = frame_addr / PAGE_SIZE;
   uint index = INDEX_FROM_BIT(frame);
   uint offset = OFFSET_FROM_BIT(frame);
   ftable[index] &= ~(1 @<< offset);
}
@

Note how individual bits are set or cleared:

\begin{itemize}
\item \verb#|=# and \verb#&=# work in a similar way as \verb#+=# for addition,
  however they perform ``bitwise or'' and ``bitwise and'', respectively. So
  \verb#x|=y# is short for \verb#x=x|y# and \verb#x&=y# is short for \verb#x=x&y#.
\item In the [[set_frame]] function, \verb#1 @<< offset# uses left shift to create
  a value whose offset's bit is set (and all others are not), e.\,g.
  \verb#1 @<< 3# is \verb#00000000000000000000000000001000# (in binary notation).
\item Next the corresponding [[uint]] is ``bitwise-or''ed with this value.
  That means: all bits which were already 1, remain 1; and the [[offset]]'s bit
  is being set (whatever its value was before).
\item In a similar way the [[clear_frame]] function can clear a bit. It
  also starts with a shift operation, but the result goes through bitwise negation
  (\verb#~#) which flips all bits. For example,
  \verb#~(1 @<< 3)# is \verb#11111111111111111111111111110111#. So there is exactly
  one 0 bit in there with all other bits being 1.
\item Then the corresponding [[uint]] is `bitwise-and''ed with this value. That means:
  all bits which were already 0, remain 0; and the [[offset]]'s bit
  is being cleared (whatever its value was before).
\end{itemize}

What remains is a function that can test a bit. It returns 0 or 1

<<kernel functions>>=
// Static function to test if a bit is set.
static uint test_frame(uint frame_addr) {
  // returns true if frame is in use (false if frame is free)
  uint frame = frame_addr / PAGE_SIZE;
  uint index = INDEX_FROM_BIT(frame);
  uint offset = OFFSET_FROM_BIT(frame);
  return ((ftable[index] & (0x1 @<< offset)) @>> offset);
}
@

A result of 0 means that a frame is available, whereas 1 means that the frame
is already in use---which corresponds to the way we have already initialized
a part of the frame table.

The function uses left and right shifts in order to always return either 0 or 1.
If you never do any comparisons with 1, but only call the function in \verb#if#
statements such as

<<example call of test\_frame>>=
if ( test_frame (address) ) {
  // result non-0 (true); frame is not available
} else {
  // result 0 (false);    frame is available
}
@

then you can skip the right shift at the end of the line and make the calculation
a bit faster.


\subsubsection{What's the Problem With Kernel Memory Management?}

So far we haven't encountered any conceptual problems, but consider this:

The information stored in the page directories, page tables, and in the frame 
table refers to physical memory. But the kernel has activated paging, and even
though it runs with the most privileges any code on the machine can get, it
cannot directly access physical memory. Yet it has to modify or create new
page tables and it has to update the frame table. So the kernel needs to have
an understanding on what is going on in the physical memory, without accessing
it.

If physical memory is very small in comparison to the virtual address space,
it is possible to permanently map all of the RAM into some area of the kernel's 
virtual address space. For our code we assume that the machine has only 64 MByte
of RAM---compared to the 4~GByte address space that is not much. We can spare
so much of the virtual kernel memory and sponsor a mapping to this physical RAM.
We will put this in the area \hexaddr{D000.0000} \dots \hexaddr{D3FF.FFFF}, so that any physical
address $x$ can be accessed via the virtual address $x$ + \hexaddr{D000.0000}.
 However the corresponding
page table entries will require some room: 64 MByte = 16384 pages, so we will need
16384 page table entries each of which uses 4 bytes. Thus, it requires 16 pages
(64 KByte) to store the extra page tables.

Where can we put these tables? To simplify things we'll declare yet more static
variables which hold our 16 tables:

<<kernel declarations>>=
page_table kernel_pt_ram[16] __attribute__ ((aligned (4096)));
@

and we initialize them with references to all of our RAM.

<<initialize system>>=
uint fid;
for ( fid=0; fid<NUMBER_OF_FRAMES; fid++ ) {
  <<map page starting at 0xD000.0000 + PAGE\_SIZE*fid to frame fid>>
}
@

The code for this mapping is not too complicated, either:

<<map page starting at 0xD000.0000 + PAGE\_SIZE*fid to frame fid>>=
/*
fill_page_desc (
  &( kernel_pt_ram[fid/1024].pds[fid%1024] ),  // address of entry no. fid
  true,                                        // present: yes
  true,                                        // writeable: yes
  true,                                        // user accessible: yes
  false,                                       // dirty: no
  fid*PAGE_SIZE    // physical address: start of fid-th frame
);
*/
KMAP ( &(kernel_pt_ram[fid/1024].pds[fid%1024]), fid*PAGE_SIZE );
@

(Note that instead of
\verb#&( kernel_pt_ram[fid/1024].pds[fid%1024] )#
we could have used
\verb#&( kernel_pt_ram[0].pds[fid] )#
which would access out of bound indices of \\ [[kernel_pt_ram[0].pds]],
but since these arrays are arranged one after the other without
other data in between, it would work as well.)

To finalize this, we have to enter the 16 new page tables in 16
page directory entries. Note that we need the physical addresses
of the page tables, not the virtual ones. While 
[[&(kernel_pt_ram[i])]] delivers the virtual address just fine,
it does not help to write it into the page directory. Subtracting
\hexaddr{C000.0000} does the job.

<<initialize system>>=
// kputs ("Address of kernel_pt_ram: "); printhex ((uint)&kernel_pt_ram); kputch ('\n');
uint physaddr;
for ( int i=0; i<16; i++ ) {
  // get physical address of kernel_pt_ram[i]
  physaddr = (uint)(&(kernel_pt_ram[i])) - 0xc0000000;
  /*
  fill_page_table_desc (
    &(current_pd->ptds[832+i]), // address of correct page directory entry
    true,                       // present
    true,                       // writeable
    true,                       // user_accessible
    physaddr                    // pointer to the page table
  );
  */
  KMAPD ( &(current_pd->ptds[832+i]), physaddr );
};
kputs ("Physical RAM (64 MB) mapped to 0xD0000000-0xD3FFFFFF.\n");
@

Note that we need not modify [[free_frames]], because only additional
parts of virtual memory are used.

\red
TODO: Was hab ich hier gemeint??
\black

Since we will often have to access a physical address, we'll define
a macro [[PHYSICAL]] that will translate an address from the first
64 MByte to the \hexaddr{D000.0000} \dots \hexaddr{D3FF.FFFF} range:

<<kernel declarations>>=
#define PHYSICAL(x) ((x)+0xd0000000)
@


Now that we can access all of the physical addresses (including
video memory) we can get rid of the mapping for 0xb80000:

<<initialize system>>=
VIDEORAM=0xD00B8000;
textmemptr = (unsigned short *)VIDEORAM;
<<remove video mapping>>
@

Trying to access the physical RAM:

If you remember home computers, their built-in Basic interpreters
often had a way to directly access memory contents. The classical
command names were [[PEEK]] (for reading) and [[POKE]] (for writing).
Here they are again: They convert an address to a pointer to an
\verb#unsigned char# and then read or write. (Credits to
Dan Henry who supplied the first two lines of this code on 
\url{http://www.keil.com/forum/8275/}.)

<<kernel declarations>>=
/* Peek and Poke for virtual addresses */
#define PEEK(addr)      (*(unsigned char *)(addr))
#define POKE(addr, b)   (*(unsigned char *)(addr) = (b))
/* Peek and Poke for physical addresses 0..64 MB */
#define PEEKPH(addr)    (*(unsigned char *)(PHYSICAL(addr)))
#define POKEPH(addr, b) (*(unsigned char *)(PHYSICAL(addr)) = (b))
#define PEEKPH_UINT(addr)    (*(unsigned int *)(PHYSICAL(addr)))
#define POKEPH_UINT(addr, b) (*(unsigned int *)(PHYSICAL(addr)) = (b))

@

<<initialize system>>=
// tests access to physical memory mapped to 0xD000.0000 ...
/*
kputs ("Peeking physical 0x100000: ");
printhexbyte (PEEKPH(0x100000)); kputch('\n');
*/
@


%There's one more area in virtual memory that we need to setup
%because in the future we will have dynamically created page
%tables, and they must be stored somewhere. A first version of
%this code just added them between ``normal'' pages, but that
%proved to be a problem when trying to allocate large (virtually)
%contiguous memory areas. So we'll put them in the range starting
%at 0xF000.0000. Here's the code to get started:
%
%<kernel declarations>=
%page_table kernel_pt_tables[16] __attribute__ ((aligned (4096)));
%uint next_pt = &f0000000;  // address of next kernel page table
%@
%
%and we initialize them with null entries:
%
%<initialize system>=
%memset (&kernel_pt_tables, 0, sizeof(kernel_pt_tables));
%@
%





<<initialize system>>=
// test sys call
// __asm__ ("movl $12345,%eax");
// __asm__ ("int	$0x80\n");
@


<<initialize system>>=

/* tests frametables...
kputs ("\nChecking frametable...\n");
int testresult;
testresult = test_frame (0);  // address ?
kputs ("Testing frame address 0x0     : "); printhex (testresult); kputch ('\n');
testresult = test_frame (0x100000);  // address ?
kputs ("Testing frame address 0x100000: "); printhex (testresult); kputch ('\n');
testresult = test_frame (0x200000);  // address ?
kputs ("Testing frame address 0x200000: "); printhex (testresult); kputch ('\n');
testresult = test_frame (0x3FF000);  // address ?
kputs ("Testing frame address 0x3FF000: "); printhex (testresult); kputch ('\n');
testresult = test_frame (0x400000);  // address ?
kputs ("Testing frame address 0x400000: "); printhex (testresult); kputch ('\n');
testresult = test_frame (0x800000);  // address ?
kputs ("Testing frame address 0x800000: "); printhex (testresult); kputch ('\n');
kputs ("Setting 0x800000 as used...\n"); set_frame (0x800000);
testresult = test_frame (0x800000);  // address ?
kputs ("Testing frame address 0x800000: "); printhex (testresult); kputch ('\n'); 
kputch ('\n');
*/
@


\subsubsection{Printing the Page Directory}

<<kernel functions>>=
void print_page_directory () {
  int i;
  kputs ("The Page Directory:\n");
  for ( i = 700 ; i<800 ; i++ ) {
    if ( current_pd->ptds[i].present ) {
      printint (i); kputch (' ');
      printhex (current_pd->ptds[i].frame_addr );
      putnl();
      // pt = (uint*) kernel_pd.ptds[i].frame_addr;
      // kputs ("first entry's address: "); printhex(pt->pds[0].frame_addr); putnl();
    };
  };
  
  uint z=(uint)current_pd;
  // z = 0xd0401000;
  kputs ("hexdump for "); printhex (z); putnl();
  hexdump (z,z+128);
  putnl();
};
@

\subsubsection{Printing the Frame Table and Page Table}

Here's a function for displaying the current page tables:

Since we want to output information from the free frame list
(we will use the [[test_frame]] to check frame states), we
write a simple function that can print status information for
a memory region (going from [[start]] to [[end]]):

<<kernel functions>>=
void print_page_table_helper (uint start, uint end, uint used) {
  if (used) {
    kputs ("Used: ");
  } else {
    kputs ("Free: ");
  }
  printf ("%05x-%05x    %5d-%5d   (%5d frames)\n", 
    start, end, start, end, end-start+1);
  //printhex (start); kputs ("-"); printhex (end); kputs ("    ");
  //printint (start); kputs ("-"); printint (end); 
  //kputs ("   ("); printint (end-start+1); kputs (" frames)\n");
  return;
};
@

For the page table information we need to be able to translate
a page number to a frame number. That is what the following
function does (returning [[-1]] if the page is not mapped). It
uses the fact that for a page number [[pageno]] we first look
at entry [[pageno/1024]] of the page directory, locate the
referenced page table and then look at entry [[pageno%1024]]
of that page table.

<<kernel functions>>=
uint pageno_to_frameno (uint pageno) {
  uint pdindex = pageno/1024;
  uint ptindex = pageno%1024;
  if ( ! current_pd->ptds[pdindex].present ) {
    // we don't have that page table
    return -1;
  } else {
    // get the page table
    page_table* pt = (page_table*)(
      PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12)
      // note: frame_addr holds a physical address
      // luckily we have a mapping of physical address space 
      // to 0xd000.0000 and above...
    );
    if ( pt->pds[ptindex].present ) {
      return pt->pds[ptindex].frame_addr;
    } else {
      // we don't have that page
      return -1;
    };
  };    
};
@

Here is the function that prints the frame and page tables:

<<kernel declarations>>=
void print_page_table ();
@

<<kernel functions>>=
void print_page_table () {
  uint cr3;
  <<print frame table>>
  kputch ('\n');
  <<print page table>>
  __asm__ __volatile__("mov %%cr3, %0": "=r"(cr3));
  printf ("cr3: %08x\n", cr3);
}
@

<<print frame table>>=
kputs ("Current Frame Info:\n");
// set_frame(2047*4096);  // use page 2047, TESTING
  
uint frameno = 0;
uint totalfree = NUMBER_OF_FRAMES;  // total number of free frames
uint test = test_frame(frameno*4096);  // check first frame
  
for (uint i=1; i<NUMBER_OF_FRAMES ; i++) {
  if (test_frame(i*4096) != test) { 
    print_page_table_helper (frameno, i-1, test);
    if (test) totalfree -= (i-frameno);
    test = 1-test;
    frameno = i;
  };
};
print_page_table_helper (frameno, NUMBER_OF_FRAMES-1, test);
if (test) totalfree -= (NUMBER_OF_FRAMES-frameno);
kputs ("Total free frames:    "); printint (totalfree); kputch ('\n');
kputs ("Value of free_frames: "); printint (free_frames); kputch ('\n');
@

Note that we need to multiply the frame number [[i]] with 4096
in order to get the frame address because [[test_frame]] expects
addresses, not numbers. The output of [[<<print frame table>>]]
looks like this:
{\small
\begin{verbatim}
Current Frame Info:
Used: 0x00000000-0x000003FF    0000000-0001023   (0001024 frames)
Free: 0x00000400-0x000007FE    0001024-0002046   (0001023 frames)
Used: 0x000007FF-0x000007FF    0002047-0002047   (0000001 frames)
Free: 0x00000800-0x00004000    0002048-0016384   (0014337 frames)
Total free frames:   0015359
\end{verbatim}
}

The following code for the page table seems overly complicated
because we want to print mappings of ranges and not each single
mapping of a page to a frame in order to save space in the output
(and keep it readable). We use a variable [[started]] to memorize
whether we're right now in a mapped region while skipping through
the page tables.

<<print page table>>=
printf ("Current Paging Info: Address Space #%d\n", current_as);

boolean started=false;
int save_i=0; int save_f=0; 
uint start_i=0; uint start_f=0;
for (uint i=0; i<1024*1024; i++) {
  frameno = mmu_p (current_as, i);  // get frameno with resp. to current AS
  if (frameno == -1) {
    // frame NOT found
    if (started) {
      <<print pages to frames block>>
      started = false;
    }
    continue;  // dont act on non-mapped pages
  } else {
    // frame found
    if (!started) {
      start_i = i; start_f = frameno;
      save_i = i; save_f = frameno; // ???
      started = true;
    } else {
      if (i-start_i != frameno-start_f) {
        // pages continue, but frames are elsewhere
        <<print pages to frames block>>
        start_i=i; start_f=frameno;
      };

      save_i = i;
      save_f = frameno;
    };
  };    
};
if (started) {
  <<print pages to frames block>>
};
@

This is just the code for formatting the output:

<<print pages to frames block>>=
printf ("PTEs 0x%05x..0x%05x -> frames 0x%05x..0x%05x  (%5d pages)\n",
  start_i, save_i, start_f, save_f, save_i-start_i+1);
@

The output of [[<<print page table>>]] will look like this:
{\small
\begin{verbatim}
Current Paging Info:
PTEs 0x00000000..0x000003FF -> frames 0x00000000..0x000003FF   (0001024 pages)
PTEs 0x000C0000..0x000C03FF -> frames 0x00000000..0x000003FF   (0001024 pages)
PTEs 0x000D0000..0x000D3FFF -> frames 0x00000000..0x00003FFF   (0016384 pages)
\end{verbatim}
}



\begin{work}
DEBUG: THIS WILL LATER BE REMOVED

<<kernel functions>>=
void bochs_print_page_table_helper (uint start, uint end, uint used) {
  if (used) {
    bochs_puts ("Used: ");
  } else {
    bochs_puts ("Free: ");
  }
  bochs_printhex (start); bochs_puts ("-"); bochs_printhex (end); bochs_puts ("    ");
  bochs_printint (start); bochs_puts ("-"); bochs_printint (end); 
  bochs_puts ("   ("); bochs_printint (end-start+1); bochs_puts (" frames)\n");
  return;
};

void bochs_print_page_table () {
  
kputs ("Current Frame Info:\n");
// set_frame(2047*4096);  // use page 2047, TESTING
  
uint frameno = 0;
uint totalfree = NUMBER_OF_FRAMES;  // total number of free frames
uint test = test_frame(frameno*4096);  // check first frame
  
for (uint i=1; i<NUMBER_OF_FRAMES ; i++) {
  if (test_frame(i*4096) != test) { 
    bochs_print_page_table_helper (frameno, i-1, test);
    if (test) totalfree -= (i-frameno);
    test = 1-test;
    frameno = i;
  };
};
bochs_print_page_table_helper (frameno, NUMBER_OF_FRAMES-1, test);
if (test) totalfree -= (NUMBER_OF_FRAMES-frameno);
bochs_puts ("Total free frames:    "); bochs_printint (totalfree); bochs_putch ('\n');
bochs_puts ("Value of free_frames: "); bochs_printint (free_frames); bochs_putch ('\n');
  bochs_putch ('\n');
  
bochs_puts ("Current Paging Info:\n");

boolean started=false;
uint save_i=1;  uint save_f=0;  // some odd values
uint start_i=0; uint start_f=0;
for (uint i=0; i<1024*1024; i++) {
  frameno = pageno_to_frameno (i);
  if (frameno == -1) {
    // frame NOT found
    if (started) {

bochs_puts ("PTEs "); 
bochs_printhex (start_i); bochs_puts (".."); bochs_printhex (save_i); 
bochs_puts (" -> frames "); 
bochs_printhex (start_f); bochs_puts (".."); bochs_printhex (save_f);
bochs_puts ("   ("); bochs_printint (save_i-start_i+1); bochs_puts (" pages)\n");
      started = false;
    }
    continue;  // dont act on non-mapped pages
  } else {
    // frame found
    if (!started) {
      start_i = i; start_f = frameno;
      started = true;
    } else {
      if (i-start_i != frameno-start_f) {
        // pages continue, but frames are elsewhere
        
bochs_puts ("PTEs "); 
bochs_printhex (start_i); bochs_puts (".."); bochs_printhex (save_i); 
bochs_puts (" -> frames "); 
bochs_printhex (start_f); bochs_puts (".."); bochs_printhex (save_f);
bochs_puts ("   ("); bochs_printint (save_i-start_i+1); bochs_puts (" pages)\n");
        start_i=i; start_f=frameno;
      };

      save_i = i;
      save_f = frameno;
    };
  };    
};
if (started) {
  
bochs_puts ("PTEs "); 
bochs_printhex (start_i); bochs_puts (".."); bochs_printhex (save_i); 
bochs_puts (" -> frames "); 
bochs_printhex (start_f); bochs_puts (".."); bochs_printhex (save_f);
bochs_puts ("   ("); bochs_printint (save_i-start_i+1); bochs_puts (" pages)\n");
};
}
@

\end{work}


\subsection{Allocating Memory for the Kernel}

So far we have not used any dynamically generated data structures
in the kernel, so there was no need for some kind of allocate function
for the kernel.

When we start creating processes, we will need to reserve (virtual)
memory for those processes, and there may also be areas in the kernel
which need memory.

So we will start simple: with a function that requests a new frame
of physical memory. It will have the following definition:

<<kernel functions>>=
int request_new_frame () {
  <<find a free frame und reserve it>>
  // < < return frame id > >
};
@

This alone will not be all too useful---only in combination with
entering it in some paging table that memory will be accessible
(unless code uses the mapping of the physical RAM to \hexaddr{D000.0000}...).

Finding a free frame is simple: We look at the frame table and
return the first available frame:

<<find a free frame und reserve it>>=
uint frameid;
boolean found=false;
for (frameid = 0; frameid < NUMBER_OF_FRAMES; frameid++) {
  if ( !test_frame (frameid*4096) ) {
    found=true;
    break;   // frame found
  };
}
@

We use [[set_frame]] to mark the frame used and return the frame id:
<<find a free frame und reserve it>>=
if (found) {
  set_frame (frameid*4096);
  free_frames--;

  if (INSIDE_FORK) debug_printf ("in ulix_fork: request_new_frame() = %d\n", frameid);
 
  return frameid;
} else {
  return -1;
}
@

Note that the function returns $-1$ if no frame was available.

We'll add code for releasing a frame: basically we just call
[[clear_frame]], but we also need to modify [[free_frames]]:

<<kernel functions>>=
void release_frame (uint frameaddr) {
  if ( test_frame (frameaddr) ) {
    // only do work if frame is marked as used
    clear_frame (frameaddr);
    free_frames++;
  };
};
@

Note that we may call [[release_frame]] for unused frames which
will have no effect.



Next up comes code which enters such a frame into a page
table:

<<kernel declarations>>=
#define NULL ((void*) 0)

<<kernel functions>>=
uint* request_new_page (int need_more_pages) {
  // debug_printf ("ENTER request_new_page\n");
  uint newframeid = request_new_frame();
  // debug_printf ("AFTER request_new_frame\n");
  if (newframeid == -1)  return NULL;   // exit if no frame was found
  <<enter frame in page table>>
  // debug_printf ("AFTER <enter frame in page table>\n");
};
@

That function is more useful.

Now, how can we enter the frame in the page table? We must
search through the page directory and find a place that is
not yet mapped. We will use the function [[pageno_to_frameno]]
that was already helpful for printing the page tables: We
loop over the pages, and when we find an unmapped page, we
map it.

<<enter frame in page table>>=
// kputs ("Frame: "); printhex (newframeid);
uint pageno = -1;
for (uint i=0xc0000; i<1024*1024; i++) {

  /*
  *
  *  MAYBE: have a global variable NEXT_PAGE ??
  *  -> deal with problem of consecutive allocation
  *
  */
  // if ( pageno_to_frameno (i) == -1 ) {
  if ( mmu_p (current_as, i) == -1 ) {
    pageno = i;
    break;       // end loop, unmapped page was found
  };

};
// kputs (", Page: "); printhex (pageno);

// debug_printf ("debug: found page %x \n", pageno);

if ( pageno == -1 ) {
  // we found no page -- whole 4 GB are mapped???
  return NULL;
};
@

There is one condition under which simply entering the
data in the page table will fail: if we fill the last
entry of the page table, it will afterwards be full,
and the next attempt to create a new page will find no
place to store it. Then it will be too late to create a
new page table (because that new page table must also
have a virtual address).

So we check now, whether we're attempting to fill the
last entry.

<<enter frame in page table>>=
uint pdindex = pageno/1024;
uint ptindex = pageno%1024;
page_table* pt;

// printf ("debug: pdindex=%x, ptindex=%x\n", pdindex,ptindex);

if ( ptindex == 0 ) {    //  ACHTUNG! war: ptindex == 1023
  // last entry!!
  <<create new page table>>
  // update pageno and related variables (we'll use the next page)
  // OLD CODE: pageno+=1; pdindex = pageno/1024; ptindex = pageno%1024;

  // printf ("debug: after create new page table\n");

  // get yet another frame
  newframeid = request_new_frame();
  if (newframeid == -1) {
    return NULL;   // exit if no frame was found
    // note: we're not removing the new page table since we assume
    // it will be used soon anyway
  }
  // kputs (", 2nd frame: "); printhex (newframeid);
};
@


Now we need to access the page directory and the right page
table again

<<kernel declarations>>=
short int DEBUG=0;
@

<<enter frame in page table>>=
if ( ! current_pd->ptds[pdindex].present ) {
  // we don't have that page table -- this should not happen!
  kputs ("FAIL! No page table entry\n");
  debug_printf ("current_as = %d, create_as = %d\n", current_as, create_as);
  debug_printf ("&current_pd = 0x%x\n", &current_pd);
  debug_printf ("pdindex = %d, ptindex = %d\n", pdindex, ptindex);
  return NULL;
} else {
  // get the page table
  pt = (page_table*)(
    PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12)
  );
  // finally: enter the frame address

  // kputs ("going to call fill_page_desc with adr = ");
  // printhex ((uint)&(pt->pds[ptindex])); putnl();
  
  // kputs ("DEBUG: pt->pds="); printhex ((uint)(&pt->pds[ptindex])); putnl();
  
  /*
  fill_page_desc (
    &(pt->pds[ptindex]),
    true, // present
    true, // writeable
    true, // user accessible
    false, // not dirty
    newframeid * PAGE_SIZE  // phys. addr.
  );
  */
  KMAP ( &(pt->pds[ptindex]), newframeid * PAGE_SIZE );

  // invalidate cache entry
  __asm__ __volatile__ ("invlpg %0" : : "m" (*(char*)(pageno<<12)));
};
@

Finally, we clear the new page and return a pointer to the new page:

<<enter frame in page table>>=
memset ((uint*) (pageno*4096), 0, 4096);

// debug_printf ("LEAVE request_new_page\n");

return ((uint*) (pageno*4096));
@

If a page table does not yet exist, it has to be created
and referenced from the page directory:

\begin{work}

HIER DEN CODE AENDERN:

NEUE TABELLE AB 0xF000.0000

WEITER OBEN DANN NICHT pageno HOCHZAEHLEN

Here's what we need to do:

\begin{itemize}

\item We noticed we're running out of free entries in the first
page table
\item A new page table has to be created
\item We use the frame we already aquired ([[newframeid]]) to put
the new page table into it
\item the job of the new page table is to map new pages (in the \hexaddr{C000.0000}...
area) to physical frames.
\item We want that page table to sit at \hexaddr{F000.0000}
\item the page directory entry for \hexaddr{F000.0000} is empty (null entry)
\item Note: the first time we do this, we also need a new page directory
entry (for the \hexaddr{F000.0000} ... area)
\end{itemize}

\end{work}




%< <create new page table old> >=
%// kputs ("Going to create new page table\n");
%// kputs ("PT Frame ID is: "); printhex (newframeid); kputch ('\n');
%
%// We use the frame that we have just allocated for the new
%// page table. Currently, we cannot write to the frame because
%// it has no virtual address. So we must enter it in the last
%// field:
%pt = (page_table*)(
%  PHYSICAL(current_pd->ptds[pdindex].frame_addr < < 12)
%  );
%// enter the frame address
%
%fill_page_desc (
%  & (pt->pds[ptindex]),        // address of entry no. fid
%  true,                        // present: yes
%  true,                        // writeable: yes
%  true,                        // user accessible: yes
%  false,                       // dirty: no
%  newframeid*PAGE_SIZE    // physical address
%);
%
%// Now we can fill the new page table because it has a virtual 
%// address: pageno*4096
%
%// kputs ("SUPERDEBUG: pageno= "); printhex(pageno< <12); putnl();
%pt = (page_table*)(pageno < < 12);
%
%memset (pt, 0, 4096);
%
%// we leave this filled with zeros: no entries yet.
%
%// a new page table means a new entry in the page directory.
%// where will it be? at pdindex+1
%
%// kputs ("DEBUG: fill_page_table_desc ...");
%// kputs ("pdindex+1, ptindex: "); printint (pdindex+1); kputch (' '); printint (ptindex); kputch('\n');
%fill_page_table_desc (
%  &(current_pd->ptds[pdindex+1]), /* address of page directory entry */
%  true,                       /* present */
%  true,                       /* writeable */ 
%  true,                       /* user_accessible */ 
%  newframeid < < 12 // ??????    /* pointer to the page table */ 
%);
%// kputs ("\n END OF CREATE_NEW_PAGE_TABLE \n");
%// kputs ("ADDRESS of PDir Entry: "); printhex((uint)&(current_pd->ptds[pdindex+1]));putnl();
%
%% @


On-the-fly creation of a new page table works like this: We have a
frame at [[newframeid]] which we can use, its physical address is 
[[newframeid << 12]]. It is not mapped (so it has no virtual address);
we'll deal with this fact later. We can use our [[PHYSICAL]] function
to ``talk'' to it directly: The address is [[PHYSICAL(newframeid<<12)]].
So we create the page table and fill it with zeros:

<<create new page table>>=
debug_printf ("ENTER <create new page table>\n");
// create a new page table in there
page_table* pt = (page_table*) PHYSICAL(newframeid<<12);
memset (pt, 0, PAGE_SIZE);
@

We need to tell the page directory that this page table
is responsible for the next chunk of memory. When we calculated
[[pdindex]] and [[ptindex]] above, we found that [[ptindex]] is 0,
and [[pdindex]] points to the page directory entry that is
currently empty. So it is just [[pdindex]] which we have to use:

<<create new page table>>=
/*
fill_page_table_desc (
  &(current_pd->ptds[pdindex]), // address of next page directory entry
  true, true, true,             // present, writeable, user_accessible
  newframeid << 12              // pointer to the page table 
);
*/
// UMAPD ( &(current_pd->ptds[pdindex]), newframeid << 12 );
@

TEST: UPDATE ALL(!) PAGE DIRECTORIES! We failed when manipulating
new address spaces (possibly because only the kernel page directory
was updated, not the one that belongs to the address space!)

<<create new page table>>=
int asid;
page_directory* tmp_pd;
for (asid=0; asid<1024; asid++) {
  debug_printf ("asid loop: asid = %d\n", asid);
  if (!address_spaces[asid].free   // is this address space in use?
      && asid != create_as)        // do not modify an address space which is cur-
                                   // rently created via create_new_address_space
  {
    tmp_pd = address_spaces[asid].pd;
    KMAPD ( &(tmp_pd->ptds[pdindex]), newframeid << 12 );
  }
}
debug_printf ("LEAVE <create new page table>\n");
@

Note: these new page tables only exist physically. Their frames are
marked as used, but no virtual addresses point to them.
Is that a problem? We can always get their physical addresses
through the page directory. So we should be fine.








Now we are able to request new pages, but occasionally we will
also want to release them. That is much simpler: In order to
release a page, we simply have to

<<kernel functions>>=
void release_page (uint pageno) {
  <<remove page to frame mapping from page table>>
  <<release corresponding frame>>
};
@

First we have to get rid of the page mapping, i.\,e., we need to
find the entry in the correct page table and replace it with a
null entry. The lookup code is similar to the code for creating
the new entry (in [[<<enter frame in page table>>]]). However,
we first test whether a page mapping exists, because if not,
we can return immediately:

<<remove page to frame mapping from page table>>=
// int frameno = pageno_to_frameno (pageno);  // we will need this later
int frameno = mmu_p (current_as, pageno);  // we will need this later
if ( frameno == -1 )  return;              // exit if no such page
@

Now we look up the right entry and set it to zero:

<<remove page to frame mapping from page table>>=
uint pdindex = pageno/1024;
uint ptindex = pageno%1024;
page_table* pt;

pt = (page_table*)(
    PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12)
  );

// write null page descriptor
fill_page_desc ( &(pt->pds[ptindex]), false, false, false, false, 0 );
@

Lastly, we free the frame---we have the [[release_frame]] function
for that:

<<release corresponding frame>>=
release_frame (frameno<<12);   // expects an address, not an ID
// note: release_frame increases free_frames
@

That's all there is to it.

Sometimes we will want to release a whole consecutive range of
pages, so we'll add an extra function for this purpose:

<<kernel functions>>=
void release_page_range (uint start_pageno, uint end_pageno) {
  for (int i = start_pageno; i < end_pageno+1; i++ )  release_page (i);    
};
@



\codesection{Memory Allocator for the Kernel}

As long as exactly one page of memory is required, the kernel can
get access to new memory by calling [[request_new_page]]. However,
since the kernel will often require memory areas which are smaller 
or larger than a page, we need a kernel memory allocator (and also
code that releases memory once it is not needed any longer).

Because of the similarity with the standard functions [[malloc]]
and [[free]] which deal with memory allocation in user space, we
will call the kernel functions [[kmalloc]] and [[kfree]].

kmalloc

Literature:

-- Linux Journal on kmalloc, \url{http://www.linuxjournal.com/article/6930}

\subsection{The most simple memory allocator}

We start with a very simple design that will get memory
allocation up and running: It will provide the needed services,
but will be all but efficient---which means: it will waste a
lot of memory.

For anything up to the size of a page, we will reserve a whole
page (via [[request_new_page]]) and return a pointer to its virtual 
address; for anything bigger we will reserve consecutive pages by 
repeatedly calling [[request_new_page]]. Note that it does not
matter what frames are going to be used: Only the pages need to
be consecutive so that the allocated memory looks like a
joined block of memory.

In principle the code for [[kmalloc]] could look like this:

<<code for kmalloc, version 1>>=
void* kmalloc (uint size) {
  void* pointer;
  int count = (size-1)/PAGE_SIZE + 1;
  <<allocate [[count]] consecutive pages, version 1>> 
  return pointer;
};
@

with

<<allocate [[count]] consecutive pages, version 1>>=
pointer = request_new_page (0);  // we need at least one page
while ( count > 1 ) {
  request_new_page (0);          // get another page if more is needed
  count--;
};
@

Try the loop for values such as [[PAGE_SIZE-1]], [[PAGE_SIZE]], and
[[PAGE_SIZE+1]] to see that this will work.

However, this code has a problem: if we intended to never return
memory, this would be OK, but since we also want to implement a
[[kfree]] function that takes only one argument (a pointer to
the beginning of the region to be freed), it cannot know how many
pages are to be freed.

So we need some space to store the length of the memory area.
(We could just store the number of pages, but since we are going
to recycle the following structure definition for a more advanced
memory allocator, we save the size as requested in the 
[[kmalloc]] call.) Since we are now creating a header, we will
add some extra fields that might be useful:

<<kernel declarations>>=
typedef struct kmalloc_header_struct {
  char magic_header[8];  // we'll put a magic string in here
  uint size;             // size of the allocated memory area
  uint reserved;         // for later use
  // gives a total of 16 bytes for the header
} kmalloc_header;
@

We'll put the header at the beginning of the allocated area---that
way, when we will later implement [[kfree]], we can just
skip 16 bytes back, read the header, and free memory appropriately.
Our default header is this:

<<kernel declarations>>=
#define KMALLOC_HEADER "ULIX_KM"
@

Our definition of [[kmalloc]] needs to change a bit: we need to
reserve the first 16 bytes for the header. So the code looks just
a tiny bit more complicated:

<<code for kmalloc, version 2>>=
void* kmalloc (uint size) {
  kmalloc_header kmhead;                  // this is the header
  kmhead.size = size;                     // write size from kmalloc call
  memcpy (&kmhead, KMALLOC_HEADER, 8);    // 8 chars (including terminating 0)
  
  void* pointer;
  size += 16;                             // we need 16 extra bytes
  int count = (size-1)/PAGE_SIZE + 1;
  <<allocate [[count]] consecutive pages, version 2>>

  memcpy (pointer, &kmhead, 16);          // copy header into new memory
  return (void*)((uint)pointer + 16);     // return pointer, offset 16
};
@

with

<<allocate [[count]] consecutive pages, version 2>>=

uint old_free_frames = free_frames;

pointer = request_new_page (0);         // we need at least one page
while ( count > 1 ) {
  set_statusline_hex(count);
  request_new_page (0);                 // get another page if more is needed
  count--;
  };

printf ("Difference in free_frames: -%d.\n", -free_frames+old_free_frames);

@

We're almost done. Remember that [[request_new_page]] can fail,
in that case it will return [[NULL]]. So we need to check that all
needed pages were successfully allocated---if not, we need to
undo what we did so far.

<<code for kmalloc, version 3>>=

// ...

@

Here's a correspondong [[kfree]] function: We start with checking
that the argument really points to a [[kmalloc]]'d memory area:

<<code for kfree, version 2>>=
void kfree (void* pointer) {
  kmalloc_header kmhead;                  // this is the header
  memcpy (&kmhead, pointer-16, 16);       // copy header from before pointer

  if ( !strcmp (KMALLOC_HEADER, (char*)&kmhead) ) {
    printf ("Error: p is not a kmalloc'ed area\n");
    return;
  }
@

Next, we overwrite the header so that the memory area will no
longer be recognized as [[kmalloc]]'d area, and we free as many
pages as required:

<<code for kfree, version 2>>=
  uint count = (kmhead.size+16-1)/PAGE_SIZE + 1;
  memcpy (pointer-16, "       ",8);  // copy 8 bytes
  uint old_free_frames = free_frames;
  printf ("kfree: Freeing %d pages.\n", count);
  uint page = ((uint)pointer - 16 ) / PAGE_SIZE;  // first page
  release_page_range (page, page+count-1);
  printf ("Difference in free_frames: %d.\n", free_frames-old_free_frames);

};
@




TEST: 
<<kernel functions>>=
<<code for kmalloc, version 2>>
<<code for kfree, version 2>>
@


Note that there is still a problem in this code:

\begin{work}

kmalloc may not be able to allocate consecutive pages, e.g. after this
sequence:

\begin{itemize}
\item [[a = kmalloc(1 k);]]   allocates page 1001
\item [[b = kmalloc(1 k);]]   allocates page 1002
\item [[c = kmalloc(1 k);]]   allocates page 1003
\item [[free(b)         ;]]   deallocates pages 1002
\item [[d = kmalloc(6 k);]]   allocates pages 1002 and 1004 -- problem
\end{itemize}

There's also a problem if a new page table is created on the fly
because it may sit in the middle of pages which were (otherwise
consecutively) requested for kmalloc.

Possible solution: change request-new-page function so that it
puts page tables in a special, reserved area of virtual memory.
\end{work}





\black


\codesection{\UlixI{} Implementation of Address Spaces}


\subsection{Creating a New Address Space}

Essentially, an address space is just a fresh page table. For
the kernel memory it looks like the initial page table.

{\small
\begin{verbatim}
                  Kernel 
                  Address Space  Address Space 1  Address Space 2

[    0 .. 3 GB [  unused         private (1)      private (2)
[ 3 GB .. 4 GB ]  Kernel         Kernel           Kernel
\end{verbatim}
}

(except: Video Memory!)

((We have 1024 page directory entries, pointing to 1024 page tables.
Each page table has 1024 PTEs, pointing to 1024 page frames.

That makes 1024 $\times$ 1024 = 1 M page frames. Each page frame
has size 4 KByte, which makes for 4 GByte of virtual memory.))


{\fontsize{3.42}{4}\selectfont
\begin{verbatim}
PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range  |  PD#      Virt. addr. range
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0000 000 00000000-003fffff  |  0128 080 20000000-203fffff  |  0256 100 40000000-403fffff  |  0384 180 60000000-603fffff  |  0512 200 80000000-803fffff  |  0640 280 a0000000-a03fffff  |  0768 300 c0000000-c03fffff  |  0896 380 e0000000-e03fffff
0001 001 00400000-007fffff  |  0129 081 20400000-207fffff  |  0257 101 40400000-407fffff  |  0385 181 60400000-607fffff  |  0513 201 80400000-807fffff  |  0641 281 a0400000-a07fffff  |  0769 301 c0400000-c07fffff  |  0897 381 e0400000-e07fffff
0002 002 00800000-00bfffff  |  0130 082 20800000-20bfffff  |  0258 102 40800000-40bfffff  |  0386 182 60800000-60bfffff  |  0514 202 80800000-80bfffff  |  0642 282 a0800000-a0bfffff  |  0770 302 c0800000-c0bfffff  |  0898 382 e0800000-e0bfffff
0003 003 00c00000-00ffffff  |  0131 083 20c00000-20ffffff  |  0259 103 40c00000-40ffffff  |  0387 183 60c00000-60ffffff  |  0515 203 80c00000-80ffffff  |  0643 283 a0c00000-a0ffffff  |  0771 303 c0c00000-c0ffffff  |  0899 383 e0c00000-e0ffffff
0004 004 01000000-013fffff  |  0132 084 21000000-213fffff  |  0260 104 41000000-413fffff  |  0388 184 61000000-613fffff  |  0516 204 81000000-813fffff  |  0644 284 a1000000-a13fffff  |  0772 304 c1000000-c13fffff  |  0900 384 e1000000-e13fffff
0005 005 01400000-017fffff  |  0133 085 21400000-217fffff  |  0261 105 41400000-417fffff  |  0389 185 61400000-617fffff  |  0517 205 81400000-817fffff  |  0645 285 a1400000-a17fffff  |  0773 305 c1400000-c17fffff  |  0901 385 e1400000-e17fffff
0006 006 01800000-01bfffff  |  0134 086 21800000-21bfffff  |  0262 106 41800000-41bfffff  |  0390 186 61800000-61bfffff  |  0518 206 81800000-81bfffff  |  0646 286 a1800000-a1bfffff  |  0774 306 c1800000-c1bfffff  |  0902 386 e1800000-e1bfffff
0007 007 01c00000-01ffffff  |  0135 087 21c00000-21ffffff  |  0263 107 41c00000-41ffffff  |  0391 187 61c00000-61ffffff  |  0519 207 81c00000-81ffffff  |  0647 287 a1c00000-a1ffffff  |  0775 307 c1c00000-c1ffffff  |  0903 387 e1c00000-e1ffffff
0008 008 02000000-023fffff  |  0136 088 22000000-223fffff  |  0264 108 42000000-423fffff  |  0392 188 62000000-623fffff  |  0520 208 82000000-823fffff  |  0648 288 a2000000-a23fffff  |  0776 308 c2000000-c23fffff  |  0904 388 e2000000-e23fffff
0009 009 02400000-027fffff  |  0137 089 22400000-227fffff  |  0265 109 42400000-427fffff  |  0393 189 62400000-627fffff  |  0521 209 82400000-827fffff  |  0649 289 a2400000-a27fffff  |  0777 309 c2400000-c27fffff  |  0905 389 e2400000-e27fffff
0010 00a 02800000-02bfffff  |  0138 08a 22800000-22bfffff  |  0266 10a 42800000-42bfffff  |  0394 18a 62800000-62bfffff  |  0522 20a 82800000-82bfffff  |  0650 28a a2800000-a2bfffff  |  0778 30a c2800000-c2bfffff  |  0906 38a e2800000-e2bfffff
0011 00b 02c00000-02ffffff  |  0139 08b 22c00000-22ffffff  |  0267 10b 42c00000-42ffffff  |  0395 18b 62c00000-62ffffff  |  0523 20b 82c00000-82ffffff  |  0651 28b a2c00000-a2ffffff  |  0779 30b c2c00000-c2ffffff  |  0907 38b e2c00000-e2ffffff
0012 00c 03000000-033fffff  |  0140 08c 23000000-233fffff  |  0268 10c 43000000-433fffff  |  0396 18c 63000000-633fffff  |  0524 20c 83000000-833fffff  |  0652 28c a3000000-a33fffff  |  0780 30c c3000000-c33fffff  |  0908 38c e3000000-e33fffff
0013 00d 03400000-037fffff  |  0141 08d 23400000-237fffff  |  0269 10d 43400000-437fffff  |  0397 18d 63400000-637fffff  |  0525 20d 83400000-837fffff  |  0653 28d a3400000-a37fffff  |  0781 30d c3400000-c37fffff  |  0909 38d e3400000-e37fffff
0014 00e 03800000-03bfffff  |  0142 08e 23800000-23bfffff  |  0270 10e 43800000-43bfffff  |  0398 18e 63800000-63bfffff  |  0526 20e 83800000-83bfffff  |  0654 28e a3800000-a3bfffff  |  0782 30e c3800000-c3bfffff  |  0910 38e e3800000-e3bfffff
0015 00f 03c00000-03ffffff  |  0143 08f 23c00000-23ffffff  |  0271 10f 43c00000-43ffffff  |  0399 18f 63c00000-63ffffff  |  0527 20f 83c00000-83ffffff  |  0655 28f a3c00000-a3ffffff  |  0783 30f c3c00000-c3ffffff  |  0911 38f e3c00000-e3ffffff
0016 010 04000000-043fffff  |  0144 090 24000000-243fffff  |  0272 110 44000000-443fffff  |  0400 190 64000000-643fffff  |  0528 210 84000000-843fffff  |  0656 290 a4000000-a43fffff  |  0784 310 c4000000-c43fffff  |  0912 390 e4000000-e43fffff
0017 011 04400000-047fffff  |  0145 091 24400000-247fffff  |  0273 111 44400000-447fffff  |  0401 191 64400000-647fffff  |  0529 211 84400000-847fffff  |  0657 291 a4400000-a47fffff  |  0785 311 c4400000-c47fffff  |  0913 391 e4400000-e47fffff
0018 012 04800000-04bfffff  |  0146 092 24800000-24bfffff  |  0274 112 44800000-44bfffff  |  0402 192 64800000-64bfffff  |  0530 212 84800000-84bfffff  |  0658 292 a4800000-a4bfffff  |  0786 312 c4800000-c4bfffff  |  0914 392 e4800000-e4bfffff
0019 013 04c00000-04ffffff  |  0147 093 24c00000-24ffffff  |  0275 113 44c00000-44ffffff  |  0403 193 64c00000-64ffffff  |  0531 213 84c00000-84ffffff  |  0659 293 a4c00000-a4ffffff  |  0787 313 c4c00000-c4ffffff  |  0915 393 e4c00000-e4ffffff
0020 014 05000000-053fffff  |  0148 094 25000000-253fffff  |  0276 114 45000000-453fffff  |  0404 194 65000000-653fffff  |  0532 214 85000000-853fffff  |  0660 294 a5000000-a53fffff  |  0788 314 c5000000-c53fffff  |  0916 394 e5000000-e53fffff
0021 015 05400000-057fffff  |  0149 095 25400000-257fffff  |  0277 115 45400000-457fffff  |  0405 195 65400000-657fffff  |  0533 215 85400000-857fffff  |  0661 295 a5400000-a57fffff  |  0789 315 c5400000-c57fffff  |  0917 395 e5400000-e57fffff
0022 016 05800000-05bfffff  |  0150 096 25800000-25bfffff  |  0278 116 45800000-45bfffff  |  0406 196 65800000-65bfffff  |  0534 216 85800000-85bfffff  |  0662 296 a5800000-a5bfffff  |  0790 316 c5800000-c5bfffff  |  0918 396 e5800000-e5bfffff
0023 017 05c00000-05ffffff  |  0151 097 25c00000-25ffffff  |  0279 117 45c00000-45ffffff  |  0407 197 65c00000-65ffffff  |  0535 217 85c00000-85ffffff  |  0663 297 a5c00000-a5ffffff  |  0791 317 c5c00000-c5ffffff  |  0919 397 e5c00000-e5ffffff
0024 018 06000000-063fffff  |  0152 098 26000000-263fffff  |  0280 118 46000000-463fffff  |  0408 198 66000000-663fffff  |  0536 218 86000000-863fffff  |  0664 298 a6000000-a63fffff  |  0792 318 c6000000-c63fffff  |  0920 398 e6000000-e63fffff
0025 019 06400000-067fffff  |  0153 099 26400000-267fffff  |  0281 119 46400000-467fffff  |  0409 199 66400000-667fffff  |  0537 219 86400000-867fffff  |  0665 299 a6400000-a67fffff  |  0793 319 c6400000-c67fffff  |  0921 399 e6400000-e67fffff
0026 01a 06800000-06bfffff  |  0154 09a 26800000-26bfffff  |  0282 11a 46800000-46bfffff  |  0410 19a 66800000-66bfffff  |  0538 21a 86800000-86bfffff  |  0666 29a a6800000-a6bfffff  |  0794 31a c6800000-c6bfffff  |  0922 39a e6800000-e6bfffff
0027 01b 06c00000-06ffffff  |  0155 09b 26c00000-26ffffff  |  0283 11b 46c00000-46ffffff  |  0411 19b 66c00000-66ffffff  |  0539 21b 86c00000-86ffffff  |  0667 29b a6c00000-a6ffffff  |  0795 31b c6c00000-c6ffffff  |  0923 39b e6c00000-e6ffffff
0028 01c 07000000-073fffff  |  0156 09c 27000000-273fffff  |  0284 11c 47000000-473fffff  |  0412 19c 67000000-673fffff  |  0540 21c 87000000-873fffff  |  0668 29c a7000000-a73fffff  |  0796 31c c7000000-c73fffff  |  0924 39c e7000000-e73fffff
0029 01d 07400000-077fffff  |  0157 09d 27400000-277fffff  |  0285 11d 47400000-477fffff  |  0413 19d 67400000-677fffff  |  0541 21d 87400000-877fffff  |  0669 29d a7400000-a77fffff  |  0797 31d c7400000-c77fffff  |  0925 39d e7400000-e77fffff
0030 01e 07800000-07bfffff  |  0158 09e 27800000-27bfffff  |  0286 11e 47800000-47bfffff  |  0414 19e 67800000-67bfffff  |  0542 21e 87800000-87bfffff  |  0670 29e a7800000-a7bfffff  |  0798 31e c7800000-c7bfffff  |  0926 39e e7800000-e7bfffff
0031 01f 07c00000-07ffffff  |  0159 09f 27c00000-27ffffff  |  0287 11f 47c00000-47ffffff  |  0415 19f 67c00000-67ffffff  |  0543 21f 87c00000-87ffffff  |  0671 29f a7c00000-a7ffffff  |  0799 31f c7c00000-c7ffffff  |  0927 39f e7c00000-e7ffffff
0032 020 08000000-083fffff  |  0160 0a0 28000000-283fffff  |  0288 120 48000000-483fffff  |  0416 1a0 68000000-683fffff  |  0544 220 88000000-883fffff  |  0672 2a0 a8000000-a83fffff  |  0800 320 c8000000-c83fffff  |  0928 3a0 e8000000-e83fffff
0033 021 08400000-087fffff  |  0161 0a1 28400000-287fffff  |  0289 121 48400000-487fffff  |  0417 1a1 68400000-687fffff  |  0545 221 88400000-887fffff  |  0673 2a1 a8400000-a87fffff  |  0801 321 c8400000-c87fffff  |  0929 3a1 e8400000-e87fffff
0034 022 08800000-08bfffff  |  0162 0a2 28800000-28bfffff  |  0290 122 48800000-48bfffff  |  0418 1a2 68800000-68bfffff  |  0546 222 88800000-88bfffff  |  0674 2a2 a8800000-a8bfffff  |  0802 322 c8800000-c8bfffff  |  0930 3a2 e8800000-e8bfffff
0035 023 08c00000-08ffffff  |  0163 0a3 28c00000-28ffffff  |  0291 123 48c00000-48ffffff  |  0419 1a3 68c00000-68ffffff  |  0547 223 88c00000-88ffffff  |  0675 2a3 a8c00000-a8ffffff  |  0803 323 c8c00000-c8ffffff  |  0931 3a3 e8c00000-e8ffffff
0036 024 09000000-093fffff  |  0164 0a4 29000000-293fffff  |  0292 124 49000000-493fffff  |  0420 1a4 69000000-693fffff  |  0548 224 89000000-893fffff  |  0676 2a4 a9000000-a93fffff  |  0804 324 c9000000-c93fffff  |  0932 3a4 e9000000-e93fffff
0037 025 09400000-097fffff  |  0165 0a5 29400000-297fffff  |  0293 125 49400000-497fffff  |  0421 1a5 69400000-697fffff  |  0549 225 89400000-897fffff  |  0677 2a5 a9400000-a97fffff  |  0805 325 c9400000-c97fffff  |  0933 3a5 e9400000-e97fffff
0038 026 09800000-09bfffff  |  0166 0a6 29800000-29bfffff  |  0294 126 49800000-49bfffff  |  0422 1a6 69800000-69bfffff  |  0550 226 89800000-89bfffff  |  0678 2a6 a9800000-a9bfffff  |  0806 326 c9800000-c9bfffff  |  0934 3a6 e9800000-e9bfffff
0039 027 09c00000-09ffffff  |  0167 0a7 29c00000-29ffffff  |  0295 127 49c00000-49ffffff  |  0423 1a7 69c00000-69ffffff  |  0551 227 89c00000-89ffffff  |  0679 2a7 a9c00000-a9ffffff  |  0807 327 c9c00000-c9ffffff  |  0935 3a7 e9c00000-e9ffffff
0040 028 0a000000-0a3fffff  |  0168 0a8 2a000000-2a3fffff  |  0296 128 4a000000-4a3fffff  |  0424 1a8 6a000000-6a3fffff  |  0552 228 8a000000-8a3fffff  |  0680 2a8 aa000000-aa3fffff  |  0808 328 ca000000-ca3fffff  |  0936 3a8 ea000000-ea3fffff
0041 029 0a400000-0a7fffff  |  0169 0a9 2a400000-2a7fffff  |  0297 129 4a400000-4a7fffff  |  0425 1a9 6a400000-6a7fffff  |  0553 229 8a400000-8a7fffff  |  0681 2a9 aa400000-aa7fffff  |  0809 329 ca400000-ca7fffff  |  0937 3a9 ea400000-ea7fffff
0042 02a 0a800000-0abfffff  |  0170 0aa 2a800000-2abfffff  |  0298 12a 4a800000-4abfffff  |  0426 1aa 6a800000-6abfffff  |  0554 22a 8a800000-8abfffff  |  0682 2aa aa800000-aabfffff  |  0810 32a ca800000-cabfffff  |  0938 3aa ea800000-eabfffff
0043 02b 0ac00000-0affffff  |  0171 0ab 2ac00000-2affffff  |  0299 12b 4ac00000-4affffff  |  0427 1ab 6ac00000-6affffff  |  0555 22b 8ac00000-8affffff  |  0683 2ab aac00000-aaffffff  |  0811 32b cac00000-caffffff  |  0939 3ab eac00000-eaffffff
0044 02c 0b000000-0b3fffff  |  0172 0ac 2b000000-2b3fffff  |  0300 12c 4b000000-4b3fffff  |  0428 1ac 6b000000-6b3fffff  |  0556 22c 8b000000-8b3fffff  |  0684 2ac ab000000-ab3fffff  |  0812 32c cb000000-cb3fffff  |  0940 3ac eb000000-eb3fffff
0045 02d 0b400000-0b7fffff  |  0173 0ad 2b400000-2b7fffff  |  0301 12d 4b400000-4b7fffff  |  0429 1ad 6b400000-6b7fffff  |  0557 22d 8b400000-8b7fffff  |  0685 2ad ab400000-ab7fffff  |  0813 32d cb400000-cb7fffff  |  0941 3ad eb400000-eb7fffff
0046 02e 0b800000-0bbfffff  |  0174 0ae 2b800000-2bbfffff  |  0302 12e 4b800000-4bbfffff  |  0430 1ae 6b800000-6bbfffff  |  0558 22e 8b800000-8bbfffff  |  0686 2ae ab800000-abbfffff  |  0814 32e cb800000-cbbfffff  |  0942 3ae eb800000-ebbfffff
0047 02f 0bc00000-0bffffff  |  0175 0af 2bc00000-2bffffff  |  0303 12f 4bc00000-4bffffff  |  0431 1af 6bc00000-6bffffff  |  0559 22f 8bc00000-8bffffff  |  0687 2af abc00000-abffffff  |  0815 32f cbc00000-cbffffff  |  0943 3af ebc00000-ebffffff
0048 030 0c000000-0c3fffff  |  0176 0b0 2c000000-2c3fffff  |  0304 130 4c000000-4c3fffff  |  0432 1b0 6c000000-6c3fffff  |  0560 230 8c000000-8c3fffff  |  0688 2b0 ac000000-ac3fffff  |  0816 330 cc000000-cc3fffff  |  0944 3b0 ec000000-ec3fffff
0049 031 0c400000-0c7fffff  |  0177 0b1 2c400000-2c7fffff  |  0305 131 4c400000-4c7fffff  |  0433 1b1 6c400000-6c7fffff  |  0561 231 8c400000-8c7fffff  |  0689 2b1 ac400000-ac7fffff  |  0817 331 cc400000-cc7fffff  |  0945 3b1 ec400000-ec7fffff
0050 032 0c800000-0cbfffff  |  0178 0b2 2c800000-2cbfffff  |  0306 132 4c800000-4cbfffff  |  0434 1b2 6c800000-6cbfffff  |  0562 232 8c800000-8cbfffff  |  0690 2b2 ac800000-acbfffff  |  0818 332 cc800000-ccbfffff  |  0946 3b2 ec800000-ecbfffff
0051 033 0cc00000-0cffffff  |  0179 0b3 2cc00000-2cffffff  |  0307 133 4cc00000-4cffffff  |  0435 1b3 6cc00000-6cffffff  |  0563 233 8cc00000-8cffffff  |  0691 2b3 acc00000-acffffff  |  0819 333 ccc00000-ccffffff  |  0947 3b3 ecc00000-ecffffff
0052 034 0d000000-0d3fffff  |  0180 0b4 2d000000-2d3fffff  |  0308 134 4d000000-4d3fffff  |  0436 1b4 6d000000-6d3fffff  |  0564 234 8d000000-8d3fffff  |  0692 2b4 ad000000-ad3fffff  |  0820 334 cd000000-cd3fffff  |  0948 3b4 ed000000-ed3fffff
0053 035 0d400000-0d7fffff  |  0181 0b5 2d400000-2d7fffff  |  0309 135 4d400000-4d7fffff  |  0437 1b5 6d400000-6d7fffff  |  0565 235 8d400000-8d7fffff  |  0693 2b5 ad400000-ad7fffff  |  0821 335 cd400000-cd7fffff  |  0949 3b5 ed400000-ed7fffff
0054 036 0d800000-0dbfffff  |  0182 0b6 2d800000-2dbfffff  |  0310 136 4d800000-4dbfffff  |  0438 1b6 6d800000-6dbfffff  |  0566 236 8d800000-8dbfffff  |  0694 2b6 ad800000-adbfffff  |  0822 336 cd800000-cdbfffff  |  0950 3b6 ed800000-edbfffff
0055 037 0dc00000-0dffffff  |  0183 0b7 2dc00000-2dffffff  |  0311 137 4dc00000-4dffffff  |  0439 1b7 6dc00000-6dffffff  |  0567 237 8dc00000-8dffffff  |  0695 2b7 adc00000-adffffff  |  0823 337 cdc00000-cdffffff  |  0951 3b7 edc00000-edffffff
0056 038 0e000000-0e3fffff  |  0184 0b8 2e000000-2e3fffff  |  0312 138 4e000000-4e3fffff  |  0440 1b8 6e000000-6e3fffff  |  0568 238 8e000000-8e3fffff  |  0696 2b8 ae000000-ae3fffff  |  0824 338 ce000000-ce3fffff  |  0952 3b8 ee000000-ee3fffff
0057 039 0e400000-0e7fffff  |  0185 0b9 2e400000-2e7fffff  |  0313 139 4e400000-4e7fffff  |  0441 1b9 6e400000-6e7fffff  |  0569 239 8e400000-8e7fffff  |  0697 2b9 ae400000-ae7fffff  |  0825 339 ce400000-ce7fffff  |  0953 3b9 ee400000-ee7fffff
0058 03a 0e800000-0ebfffff  |  0186 0ba 2e800000-2ebfffff  |  0314 13a 4e800000-4ebfffff  |  0442 1ba 6e800000-6ebfffff  |  0570 23a 8e800000-8ebfffff  |  0698 2ba ae800000-aebfffff  |  0826 33a ce800000-cebfffff  |  0954 3ba ee800000-eebfffff
0059 03b 0ec00000-0effffff  |  0187 0bb 2ec00000-2effffff  |  0315 13b 4ec00000-4effffff  |  0443 1bb 6ec00000-6effffff  |  0571 23b 8ec00000-8effffff  |  0699 2bb aec00000-aeffffff  |  0827 33b cec00000-ceffffff  |  0955 3bb eec00000-eeffffff
0060 03c 0f000000-0f3fffff  |  0188 0bc 2f000000-2f3fffff  |  0316 13c 4f000000-4f3fffff  |  0444 1bc 6f000000-6f3fffff  |  0572 23c 8f000000-8f3fffff  |  0700 2bc af000000-af3fffff  |  0828 33c cf000000-cf3fffff  |  0956 3bc ef000000-ef3fffff
0061 03d 0f400000-0f7fffff  |  0189 0bd 2f400000-2f7fffff  |  0317 13d 4f400000-4f7fffff  |  0445 1bd 6f400000-6f7fffff  |  0573 23d 8f400000-8f7fffff  |  0701 2bd af400000-af7fffff  |  0829 33d cf400000-cf7fffff  |  0957 3bd ef400000-ef7fffff
0062 03e 0f800000-0fbfffff  |  0190 0be 2f800000-2fbfffff  |  0318 13e 4f800000-4fbfffff  |  0446 1be 6f800000-6fbfffff  |  0574 23e 8f800000-8fbfffff  |  0702 2be af800000-afbfffff  |  0830 33e cf800000-cfbfffff  |  0958 3be ef800000-efbfffff
0063 03f 0fc00000-0fffffff  |  0191 0bf 2fc00000-2fffffff  |  0319 13f 4fc00000-4fffffff  |  0447 1bf 6fc00000-6fffffff  |  0575 23f 8fc00000-8fffffff  |  0703 2bf afc00000-afffffff  |  0831 33f cfc00000-cfffffff  |  0959 3bf efc00000-efffffff
0064 040 10000000-103fffff  |  0192 0c0 30000000-303fffff  |  0320 140 50000000-503fffff  |  0448 1c0 70000000-703fffff  |  0576 240 90000000-903fffff  |  0704 2c0 b0000000-b03fffff  |  0832 340 d0000000-d03fffff  |  0960 3c0 f0000000-f03fffff
0065 041 10400000-107fffff  |  0193 0c1 30400000-307fffff  |  0321 141 50400000-507fffff  |  0449 1c1 70400000-707fffff  |  0577 241 90400000-907fffff  |  0705 2c1 b0400000-b07fffff  |  0833 341 d0400000-d07fffff  |  0961 3c1 f0400000-f07fffff
0066 042 10800000-10bfffff  |  0194 0c2 30800000-30bfffff  |  0322 142 50800000-50bfffff  |  0450 1c2 70800000-70bfffff  |  0578 242 90800000-90bfffff  |  0706 2c2 b0800000-b0bfffff  |  0834 342 d0800000-d0bfffff  |  0962 3c2 f0800000-f0bfffff
0067 043 10c00000-10ffffff  |  0195 0c3 30c00000-30ffffff  |  0323 143 50c00000-50ffffff  |  0451 1c3 70c00000-70ffffff  |  0579 243 90c00000-90ffffff  |  0707 2c3 b0c00000-b0ffffff  |  0835 343 d0c00000-d0ffffff  |  0963 3c3 f0c00000-f0ffffff
0068 044 11000000-113fffff  |  0196 0c4 31000000-313fffff  |  0324 144 51000000-513fffff  |  0452 1c4 71000000-713fffff  |  0580 244 91000000-913fffff  |  0708 2c4 b1000000-b13fffff  |  0836 344 d1000000-d13fffff  |  0964 3c4 f1000000-f13fffff
0069 045 11400000-117fffff  |  0197 0c5 31400000-317fffff  |  0325 145 51400000-517fffff  |  0453 1c5 71400000-717fffff  |  0581 245 91400000-917fffff  |  0709 2c5 b1400000-b17fffff  |  0837 345 d1400000-d17fffff  |  0965 3c5 f1400000-f17fffff
0070 046 11800000-11bfffff  |  0198 0c6 31800000-31bfffff  |  0326 146 51800000-51bfffff  |  0454 1c6 71800000-71bfffff  |  0582 246 91800000-91bfffff  |  0710 2c6 b1800000-b1bfffff  |  0838 346 d1800000-d1bfffff  |  0966 3c6 f1800000-f1bfffff
0071 047 11c00000-11ffffff  |  0199 0c7 31c00000-31ffffff  |  0327 147 51c00000-51ffffff  |  0455 1c7 71c00000-71ffffff  |  0583 247 91c00000-91ffffff  |  0711 2c7 b1c00000-b1ffffff  |  0839 347 d1c00000-d1ffffff  |  0967 3c7 f1c00000-f1ffffff
0072 048 12000000-123fffff  |  0200 0c8 32000000-323fffff  |  0328 148 52000000-523fffff  |  0456 1c8 72000000-723fffff  |  0584 248 92000000-923fffff  |  0712 2c8 b2000000-b23fffff  |  0840 348 d2000000-d23fffff  |  0968 3c8 f2000000-f23fffff
0073 049 12400000-127fffff  |  0201 0c9 32400000-327fffff  |  0329 149 52400000-527fffff  |  0457 1c9 72400000-727fffff  |  0585 249 92400000-927fffff  |  0713 2c9 b2400000-b27fffff  |  0841 349 d2400000-d27fffff  |  0969 3c9 f2400000-f27fffff
0074 04a 12800000-12bfffff  |  0202 0ca 32800000-32bfffff  |  0330 14a 52800000-52bfffff  |  0458 1ca 72800000-72bfffff  |  0586 24a 92800000-92bfffff  |  0714 2ca b2800000-b2bfffff  |  0842 34a d2800000-d2bfffff  |  0970 3ca f2800000-f2bfffff
0075 04b 12c00000-12ffffff  |  0203 0cb 32c00000-32ffffff  |  0331 14b 52c00000-52ffffff  |  0459 1cb 72c00000-72ffffff  |  0587 24b 92c00000-92ffffff  |  0715 2cb b2c00000-b2ffffff  |  0843 34b d2c00000-d2ffffff  |  0971 3cb f2c00000-f2ffffff
0076 04c 13000000-133fffff  |  0204 0cc 33000000-333fffff  |  0332 14c 53000000-533fffff  |  0460 1cc 73000000-733fffff  |  0588 24c 93000000-933fffff  |  0716 2cc b3000000-b33fffff  |  0844 34c d3000000-d33fffff  |  0972 3cc f3000000-f33fffff
0077 04d 13400000-137fffff  |  0205 0cd 33400000-337fffff  |  0333 14d 53400000-537fffff  |  0461 1cd 73400000-737fffff  |  0589 24d 93400000-937fffff  |  0717 2cd b3400000-b37fffff  |  0845 34d d3400000-d37fffff  |  0973 3cd f3400000-f37fffff
0078 04e 13800000-13bfffff  |  0206 0ce 33800000-33bfffff  |  0334 14e 53800000-53bfffff  |  0462 1ce 73800000-73bfffff  |  0590 24e 93800000-93bfffff  |  0718 2ce b3800000-b3bfffff  |  0846 34e d3800000-d3bfffff  |  0974 3ce f3800000-f3bfffff
0079 04f 13c00000-13ffffff  |  0207 0cf 33c00000-33ffffff  |  0335 14f 53c00000-53ffffff  |  0463 1cf 73c00000-73ffffff  |  0591 24f 93c00000-93ffffff  |  0719 2cf b3c00000-b3ffffff  |  0847 34f d3c00000-d3ffffff  |  0975 3cf f3c00000-f3ffffff
0080 050 14000000-143fffff  |  0208 0d0 34000000-343fffff  |  0336 150 54000000-543fffff  |  0464 1d0 74000000-743fffff  |  0592 250 94000000-943fffff  |  0720 2d0 b4000000-b43fffff  |  0848 350 d4000000-d43fffff  |  0976 3d0 f4000000-f43fffff
0081 051 14400000-147fffff  |  0209 0d1 34400000-347fffff  |  0337 151 54400000-547fffff  |  0465 1d1 74400000-747fffff  |  0593 251 94400000-947fffff  |  0721 2d1 b4400000-b47fffff  |  0849 351 d4400000-d47fffff  |  0977 3d1 f4400000-f47fffff
0082 052 14800000-14bfffff  |  0210 0d2 34800000-34bfffff  |  0338 152 54800000-54bfffff  |  0466 1d2 74800000-74bfffff  |  0594 252 94800000-94bfffff  |  0722 2d2 b4800000-b4bfffff  |  0850 352 d4800000-d4bfffff  |  0978 3d2 f4800000-f4bfffff
0083 053 14c00000-14ffffff  |  0211 0d3 34c00000-34ffffff  |  0339 153 54c00000-54ffffff  |  0467 1d3 74c00000-74ffffff  |  0595 253 94c00000-94ffffff  |  0723 2d3 b4c00000-b4ffffff  |  0851 353 d4c00000-d4ffffff  |  0979 3d3 f4c00000-f4ffffff
0084 054 15000000-153fffff  |  0212 0d4 35000000-353fffff  |  0340 154 55000000-553fffff  |  0468 1d4 75000000-753fffff  |  0596 254 95000000-953fffff  |  0724 2d4 b5000000-b53fffff  |  0852 354 d5000000-d53fffff  |  0980 3d4 f5000000-f53fffff
0085 055 15400000-157fffff  |  0213 0d5 35400000-357fffff  |  0341 155 55400000-557fffff  |  0469 1d5 75400000-757fffff  |  0597 255 95400000-957fffff  |  0725 2d5 b5400000-b57fffff  |  0853 355 d5400000-d57fffff  |  0981 3d5 f5400000-f57fffff
0086 056 15800000-15bfffff  |  0214 0d6 35800000-35bfffff  |  0342 156 55800000-55bfffff  |  0470 1d6 75800000-75bfffff  |  0598 256 95800000-95bfffff  |  0726 2d6 b5800000-b5bfffff  |  0854 356 d5800000-d5bfffff  |  0982 3d6 f5800000-f5bfffff
0087 057 15c00000-15ffffff  |  0215 0d7 35c00000-35ffffff  |  0343 157 55c00000-55ffffff  |  0471 1d7 75c00000-75ffffff  |  0599 257 95c00000-95ffffff  |  0727 2d7 b5c00000-b5ffffff  |  0855 357 d5c00000-d5ffffff  |  0983 3d7 f5c00000-f5ffffff
0088 058 16000000-163fffff  |  0216 0d8 36000000-363fffff  |  0344 158 56000000-563fffff  |  0472 1d8 76000000-763fffff  |  0600 258 96000000-963fffff  |  0728 2d8 b6000000-b63fffff  |  0856 358 d6000000-d63fffff  |  0984 3d8 f6000000-f63fffff
0089 059 16400000-167fffff  |  0217 0d9 36400000-367fffff  |  0345 159 56400000-567fffff  |  0473 1d9 76400000-767fffff  |  0601 259 96400000-967fffff  |  0729 2d9 b6400000-b67fffff  |  0857 359 d6400000-d67fffff  |  0985 3d9 f6400000-f67fffff
0090 05a 16800000-16bfffff  |  0218 0da 36800000-36bfffff  |  0346 15a 56800000-56bfffff  |  0474 1da 76800000-76bfffff  |  0602 25a 96800000-96bfffff  |  0730 2da b6800000-b6bfffff  |  0858 35a d6800000-d6bfffff  |  0986 3da f6800000-f6bfffff
0091 05b 16c00000-16ffffff  |  0219 0db 36c00000-36ffffff  |  0347 15b 56c00000-56ffffff  |  0475 1db 76c00000-76ffffff  |  0603 25b 96c00000-96ffffff  |  0731 2db b6c00000-b6ffffff  |  0859 35b d6c00000-d6ffffff  |  0987 3db f6c00000-f6ffffff
0092 05c 17000000-173fffff  |  0220 0dc 37000000-373fffff  |  0348 15c 57000000-573fffff  |  0476 1dc 77000000-773fffff  |  0604 25c 97000000-973fffff  |  0732 2dc b7000000-b73fffff  |  0860 35c d7000000-d73fffff  |  0988 3dc f7000000-f73fffff
0093 05d 17400000-177fffff  |  0221 0dd 37400000-377fffff  |  0349 15d 57400000-577fffff  |  0477 1dd 77400000-777fffff  |  0605 25d 97400000-977fffff  |  0733 2dd b7400000-b77fffff  |  0861 35d d7400000-d77fffff  |  0989 3dd f7400000-f77fffff
0094 05e 17800000-17bfffff  |  0222 0de 37800000-37bfffff  |  0350 15e 57800000-57bfffff  |  0478 1de 77800000-77bfffff  |  0606 25e 97800000-97bfffff  |  0734 2de b7800000-b7bfffff  |  0862 35e d7800000-d7bfffff  |  0990 3de f7800000-f7bfffff
0095 05f 17c00000-17ffffff  |  0223 0df 37c00000-37ffffff  |  0351 15f 57c00000-57ffffff  |  0479 1df 77c00000-77ffffff  |  0607 25f 97c00000-97ffffff  |  0735 2df b7c00000-b7ffffff  |  0863 35f d7c00000-d7ffffff  |  0991 3df f7c00000-f7ffffff
0096 060 18000000-183fffff  |  0224 0e0 38000000-383fffff  |  0352 160 58000000-583fffff  |  0480 1e0 78000000-783fffff  |  0608 260 98000000-983fffff  |  0736 2e0 b8000000-b83fffff  |  0864 360 d8000000-d83fffff  |  0992 3e0 f8000000-f83fffff
0097 061 18400000-187fffff  |  0225 0e1 38400000-387fffff  |  0353 161 58400000-587fffff  |  0481 1e1 78400000-787fffff  |  0609 261 98400000-987fffff  |  0737 2e1 b8400000-b87fffff  |  0865 361 d8400000-d87fffff  |  0993 3e1 f8400000-f87fffff
0098 062 18800000-18bfffff  |  0226 0e2 38800000-38bfffff  |  0354 162 58800000-58bfffff  |  0482 1e2 78800000-78bfffff  |  0610 262 98800000-98bfffff  |  0738 2e2 b8800000-b8bfffff  |  0866 362 d8800000-d8bfffff  |  0994 3e2 f8800000-f8bfffff
0099 063 18c00000-18ffffff  |  0227 0e3 38c00000-38ffffff  |  0355 163 58c00000-58ffffff  |  0483 1e3 78c00000-78ffffff  |  0611 263 98c00000-98ffffff  |  0739 2e3 b8c00000-b8ffffff  |  0867 363 d8c00000-d8ffffff  |  0995 3e3 f8c00000-f8ffffff
0100 064 19000000-193fffff  |  0228 0e4 39000000-393fffff  |  0356 164 59000000-593fffff  |  0484 1e4 79000000-793fffff  |  0612 264 99000000-993fffff  |  0740 2e4 b9000000-b93fffff  |  0868 364 d9000000-d93fffff  |  0996 3e4 f9000000-f93fffff
0101 065 19400000-197fffff  |  0229 0e5 39400000-397fffff  |  0357 165 59400000-597fffff  |  0485 1e5 79400000-797fffff  |  0613 265 99400000-997fffff  |  0741 2e5 b9400000-b97fffff  |  0869 365 d9400000-d97fffff  |  0997 3e5 f9400000-f97fffff
0102 066 19800000-19bfffff  |  0230 0e6 39800000-39bfffff  |  0358 166 59800000-59bfffff  |  0486 1e6 79800000-79bfffff  |  0614 266 99800000-99bfffff  |  0742 2e6 b9800000-b9bfffff  |  0870 366 d9800000-d9bfffff  |  0998 3e6 f9800000-f9bfffff
0103 067 19c00000-19ffffff  |  0231 0e7 39c00000-39ffffff  |  0359 167 59c00000-59ffffff  |  0487 1e7 79c00000-79ffffff  |  0615 267 99c00000-99ffffff  |  0743 2e7 b9c00000-b9ffffff  |  0871 367 d9c00000-d9ffffff  |  0999 3e7 f9c00000-f9ffffff
0104 068 1a000000-1a3fffff  |  0232 0e8 3a000000-3a3fffff  |  0360 168 5a000000-5a3fffff  |  0488 1e8 7a000000-7a3fffff  |  0616 268 9a000000-9a3fffff  |  0744 2e8 ba000000-ba3fffff  |  0872 368 da000000-da3fffff  |  1000 3e8 fa000000-fa3fffff
0105 069 1a400000-1a7fffff  |  0233 0e9 3a400000-3a7fffff  |  0361 169 5a400000-5a7fffff  |  0489 1e9 7a400000-7a7fffff  |  0617 269 9a400000-9a7fffff  |  0745 2e9 ba400000-ba7fffff  |  0873 369 da400000-da7fffff  |  1001 3e9 fa400000-fa7fffff
0106 06a 1a800000-1abfffff  |  0234 0ea 3a800000-3abfffff  |  0362 16a 5a800000-5abfffff  |  0490 1ea 7a800000-7abfffff  |  0618 26a 9a800000-9abfffff  |  0746 2ea ba800000-babfffff  |  0874 36a da800000-dabfffff  |  1002 3ea fa800000-fabfffff
0107 06b 1ac00000-1affffff  |  0235 0eb 3ac00000-3affffff  |  0363 16b 5ac00000-5affffff  |  0491 1eb 7ac00000-7affffff  |  0619 26b 9ac00000-9affffff  |  0747 2eb bac00000-baffffff  |  0875 36b dac00000-daffffff  |  1003 3eb fac00000-faffffff
0108 06c 1b000000-1b3fffff  |  0236 0ec 3b000000-3b3fffff  |  0364 16c 5b000000-5b3fffff  |  0492 1ec 7b000000-7b3fffff  |  0620 26c 9b000000-9b3fffff  |  0748 2ec bb000000-bb3fffff  |  0876 36c db000000-db3fffff  |  1004 3ec fb000000-fb3fffff
0109 06d 1b400000-1b7fffff  |  0237 0ed 3b400000-3b7fffff  |  0365 16d 5b400000-5b7fffff  |  0493 1ed 7b400000-7b7fffff  |  0621 26d 9b400000-9b7fffff  |  0749 2ed bb400000-bb7fffff  |  0877 36d db400000-db7fffff  |  1005 3ed fb400000-fb7fffff
0110 06e 1b800000-1bbfffff  |  0238 0ee 3b800000-3bbfffff  |  0366 16e 5b800000-5bbfffff  |  0494 1ee 7b800000-7bbfffff  |  0622 26e 9b800000-9bbfffff  |  0750 2ee bb800000-bbbfffff  |  0878 36e db800000-dbbfffff  |  1006 3ee fb800000-fbbfffff
0111 06f 1bc00000-1bffffff  |  0239 0ef 3bc00000-3bffffff  |  0367 16f 5bc00000-5bffffff  |  0495 1ef 7bc00000-7bffffff  |  0623 26f 9bc00000-9bffffff  |  0751 2ef bbc00000-bbffffff  |  0879 36f dbc00000-dbffffff  |  1007 3ef fbc00000-fbffffff
0112 070 1c000000-1c3fffff  |  0240 0f0 3c000000-3c3fffff  |  0368 170 5c000000-5c3fffff  |  0496 1f0 7c000000-7c3fffff  |  0624 270 9c000000-9c3fffff  |  0752 2f0 bc000000-bc3fffff  |  0880 370 dc000000-dc3fffff  |  1008 3f0 fc000000-fc3fffff
0113 071 1c400000-1c7fffff  |  0241 0f1 3c400000-3c7fffff  |  0369 171 5c400000-5c7fffff  |  0497 1f1 7c400000-7c7fffff  |  0625 271 9c400000-9c7fffff  |  0753 2f1 bc400000-bc7fffff  |  0881 371 dc400000-dc7fffff  |  1009 3f1 fc400000-fc7fffff
0114 072 1c800000-1cbfffff  |  0242 0f2 3c800000-3cbfffff  |  0370 172 5c800000-5cbfffff  |  0498 1f2 7c800000-7cbfffff  |  0626 272 9c800000-9cbfffff  |  0754 2f2 bc800000-bcbfffff  |  0882 372 dc800000-dcbfffff  |  1010 3f2 fc800000-fcbfffff
0115 073 1cc00000-1cffffff  |  0243 0f3 3cc00000-3cffffff  |  0371 173 5cc00000-5cffffff  |  0499 1f3 7cc00000-7cffffff  |  0627 273 9cc00000-9cffffff  |  0755 2f3 bcc00000-bcffffff  |  0883 373 dcc00000-dcffffff  |  1011 3f3 fcc00000-fcffffff
0116 074 1d000000-1d3fffff  |  0244 0f4 3d000000-3d3fffff  |  0372 174 5d000000-5d3fffff  |  0500 1f4 7d000000-7d3fffff  |  0628 274 9d000000-9d3fffff  |  0756 2f4 bd000000-bd3fffff  |  0884 374 dd000000-dd3fffff  |  1012 3f4 fd000000-fd3fffff
0117 075 1d400000-1d7fffff  |  0245 0f5 3d400000-3d7fffff  |  0373 175 5d400000-5d7fffff  |  0501 1f5 7d400000-7d7fffff  |  0629 275 9d400000-9d7fffff  |  0757 2f5 bd400000-bd7fffff  |  0885 375 dd400000-dd7fffff  |  1013 3f5 fd400000-fd7fffff
0118 076 1d800000-1dbfffff  |  0246 0f6 3d800000-3dbfffff  |  0374 176 5d800000-5dbfffff  |  0502 1f6 7d800000-7dbfffff  |  0630 276 9d800000-9dbfffff  |  0758 2f6 bd800000-bdbfffff  |  0886 376 dd800000-ddbfffff  |  1014 3f6 fd800000-fdbfffff
0119 077 1dc00000-1dffffff  |  0247 0f7 3dc00000-3dffffff  |  0375 177 5dc00000-5dffffff  |  0503 1f7 7dc00000-7dffffff  |  0631 277 9dc00000-9dffffff  |  0759 2f7 bdc00000-bdffffff  |  0887 377 ddc00000-ddffffff  |  1015 3f7 fdc00000-fdffffff
0120 078 1e000000-1e3fffff  |  0248 0f8 3e000000-3e3fffff  |  0376 178 5e000000-5e3fffff  |  0504 1f8 7e000000-7e3fffff  |  0632 278 9e000000-9e3fffff  |  0760 2f8 be000000-be3fffff  |  0888 378 de000000-de3fffff  |  1016 3f8 fe000000-fe3fffff
0121 079 1e400000-1e7fffff  |  0249 0f9 3e400000-3e7fffff  |  0377 179 5e400000-5e7fffff  |  0505 1f9 7e400000-7e7fffff  |  0633 279 9e400000-9e7fffff  |  0761 2f9 be400000-be7fffff  |  0889 379 de400000-de7fffff  |  1017 3f9 fe400000-fe7fffff
0122 07a 1e800000-1ebfffff  |  0250 0fa 3e800000-3ebfffff  |  0378 17a 5e800000-5ebfffff  |  0506 1fa 7e800000-7ebfffff  |  0634 27a 9e800000-9ebfffff  |  0762 2fa be800000-bebfffff  |  0890 37a de800000-debfffff  |  1018 3fa fe800000-febfffff
0123 07b 1ec00000-1effffff  |  0251 0fb 3ec00000-3effffff  |  0379 17b 5ec00000-5effffff  |  0507 1fb 7ec00000-7effffff  |  0635 27b 9ec00000-9effffff  |  0763 2fb bec00000-beffffff  |  0891 37b dec00000-deffffff  |  1019 3fb fec00000-feffffff
0124 07c 1f000000-1f3fffff  |  0252 0fc 3f000000-3f3fffff  |  0380 17c 5f000000-5f3fffff  |  0508 1fc 7f000000-7f3fffff  |  0636 27c 9f000000-9f3fffff  |  0764 2fc bf000000-bf3fffff  |  0892 37c df000000-df3fffff  |  1020 3fc ff000000-ff3fffff
0125 07d 1f400000-1f7fffff  |  0253 0fd 3f400000-3f7fffff  |  0381 17d 5f400000-5f7fffff  |  0509 1fd 7f400000-7f7fffff  |  0637 27d 9f400000-9f7fffff  |  0765 2fd bf400000-bf7fffff  |  0893 37d df400000-df7fffff  |  1021 3fd ff400000-ff7fffff
0126 07e 1f800000-1fbfffff  |  0254 0fe 3f800000-3fbfffff  |  0382 17e 5f800000-5fbfffff  |  0510 1fe 7f800000-7fbfffff  |  0638 27e 9f800000-9fbfffff  |  0766 2fe bf800000-bfbfffff  |  0894 37e df800000-dfbfffff  |  1022 3fe ff800000-ffbfffff
0127 07f 1fc00000-1fffffff  |  0255 0ff 3fc00000-3fffffff  |  0383 17f 5fc00000-5fffffff  |  0511 1ff 7fc00000-7fffffff  |  0639 27f 9fc00000-9fffffff  |  0767 2ff bfc00000-bfffffff  |  0895 37f dfc00000-dfffffff  |  1023 3ff ffc00000-ffffffff

\end{verbatim}
}

% (Rest erzeugen mit tmp/showaddress.py)

It is helpful to reconsider how the CPU (or the MMU) accesses
the paging information: A register holds the address of the page
directory which has 1024 entries, each of which is either null or
points to a page table.

The upper $1024-768 = 256$ entries are responsible for the kernel
memory (\hexaddr{C000.0000}--\hexaddr{FFFF.FFFF}), and the lower 768 entries are available
for process memory (\hexaddr{0000.0000}--\hexaddr{BFFF.FFFF}) with the exception that
we will not use the first megabyte of RAM because it contains the
video memory (\hexaddr{000B.8000}--\hexaddr{000B.9FFF}), so processes will always
start using memory from address \hexaddr{0010.0000}.

We want to allow for three different situations, as far as access
to process memory and kernel memory is concerned:

\begin{description}
\item[pure kernel mode:] The kernel is actively dealing with specific kernel tasks, such as memory management or interrupt service. The kernel's view on memory in this state is basically the same as it was after enabling paging: It sees its own memory (\hexaddr{C000.0000}--\hexaddr{FFFF.FFFF}) and the two pages for video memory.
\item[pure user mode:] A process is active and running in user mode. It only sees its own memory (\hexaddr{0010.0000}--\hexaddr{BFFF.FFFF}), i.\,e. the lower 3 GByte minus the first MByte.
\item[process in kernel mode:] A process has entered kernel mode via a system call. In this situation the page tables must give access to both the current process' memory and the kernel memory. All 4 GByte of virtual memory (minus the never-used first 1 MByte) are visible.
\end{description}

When we create a new address space we do not assume that it will be used by a process; it may also be created for a new kernel thread which is similar to a process but never enters user mode.

We reserve memory for an address space list. This list does not hold
the page tables, but just a pointer to the page directory and some
status information:

<<kernel declarations>>=
typedef struct {
  void* pd;      // address of the page directory
  uint physical; // physical address of the page directory
  int pid;       // process ID (if used by a process or kernel thread; -1 if not)
  boolean free;  // are we using this address space?
  uint memstart; // first address below 0xc000.0000
  uint memend;   // last address below 0xc000.0000
  // FURTHER DATA? TYPE?
} address_space;
address_space address_spaces[MAX_ADDR_SPACES];
@

We will need to search for a free address space:


<<kernel functions>>=
int get_free_address_space () {
  int id=0;
  while ((!address_spaces[id].free) && (id<MAX_ADDR_SPACES)) id++;
  if (id==MAX_ADDR_SPACES) id = -1;
  return id;
}
@

Also, the array [[address_spaces]] needs to be initialised, and
we will let its first entry point to the kernel page directory.
We add the code just after enabling paging:

<<enable paging for the kernel>>=
for (int id=1; id<MAX_ADDR_SPACES; id++) address_spaces[id].free = true;
// loops from 1 to 1023; 0 is for kernel page directory:

// we also want to initialize address space 0 (for the kernel
// address space), but we need to postpone this until the system
// is further up.
// We will put the following lines in the address space creation
// function to be run when it is called the first time.
// 
address_spaces[0].free = false;
address_spaces[0].pd   = &kernel_pd;
address_spaces[0].physical = 0;
address_spaces[0].pid  = -1;         // not a process
@

This is what we need to do in order to create a fresh address space:
We first retrieve a new address space ID and mark it as used. Then
we reserve memory for a new page directory and copy the system's one
into it. Finally we set up some user space memory and add it to
the page directory:

<<kernel functions>>=
int create_new_address_space(int initial_ram) {
  // debug_printf ("ENTER create_new_address_space (%d)\n", initial_ram);
  int id = get_free_address_space ();
  if (id == -1) return -1;   // fail: no address space available
  address_spaces[id].free = false;
  // debug_printf ("BEFORE <reserve memory for pd>\n");
  create_as = id; // if set, this is the address space we currently create
  <<reserve memory for new page directory>>   // sets new_pd
  create_as = -1;  // (reset create_as)
  // debug_printf ("AFTER <reserve memory for pd>\n");
  address_spaces[id].pd = new_pd;
  address_spaces[id].physical = mmu( 0, (uint)new_pd );
  <<copy master page directory to new directory>>
  if (initial_ram > 0) {
    // make initial_ram a multiple of PAGE_SIZE
    initial_ram = ((initial_ram+PAGE_SIZE-1)/PAGE_SIZE)*PAGE_SIZE;
    
    address_spaces[id].memstart = 0;
    address_spaces[id].memend   = initial_ram;
    
    int frameno;
    int pageno = 0;
    while (initial_ram > 0) {
      if ( (frameno = request_new_frame ()) < 0) {
        // error
        printf ("\nERROR: no free frame, aborting create_new_address_space\n");
        return -1;
      };
      as_map_page_to_frame (id, pageno, frameno);
      pageno++;
      initial_ram-=PAGE_SIZE;
    };
  };
  // debug_printf ("LEAVE create_new_address_space (%d)\n", initial_ram);
  return id;
};
@

\begin{work}
\red
For some reason, the above code -- sometimes -- does not work
when only one page is created (0x10000).
\end{work}

We cannot use our [[kmalloc]] function to reserve the memory needed for
the new page directory, since it prepends a header in front of the
data area; however, we need page aligned memory. So instead we use
[[request_new_page]].

<<reserve memory for new page directory>>=
debug_printf ("BEFORE request_new_page\n");
page_directory* new_pd = (void*)request_new_page (0);
debug_printf ("AFTER request_new_page\n");
if (new_pd == NULL) {
  // Error
  printf ("\nERROR: no free page, aborting create_new_address_space\n");
  return -1;
};
memset (new_pd, 0, sizeof(page_directory));
@

For copying the kernel page directory to the new directory, we
simply use [[memcpy]].

<<copy master page directory to new directory>>=
bochs_memcpy (new_pd, &kernel_pd, sizeof(page_directory));

// now make a copy of the first page table as well and link it
page_table* new_pt = (void*) request_new_page (0);
if (new_pt == NULL) {
  // Error
  printf ("\nERROR: no free page, aborting create_new_address_space\n");
  return -1;
};
// printf ("new_pt: 0x%x, mmu(): 0x%x\n", (uint)new_pt, mmu(0,(uint)new_pt));
memcpy (new_pt, (void*) PHYSICAL(kernel_pd.ptds[0].frame_addr << 12), sizeof(page_table));
// printf ("begin UMAPD 0x%x,0x%x\n", &new_pd->ptds[0], mmu (0, (uint)new_pt) );
UMAPD ( &new_pd->ptds[0], mmu (0, (uint)new_pt) );
// printf ("end UMAPD\n");
@


(The argument [[initial_ram]] defines the amount of extra memory that
should be allocated at once.)


\begin{work}
\red
WARNING: There is another section defining an address space table,
see section B-7.9.4. Address Space Table!
\end{work}




The page table consists of the page directory 

and must be updated... SHARE THE UPPER PART OF THE TABLES!

Update all directory entries for 3 GB and above whenever a change
is made to that area!

To simplify things we'll add null entries in the page directory


....

What we need is a function that adds mappings to the lower memory
address range of the page directory, something along the lines
of [[map (int address_space, uint32 start, int pages)]]. We move
that into the next subsection which deals with allocating memory
for address spaces.


\subsection{Allocating Memory for Address Spaces}

We will now describe how to reserve memory for an address space;
this will make it possible to give processes their own memory
since each process will use a unique address space.

Getting new physical memory is not a problem since we already have
defined the function [[request_new_frame()]] which reserves a new frame.

Let's begin with a function that can map a page to a frame for some
given address space:

<<kernel declarations>>=
int as_map_page_to_frame (int as, uint pageno, uint frameno);
@

This will basically be a rewrite of parts of [[<<enter frame in page table>>]].

<<kernel functions>>=
int as_map_page_to_frame (int as, uint pageno, uint frameno) {
  // for address space as, map page #pageno to frame #frameno
  // printf ("DEBUG: as_map_page_to_frame (%d,0x%x,0x%x)\n", as, pageno, frameno);
  page_table* pt;
  page_directory* pd;

  pd = address_spaces[as].pd;   // use the right address space
  uint pdindex = pageno/1024;   // calculuate pd entry
  uint ptindex = pageno%1024;   // ... and pt entry

  if ( ! pd->ptds[pdindex].present ) {
    // page table is not present
    pt = NULL;
    <<create new page table for this address space>>
    printf ("ERROR: create new page table not implemented\n"); // REMOVE
    return -1;
  } else {
    // get the page table
    // printf ("DEBUG: frame number of page table: 0x%x\n", pd->ptds[pdindex].frame_addr);
    pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
  };
  UMAP ( &(pt->pds[ptindex]), frameno << 12 );
  // ??? hier evtl. KMAP statt UMAP? Unterscheiden, ob <c000.0000 oder nicht?
  return 0;
};
@


Now we need to explain how to
<<create new page table for this address space>>=

@


\subsection{Destroying an Address Space}

When we [[exit]] a process, we must also destroy its address
space and release all pages used by it. For that purpose we write
a function [[destroy_address_space()]]:

<<kernel declarations>>=
void destroy_address_space (int id);
@

<<kernel functions>>=
void destroy_address_space (int id) {
  debug_printf ("ENTER destroy_address_space (%d)\n", id);
  debug_printf ("      memstart: %d\n", address_spaces[id].memstart);
  debug_printf ("      memend  : %d\n", address_spaces[id].memend);

  int as = current_as;  // remember the current address space
  current_as = id;

  // TODO: release all pages used by this process
  debug_printf ("free_frame: %d\n", free_frames);
  for ( int i = address_spaces[id].memstart / PAGE_SIZE;
        i < address_spaces[id].memend / PAGE_SIZE;
        i++ ) {
    debug_printf ("release: page %d\n", i);
    memset ((void*)(i<<12), 0, PAGE_SIZE);
    release_page (i);
  };
  debug_printf ("free_frame: %d\n", free_frames);
  
  // TODO: remove kernel stack
  // (cannot do this here, this kernel stack is in use right now)
  // ( -> scheduler )
  
  // TODO: remove reference to kernel memory  
  // (same problem)
  
  current_as = as;
  address_spaces[id].free = true;
  return;
}
@



\subsection{Switching between Address Spaces}

In order to switch between two address spaces it is sufficient
to load the new address space's page directory address into
the CR3 register.

Note that using this function should be avoided because it has
the side effect of switching the kernel stack. Even while it is
implemented as [[inline]] function, it is still not safe to call
it: parameter passing creates local variables (on the kernel
stack) which are lost after the context switch.

In earlier versions of the code, [[<<context switch>>]] used to
make a function call to [[activate_address_space()]] and it 
caused many problems (the operating system crashed). After moving
the [[CR3]] loading code directly into the context switch, the
problems disappeared.


<<kernel declarations>>=
inline void activate_address_space (int id)  __attribute__((always_inline));
int current_as = 0;  // global variable: current address space
@

<<kernel functions>>=
inline void activate_address_space (int id) {
  // NOTE: Do not call this from the scheduler;
  //       where needed, replicate the code
  
  // We need to store id in a global variable because we switch the
  // address space
  tmp_as = id;
  
  if (tmp_as == 0) {
    debug_printf ("WARNING: activate_address_space (0) called!\n");
  } else {
    debug_printf ("NOTICE:  activate_address_space (%d) called!\n", tmp_as);
  }

  uint mem  = mmu(0, (uint)address_spaces[tmp_as].pd);
  __asm__ __volatile__ ("mov %0, %%cr3" : : "r"(mem)); // write CR3

  current_as = tmp_as;
  current_pd = address_spaces[tmp_as].pd;  // need this?
  return;
};
@

\begin{work}
TBD:
\begin{itemize}
\item write a function that loads CR3, e.g. \verb#load_cr3 (address)#
(DONE, happens inside [[activate_address_space]])
\item get rid of the long [[__asm__]] stuff. macros? can i write
[[#define asm __asm__]]? (DONE, macro is there, maybe change code later)
\item write a test suite that creates three address spaces, defines
and stores different local variables (DONE)
\end{itemize}


\end{work}


<<kernel declarations>>=
void list_address_spaces ();
@

<<kernel functions>>=
void list_address_space (int id) {
  int mem  = (uint) address_spaces[id].pd;
  int phys = mmu (id, (uint) address_spaces[id].pd);  // emulate MMU
  int memstart = address_spaces[id].memstart;
  int memend = address_spaces[id].memend;
  printf ("ID: %d, MEM: %08x, PHYS: %08x  - USER: [%08x..%08x[\n", 
    id, mem, phys, memstart, memend); 
};

void list_address_spaces () {
  int id;
  for (id=0; id<MAX_ADDR_SPACES; id++) {
    if (!address_spaces[id].free) {
      list_address_space (id);
    }
  }
};
@

The function [[list_address_space]] uses another function
called [[mmu]] which emulates the MMU behavior and calculates
the physical address belonging to a virtual address with respect
to an address space:

<<kernel declarations>>=
uint mmu (int id, uint vaddress);  // v-address -> phys-address
uint mmu_p (int id, uint pageno);  // pageno -> frameno
@

It looks up the page directory and then the right page table
which holds the mapping for the virtual address. Note that this
function can only work if the page table is in memory---if it
was paged out, it will return -1 (or actually: [[MAXINT32]], since
it is of type [[uint]]).

<<kernel functions>>=
uint mmu (int id, uint vaddress) {
  uint pageno, frameno, offset, pdindex, ptindex;
  page_directory* pd;
  page_table* pt;
  offset = vaddress%PAGE_SIZE;
  pageno = vaddress/PAGE_SIZE;
  pdindex = pageno/1024;
  ptindex = pageno%1024;
  pd = address_spaces[id].pd;
  if ( ! pd->ptds[pdindex].present ) {
    return -1;
  }
  pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
  if ( pt->pds[ptindex].present) {
    frameno = pt->pds[ptindex].frame_addr;
    return (frameno << 12) + offset;
  } else {
    return -1;
  };
};

uint mmu_p (int id, uint pageno) {
  // the same, but with page numbers returns framer number
  uint pdindex, ptindex;
  page_directory* pd;
  page_table* pt;
  pdindex = pageno/1024;
  ptindex = pageno%1024;
  pd = address_spaces[id].pd;
  if ( ! pd->ptds[pdindex].present ) {
    return -1;
  } else {
    pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
    if ( pt->pds[ptindex].present) {
      return pt->pds[ptindex].frame_addr;
    } else {
      return -1;
    };
  }
};

@



\subsection{Enlarging an Address Space}

We want to allow processes to increase their standard memory usage (which
is 64 KByte). Most Unix systems provide an implementation of [[malloc]] as
part of their standard library.

Since we have already described an implementation of [[malloc]] and
[[free]] for the \UlixI{} kernel ([[kmalloc]] and [[kfree]]), we will
introduce the more historical method of using [[brk]].

The [[brk]] system call (and corresponding library function) is still
available on modern Unix systems, but its use is advised against.
[[brk]] adds one or more pages to the calling process' data ``segment''. 
The function [[sbrk]] does the same but is more user-friendly: It takes
an increment as argument, so if the process needs 16 KByte extra memory,
it can call [[sbrk(16*1024)]]. [[sbrk]] returns the lowest address of
the new memory: After executing [[void *mem = sbrk(incr)]], the
address range $[ \texttt{mem}\, ; \texttt{mem}+\texttt{incr}-1 ]$ is available to the process.

How can we do this in \UlixI{}? Remember that each process uses an
[[address_space]] which has elements named [[memstart]] and [[memend]]
(the last of which is the first address that is \emph{not} available)
and a pointer to the address space's page directory ([[pd]]). Thus,
[[sbrk]] just needs to 

\begin{itemize}
\item acquire the needed number of frames,
\item modify the page directory so that the new frames are mapped just
after the last old pages, and
\item update the [[memend]] element.
\end{itemize}

It then returns the first (virtual) address of the first new page.

We start with the kernel-internal function [[sbrk]]; we expect that its
argument is always a multiple of [[PAGE_SIZE]]:

<<kernel declarations>>=
void *sbrk (int incr);
@

<<kernel functions>>=
void *sbrk (int incr) {
  int pages = incr / PAGE_SIZE;
  int i, frame;
  address_space *aspace = &address_spaces[current_as];
  // page_table *pt = (page_table *)aspace->pd;

  uint oldbrk = aspace->memend;
    
  for (i=0; i<pages; i++) {
    frame = request_new_frame ();
    as_map_page_to_frame (current_as, aspace->memend/PAGE_SIZE, frame);
    aspace->memend += PAGE_SIZE;
  }
  return (void*) oldbrk;  
}
@

Next we need to provide a system call for the [[sbrk]] function. The
constant [[__NR_brk]] is defined as 45. There is no [[sbrk]] system call
since normally the [[sbrk]] function is implemented by calling [[brk]].
But we will only implement [[sbrk]] and reuse the [[brk]] system call
number.

<<syscall functions>>=
void syscall_brk (struct regs *r) {
  // ebx: increment
  r->eax = (uint)sbrk (r->ebx);
  return;
}
@

<<initialize syscalls>>=
insert_syscall (__NR_brk, syscall_brk);
@


\section{Summary}





\black



% --------------------------------------------------------------------------



\chapter{Virtual Consoles}
\label{chap:ulix:virtualconsoles}

We want \UlixI{} to provide several terminals so that we can run a few
login shells and execute programs on them.

Conceptually, providing terminals is not complicated: we need

\begin{itemize}
\item memory to store the contents of the terminals -- roughly 80 x 25 x 2
bytes per terminal (the size of the textmode video buffer),
\item a way to make \Ulix{} switch the active terminal,
\item a modification of the [[write()]] functions so that they will
either write to the current terminal or a specified terminal.
\item When writes to a terminal occur, the terminal's screen buffer
is updated---if it is the active terminal, the screen is updated at
the same time.
\item When switching to a different terminal, its screen buffer is
copied to the screen.
\end{itemize}

We start with the required memory. Since \UlixI{} uses the last line on
the screen for displaying a status line, we consider it not to be part
of any terminal buffer; for example scrolling shall always ignore the
last line. So we can define

<<kernel declarations>>=
#define VT_SIZE 80*24*2
typedef struct {
  char mem[VT_SIZE];
  int x,y;
} term_buffer;
@

Two bytes are required for each character; the first one holds the
ASCII value of the symbol to be displayed, the second is used for
foreground and background colors.

We want the system to use up to ten virtual consoles (numbered from
0 to 9), so we create an array for them:

<<kernel global variables>>=
#define MAX_VT 9
term_buffer vt[MAX_VT+1];
int cur_vt = 0;
@

[[vt[i].mem]] is the buffer of console [[i]], and [[vt[i].x]] and
[[vt[i].y]] hold the current cursor position in console [[i]]. We
initialize the current terminal to number 0.

To start with proper contents, we initialize each of the ten 
text buffers with blanks. A blank character is actually an
[[unsigned short]] with the low byte containing the ASCII value
of the blank symbol ([[0x20]]) and the high byte containing the
color information ([[0x0f]] for white on black).

<<initialize system>>=
int vtno;
unsigned short* memptr;
unsigned blank = 0x20 + (0x0f<<8);  // blank character
for (vtno=0; vtno<10; vtno++) {
  memptr = (unsigned short*)vt[vtno].mem;
  memsetw (memptr, blank, 80*24);
}
printf ("Initialized ten terminals (press [Alt-1] to [Alt-0])\n");
@

We also need a way to tell a process what terminal it runs on, so we
add a new [[TCB]] entry:

<<more TCB entries>>=
int terminal;
@

A regular Unix system would allow for a more complex setup, but
for \UlixI{} we restrict ourselves to using ten text consoles.

Activating a console is the simplest of all the operations, we will collect
them in a code chunk named [[<<virtual console functions>>]]:

<<kernel functions>>=
<<virtual console functions>>
@

which starts with

<<virtual console functions>>=
int vt_activate (int i) {
  if (i<0 || i>MAX_VT)
    return -1;    // no such console
  else {
    int old_vt = cur_vt;
    // handle screen part
    memcpy (vt[cur_vt].mem, (void*)VIDEORAM, VT_SIZE);  // store old stuff (remove)
    vt[cur_vt].x = csr_x; vt[cur_vt].y = csr_y; 
    memcpy ((void*)VIDEORAM, vt[i].mem, VT_SIZE);
    cur_vt = i;
    csr_x = vt[i].x;
    csr_y = vt[i].y;
    move_csr();
  }
}
@

We need to declare this function in the headers as well:

<<kernel declarations>>=
int vt_activate (int i);
@

Let's define what terminal we expect to print out kernel messages.
We initialize [[KERNEL_VT]] to 0, though it may later be changed.

<<kernel declarations>>=
short int KERNEL_VT = 0;
@


We provide a system call that lets a process choose which terminal to use.

<<kernel functions>>=
void syscall_setterm (struct regs* r) {
  int vt = r->ebx;                  // argument in ebx register
  if (vt<0 || vt>MAX_VT) return;    // check if proper number...
  thread_table[current_task].terminal = vt;
  debug_printf ("DEBUG: current_task = %d\n", current_task);
  debug_printf ("DEBUG: terminal     = %d\n", vt);
  return;
};
@

The system call number shall be [[0x2001]]:

<<kernel declarations>>=
#define __NR_setterm  0x2001
@

Finally, we need to register the new system call:

<<initialize syscalls>>=
insert_syscall (__NR_setterm, syscall_setterm);
@



We also need functions to clear the screen, set the cursor and get
the current cursor location:

<<kernel declarations>>=
void terminal_clrscr ();
void terminal_get_xy (char *x, char *y);
void terminal_set_xy (char x, char y);
@

[[terminal_clrscr]] just overwrites the current terminal's memory
with blank characters and then calls [[terminal_set_xy]] to set
the cursor to the top left position.

<<kernel functions>>=
void terminal_clrscr () {
  int process_term = thread_table[current_task].terminal;
  unsigned short* memptr;
  unsigned blank = 0x20 + (0x0f<<8); // blank character
  memptr = (unsigned short*)vt[process_term].mem;
  memsetw (memptr, blank, 80*24);
  terminal_set_xy (0, 0);
  
  // current terminal?
  if (process_term == cur_vt)
    memsetw ((void*)VIDEORAM, blank, 80*24);
  return;
}
@

The [[terminal_get_xy]] and [[terminal_set_xy]] read respectively
set the [[x]] and [[y]] members of the current terminal's
[[term_buffer]] structure:

<<kernel functions>>=
void terminal_get_xy (char *x, char *y) {
  int process_term = thread_table[current_task].terminal;
  *x = vt[process_term].x;
  *y = vt[process_term].y;
}

void terminal_set_xy (char x, char y) {
  int process_term = thread_table[current_task].terminal;
  vt[process_term].x = x;
  vt[process_term].y = y;
  
  // current terminal?
  if (process_term == cur_vt) {
    csr_x = x; csr_y = y;
    move_csr();
  }
}
@

We provide three system calls for these functions:

<<ulix system calls>>=
#define __NR_clrscr   0x6001
#define __NR_get_xy   0x6002
#define __NR_set_xy   0x6003
@

<<syscall functions>>=
void syscall_clrscr (struct regs_syscall *r) {
  // no parameters, no return value
  terminal_clrscr ();
  return;
}

void syscall_get_xy (struct regs_syscall *r) {
  // ebx: address of x position (char)
  // ecx: address of y position (char)
  terminal_get_xy ((char*)r->ebx, (char*)r->ecx);
  return;
}

void syscall_set_xy (struct regs_syscall *r) {
  // ebx: x position (char)
  // ecx: y position (char)
  terminal_set_xy ((char)r->ebx, (char)r->ecx);
  return;
}
@

And we add those system calls to the system:

<<initialize syscalls>>=
insert_syscall (__NR_clrscr, syscall_clrscr);
insert_syscall (__NR_get_xy, syscall_get_xy);
insert_syscall (__NR_set_xy, syscall_set_xy);
@


To make live easier for the application programmer (who cannot access
the screen memory directly) we also provide functions which allow
reading or writing the whole screen (that is: 24 line of 80 characters;
the last line on the $80 \times 25$ display is reserved for the operating 
system). For this purpose we implement the [[read_screen]] and
[[write_screen]] functions and let applications call them via system
calls.

<<kernel declarations>>=
void read_write_screen (char *buf, boolean read_flag);
void read_screen (char *buf);
void write_screen (char *buf);
@

<<kernel functions>>=
void read_write_screen (char *buf, boolean read_flag) {
  // if read_flag == true: read from screen, otherwise write
  int process_term = thread_table[current_task].terminal;
  char *video_address = (char*) vt[process_term].mem;
  
  if (read_flag) {
    // read the screen
    memcpy (buf, video_address, 80*24*2);
  } else {
    // write the screen
    memcpy (video_address, buf, 80*24*2);
    // current terminal?
    if (process_term == cur_vt)
      memcpy ((char*)VIDEORAM, video_address, 80*24*2);
  }
}

void read_screen (char *buf) {
  read_write_screen (buf, true);
}

void write_screen (char *buf) {
  read_write_screen (buf, false);
}
@

The system call handlers are simple; we don't call [[read_screen]]
and [[write_screen]] individually to save the extra function call:

<<ulix system calls>>=
#define __NR_read_screen   0x6004
#define __NR_write_screen  0x6005
@

<<syscall functions>>=
void syscall_read_screen (struct regs_syscall *r) {
  // ebx: buffer address
  read_write_screen ((char *) r->ebx, true); return;
}

void syscall_write_screen (struct regs_syscall *r) {
  // ebx: buffer address
  read_write_screen ((char *) r->ebx, false); return;
}
@

<<initialize syscalls>>=
insert_syscall (__NR_read_screen,  syscall_read_screen);
insert_syscall (__NR_write_screen, syscall_write_screen);
@






% --------------------------------------------------------------------------




\chapter{Processes and Threads}
\label{chap:ulix:processes}%


Here we go...


\green


\section{Motivation}

In the preceding chapter we looked into a fundamental abstraction
offered by the operating system: virtual memory. Virtual memory is an
abstraction of physical memory, one of the main resources provided by
the hardware. The second main resource offered by the hardware is
\emph{processor time}, i.e., machine cycles or computation power
offered by the CPU. The abstraction which encapsulates processor time
in an operating system is called a \emph{thread}. Threads are
\vindex{virtual processors}. Like virtual address spaces, virtual
processors can be created and destroyed on demand. If you need more
memory, then create a new virtual address space. Consequently, if you
need more processing power, then simply create a new virtual
processor. The operating system must handle the job to multiplex
the virtual processors on to the available physical processors.

\subsection{Process vs.~Thread}

Up to now, we used the more historic term \emph{process} in parts of
this document instead of the term thread. Briefly spoken, a
\vindex{process} is a virtual address space plus exactly one
thread. Thus, the term process alludes to the classical
\emph{\vindex{Unix process}}. Today, modern operating systems offer
multiple threads within one virtual address space. 

\subsection{Outlook}

In this chapter we will show how such threads are implemented in
operating systems in general and in \Ulix{} in particular.  After a
brief introduction into threads, teams of threads and the notion of
virtual processors in
Section~\ref{sec:threads:teams:virtual:processors} we discuss the
different types of threads in
Section~\ref{sec:kernel:vs:user:level:threads}. We then turn our
attention to the more fundamental type of threads:
\emph{\vindex{kernel level threads}}. We go through the basic state
model of such a thread in Section~\ref{sec:thread:state} and discuss
the different types of scheduling in
Sections~\ref{sec:monoprocessor:scheduling},
\ref{sec:real:time:scheduling}, and
\ref{sec:multiprocessor:scheduling}. A brief glimpse into a simple
thread API is given in Section~\ref{sec:thread:APIs}, so that readers
have an idea how threads can be created and terminated through system
calls.

The implementation of kernel level threads in \Ulix{} is given in
Section~\ref{sec:kernel:level:dispatcher:ulix}. User level threads
follow in Section~\ref{sec:user:level:threads:package:ulix}.



\section{Threads, Teams of Threads, and Virtual Processors}
\label{sec:threads:teams:virtual:processors}

A thread can be regarded quite literally as an execution thread within
the operating system. As mentioned above, threads are abstractions of
processing time, virtual processors. Threads are implemented by
multiplexing virtual processors (the threads) on to the physical
processors (CPUs). A thread always has an associated
\emph{\vindex{program}}, i.e., a sequence of machine instructions
which it executes. When a thread starts its operation, execution
starts at a pre-defined address in this sequence.

Threads and address spaces are two abstractions which are orthogonal
but nevertheless closely tied together. Whenever a virtual address space
is created, a first thread is also created within the address space.
This results in what is often called a \emph{process}. In most cases
(as in early Unix) this is absolutely sufficient to perform all
the classical application tasks programmed on top of the operating
system. However, it sometimes makes sense to create multiple
threads within a single address space, as we now explain.

\subsection{Teams of Threads}

We call multiple threads within a single address space a
\emph{\vindex{team}} (or \emph{\vindex{team of threads}}).  Why does
it make sense to create multiple threads within one address space?
There are multiple answers to this question. The first block of
answers refers to performance issues: If within an application one
thread invokes a system call which blocks for an I/O operation to
succeed, then the whole application will block if the application is
carried on just this one single thread. If more than one thread would
carry the application, these other threads could continue to operate,
giving the user a better quality of service. Also, if an application
runs on multiple threads, it is possible to distribute the machine
cycles on to \emph{physically distinct} processors. This (of course)
is not an issue in a monoprocessor system. However, in a dual
processor system for example an application which is carried only by a
single thread will never be able to bring the power of the two CPUs
into the application.

The second block of answers refers mainly to software engineering
aspects, i.e., the way we write programs. Multiple threads within one
address space allow to program those applications which contain
inherent parallel activities in a much more natural way. The result is
a \emph{concurrent model of programming}\pindex{concurrent
  programming} which includes both the fields of distributed and
parallel programming.  Concurrent programming refers to programming
multiple independent threads of execution in general. Parallel
programming\pindex{parallel programming} on the one side refers rather
to more dependent threads, e.g., threads which operate in strongly
synchronized ``lock-step'' mode. Distributed
programming\pindex{distributed programming} on the other side refers
to concurrent programming where the aspect of geographic distribution
plays a role (like in the Internet).

\subsection{Natural Concurrency}

Many of today's operating systems already support multiple threads
in one address space and so it is becoming more and more natural to
use them. It is especially natural if the application which is
implemented already contains \emph{inherent} concurrency.
As an example (taken from Nehmer and Sturm \cite{Nehmer:1998:SGM}) consider
a weather reporting application. It consists of a huge database in
which new measurements of humidity, temperature etc.~are regularly logged
from different sensing stations. From this database the application
computes in a continuous manner weather reports for different areas
of the country using complex weather models. Additionally, the
application has a graphical user interface through which data can
be inspected, weather reports queried and measurement data visualized.

Looking at the application from a concurrent programming viewpoint, it
has three rather independent streams of activity:
%
\begin{enumerate}
\item The measurement and logging activity of data into the database.
\item The continuous weather predication and reporting computation.
\item The graphical user interface.
\end{enumerate}
%
Note that each stream of activity by itself is sequential. 

Let's make things simple and just look at the last two
activities: computation and user interface. As both are
sequential activities, we can program then separately and
enclose their activity within a thread each. The pseudocode
could look like this:

<<weather reporting example: thread pseudocode>>=
// activity 1: computation
Compute() {
  while (1) {
    // do the actual computation
  }
}
// activity 2: graphical user interface (GUI)
GUI() {
  while (1) {
    Event e = ReceiveEvent();
    ProcessEvent(e);
  }
}
// Start concurrent threads
int main() {
  start_thread(Compute());
  start_thread(GUI());
}

@ Note that the sequential activities are encoded within 
simple sequential functions which are both started within
separate threads within the [[main]] routine and thereafter
run separately. Here we assume that the entire application
exits when all of its threads have exited. 

How would we program this application traditionally (i.e., without
threads)? We would have to split the activities into small slices and
run them alternately. Assume we can divide the function [[Compute()]]
into small parts called [[ComputeStep]]. Then after computing such a
step we would need to check whether user input must be handled. If
yes, we handle it, if not, we compute the next step. The pseudocode
could look like this:

<<weather reporting example: traditional pseudocode>>=
int main() {
  while (1) {
    ComputeStep();      // compute the next step
    if (QueryEvent()) { // does an event need to be processed?
      e = ReceiveEvent();
      ProcessEvent(e);
    }
  }
}

@ This approach should also work, but only under the assumption that
we can in fact split [[Compute]] into [[ComputeStep]]. In many cases
this is not as easy as it seems, sometimes it might even be
impossible. Another disadvantage of the traditional approach is that
the computation is interrupted regularly even if there are no events
to be processed. In this case the code for [[QueryEvent]] should be
very efficient so that it doesn't cost too many CPU cycles. It goes
without saying that functions like [[QueryEvent]] should not block
(e.g., until user input arrives) because this would block the entire
application. 

There are more downsides of the traditional approach. For example, the
program structure without threads determines the reaction time to user
input. If [[ComputeStep]] may take up to a couple of seconds of
execution time, then reaction to user input can also take this time.
The execution time of [[ComputeStep]] should therefore be rather short
to guarantee responsiveness. However, a short execution time implies
that the overhead of [[QueryEvent]] increases in relation. So we have
a non-trivial tradeoff here.  Finally, but this is a matter of taste,
I find the traditional code much harder to read and understand as the
code using threads.

\subsection{Advantages of Concurrent Programming}

Threads allow to create an unbounded number of virtual processors, no
matter how many physical processors exist in the system. This allows
to distribute applications over as many virtual processors as are
necessary to serve their inherent concurrency. Threads therefore allow
to abstract from the actual number of physical processors in the
system and allow to depart from the traditional sequential programming
model. If an application has inherent, natural concurrency, then
it should be expressed in the program. 

Threads do not only make programs with inherent concurrency easier to
read and understand, they also may make the exection of the
application more efficient since only concurrent applications can
exploit the power of truely concurrent hardware available in
multiprocessor systems. But even on monoprocessor systems a concurrent
program can be more efficient than its sequential counterpart because
the periods in which one thread is blocked (e.g., due to lack of
user input) can be used by other threads more effectively.

\subsection{Virtual vs.~Physical Processors}

As mentioned above, a thread can be regarded as a
\emph{\vindex{virtual processor}}. Therefore, a team of threads can be
regarded as a \emph{\vindex{virtual multiprocessor}}. Ideally, every
virtual processor is backup up from below by exactly one physical
processor and the assignment of virtual to physical processors is
fixed. However, the normal case is rather different: Many virtual
processors need to be executed on few physical processors. The task of
the operating system is to distribute the physical processor cycles as
effectively as possible between the virtual processors in a kind of
\emph{\vindex{time division multiplex}} mode of operation. This is
depicted in Figure~\ref{fig:time:multiplex}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/time-multiplex.jpg}
  \caption{The assignment of virtual to physical processors can change over time.}
  \label{fig:time:multiplex}
\end{figure}

As an example, consider the case where one physical processor carries
two virtual processors (threads). In this case the threads would be
assigned alternately to the physical processor by the operating
system. The change from one thread to the other is called a
\emph{\vindex{context switch}}. Within the context switch, the
execution of the current thread is interrupted, the processor context
(registers, stack pointer etc.) is saved somewhere, the processor
context of the next thread is loaded from somewhere onto the processor
and the next thread then continues execution at the point in its
program where it was previously interrupted. 

In a sense, the operating system pretends that every thread has
exclusive access to the physical processor. During a context switch,
the previously running thread is ``frozen'' and saved somewhere.  The
next thread is selected and ``unfrozen'' by loading its state into the
CPU. During the times in which they are frozen, threads do not
operate. In fact, since they don't operate, they are not aware that
time is passing. After unfreezing the new thread, it continues
operation as if it had never been interrupted. This can remotely
be compared with becoming unconscious after a knock out in boxing.

If there are more than one candidates to be the next running thread,
the operating system has to make a choice. The operating system
component which is responsible for making this decision is called the
\emph{\vindex{scheduler}}. As we will see later in this chapter there
exist many different strategies to make this scheduling decision.



\section{Thread Requirements and Thread Types}
\label{sec:kernel:vs:user:level:threads}

\subsection{Thread Requirements}

If an operating system supports threads, it must offer at least two
types of functionality: On the one hand, a user should be able to
create a new address space with a \emph{single} thread. On the other
hand, the user should be able to assign a new program to this
thread. Often these two functionalities are assembled within one
single system call offered by the kernel.

To offer more flexibility, it should be possible to create
\emph{multiple} threads within one address space. Good operating
systems therefore offer functionality to create a new thread within
the same address space at runtime and to assign a new program to
this thread. 

\subsection{Utility of Threads}

\begin{work}
  Ch 5, slide 16, 17
\end{work}

\subsection{Preventing CPU Monopolization}
\label{sec:preventing:cpu:monopolization}

Every instruction cycle spent in a user program is a cycle in which
the operating system does not run. There are two basic ways in
which the operating system can take back control of the processor:
%
\begin{enumerate}

\item The application program \emph{intentionally} gives up the
  processor. For example, issuing a system call falls into this
  class. System calls usually involve invocation of a [[TRAP]] command
  on the CPU. As explained in Chapter~\ref{chap:hardware}, the result
  is a switch to system mode and the execution of an interrupt handler
  that belongs to the operating system.

\item The application program \emph{unintentionally} gives up the
  processor. This can be the result of an asynchronous interrupt like
  a timer interrupt or an I/O interrupt. The result is the same 
  as above: the CPU switches to system mode and the execution of
  an interrupt handler belonging to the operating system begins.

\end{enumerate}
%
In principle, the application program can avoid the first case: For
example, it could enter an infinite loop in which no system call is
issued.  Unless there is an asynchronous interrupt, the application
would monopolize the CPU. No other application program is ever able to
gain access to the processor. Since this must be avoided, the
operating system uses the second case to ensure that it always can
re-gain access to the processor. A central piece of hardware to
achieve this is the \emph{\vindex{timer unit}}.

The timer unit is a digital circuit with a builtin clock. It can be
instructed to raise periodic interrupts at the CPU. The length of the
period can usually be configured. These interrupts force the system
into an interrupt handler, giving back control of the processor to the
operating system. Programming the timer unit, i.e., determining the
length of the interrupt period for example, is a priviliged operation
that can only be performed in system mode. To prevent CPU
monopolization, it is therefore necessary to prevent untrustworthy
user programs to ever run in system mode. In case such an application
runs in system mode, it could disable any asynchronous interrupts and
therefore prevent the operating system from ever re-gaining access to
the CPU.


\subsection{Types of Threads}

Two different types of threads are usually distinguished:
\emph{\vindex{kernel-level threads}} and \emph{\vindex{user-level
    threads}}. The ``classical'' threads (i.e., the threads in UNIX
processes) are kernel-level threads. The distinction is based on the
mode in which the \vindex{context switch} is performed. In
kernel-level threads the context switch happens in system mode, in
user-level threads it happens in system mode.

Kernel-level threads can be regarded as \vindex{virtual processors}
running directly on physical processors. User-level threads can be
regarded as virtual processors running on kernel-level threads.  In
this sense, a team of kernel-level threads running in the same virtual
memory can be regarded as a \vindex{virtual multiprocessor} for
user-level threads.  

As we will see later, the techniques used to implement and synchronize
virtual processors (kernel-level threads) on physical processors are
the same as those used to implement and synchronize virtual processors
(user-level threads) on virtual processors (kernel-level
threads). Therefore people sometimes speak of a
\emph{\vindex{processor hierarchy}}. Virtual processors run on virtual
processors that run on physical processors. (Note that in principle it
is even possible to run user-level threads on user-level threads,
extending the processor hierarchy.) The multiplexing of higher-level
processors to lower-level processors is performed by a software layer
(see Figure~\ref{fig:processor:hierarchy}).  In case of kernel-level
threads implemented on physical processors this software layer is the
operating system; in case of user-level threads implemented on
kernel-level threads this software layer is usually called the
\emph{\vindex{user-level threadspackage}}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/processor-hierarchy.jpg}
  \caption{Schematic view of the processor hierarchy.}
  \label{fig:processor:hierarchy}
\end{figure}

\subsubsection{Kernel Level Threads}

Kernel-level threads are managed in system mode, i.e., the context
switch of one kernel-level thread to the next requires a system call.
This is why kernel-level threads are often called \emph{heavy-weight}
threads, because a system call usually incurs a large performance
overhead. For example, if the context switch from one kernel-level
thread to the next also causes a switch of one virtual memory to
another, the effect of caching in the \vindex{TLB} or in any other
\vindex{logical cache} is destroyed.


\subsubsection{User Level Threads}

User-level threads run on kernel-level threads. From the point of view
of user-level threads, kernel level threads are virtual processors
that carry the user-level threadspackage.
In contrast to kernel-level threads, user level threads are managed
entirely in user mode. This implies that the context switch of
user-level threads does not incur a context switch of the kernel-level
thread that carries it. This in turn implies that there is no switch
of virtual memories and no performance penalty. Therefore, user-level
threads are often called \emph{light-weight} threads.

As we will see below, the implementation of the dispatcher for
user-level threads is structurally similar to the implementation of
kernel-level threads. We will look at the implementation of
kernel-level threads first, so in the following, the term thread is
synonymous with the term kernel-level thread.


\section{Thread State}
\label{sec:thread:state}

\subsection{Simple State Model for Threads}
\label{sec:simple:state:model}

Threads have a lifecycle. They are born, live, and finally die. During
their life they undergo many changes. For example, they sometimes are
executed by a physical processor and sometimes not. This is what is
called the \emph{\vindex{thread state}} or simply
\emph{\vindex{state}}. The number and type of states together with the
transitions which a thread can experience during its lifetime is
called a \emph{\vindex{state model}}.

The simplest state model which can be found in almost every textbook
on operating systems consists of three states: [[running]],
[[ready]], and [[blocked]]. Here's what these states mean:
%
\begin{itemize}

\item A thread in state [[running]] is actually executing on a
  physical processor. If there are more than one processors in the
  system, more than one threads can be in this state.

\item A thread in state [[ready]] is not currently assigned to a
  physical processor, but it \emph{could} be assigned. In other words,
  the thread is \vindex{ready to run} in case a physical processor
  becomes free. Many threads can be in this state at the same time.
  After all, there can be many more virtual processors (threads) than
  physical processors. All these threads are kept within a list of
  threads called the \emph{\vindex{ready queue}}.

\item A thread in state [[blocked]] is waiting for a certain
  event. Only after this even has happened, it can become [[running]]
  or [[ready]] again. There can be many different events for which a
  thread can wait. For example, a thread could be waiting for a page
  fault to be services, i.e., waiting for an I/O operating to
  terminate. Another example is that a thread is waiting for a
  synchronization operation to be executed by another thread (see
  Chapter~\ref{chap:synchronization}). 

  Usually an indication of the event for which the thread is waiting
  is part of the [[blocked]] state. This can be interpreted as many
  different [[blocked]] states. For simplicity, most textbooks
  therefore reduce these states to just one. Many threads can be
  in a blocked state at the same time. They are kept internally within
  one (or more) \emph{blocked queues}\pindex{blocked queue}.

\end{itemize}
%
We will use this state model in \Ulix{}.

The possible transitions between thread states are depicted in
Figure~\ref{fig:simple:state:model}. We enumerate and explain them
here now:
%
\begin{itemize}

\item [[add]]: a new thread is dynamically created and enters the set
  of threads in the state [[ready]].

\item [[assign]]: a new thread from state [[ready]] is assigned to 
  the processor and becomes [[running]].

\item [[block]]: a running thread invokes a blocking system operation
  (e.g., I/O), runs in to a page fault or must wait for some other
  event to continue operation. Now a new thread can become
  [[running]]. (Note the difference between the thread state [[blocked]]
  and the state transition [[block]].)

\item [[deblock]]: the event for which a [[blocked]] thread is waiting
  has happened. Consequently, the [[blocked]] thread is transferred to
  the state [[ready]]. (Sometimes this transition is also called
  [[ready]], but since this can be confused with the thread state
  [[ready]] we prefer to call it [[deblock]].)

\item [[resign]]: the thread which is currently [[running]] has
  finished executing parts of its program and leaves the physical
  processor. It transits from state [[running]] back into state
  [[ready]]. Now a new thread can become [[running]].

\item [[retire]]: a currently [[running]] thread has finished
  executing its program code and terminates its lifetime.

\end{itemize}
%
Not all possible transitions from one state to the other exist in the
state model because a reduced state model decreases the complexity of
the implementation. For example it is rather uncommon to transit from
[[blocked]] directly to [[running]]. Similarly, a newly created thread
must be [[ready]] first before it may become [[running]].

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/simple-thread-state-model.jpg}
  \caption{States and state transitions in the simple state model for threads.}
  \label{fig:simple:state:model}
\end{figure}

The transitions of a thread from one state to the other are initiated
by the operating system and happen ``instantaneously''. Since a state
change needs many machine instructions, real
instantaneousness\pindex{instantaneousness (difficult word)} cannot be
achieved, so the operating system simulates atomic transitions using
synchronization operations in the kernel (see
Chapter~\ref{chap:synchronization}). In essence, the atomic
transitions are implemented in such ``atomic'' kernel functions which
carry the same name as the state transitions (e.g., [[assign]],
[[resign]], etc.). The place in the kernel where all these functions
are collected is called the \emph{\vindex{dispatcher}}.

Here are the forward declarations of the dispatcher functions. They
will be implemented later in
Section~\ref{sec:kernel:level:dispatcher:ulix}. Note that the
dispatcher operation [[block]] takes an indication to the event on
which the thread is blocking. This indication is encoded in the
particular blocked queue to which the thread should be added. The data
type of [[blocked_queue]] will be explained below.

All operations that load and store processor context need an indication
which CPU they are running on. This is important for multiprocessing,
as will be explained below.

<<kernel declarations>>=
typedef unsigned int thread_id;

<<declaration of blocked queue>>

void add(thread_id t);
void assign(int cpuid);
void block(int cpuid, blocked_queue* q); 
void deblock(thread_id t, blocked_queue* q);
void resign(int cpuid);
void retire(thread_id t);
@


\subsection{Thread States with Swapping}

In case of shortage of memory it may make sense to completely ``swap
out'' a process with all its threads and virtual memory to exteral
storage (see also Section~\ref{sec:swapping}). In this case it is
necessary to define an additional thread state [[swapped]].  The
additional state transitions are depicted in
Figure~\ref{fig:state:diagram:swapping}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/state-diagram-swapping.jpg}
  \caption{Thread states and state transitions for a system that
    supports swapping.}
\label{fig:state:diagram:swapping}
\end{figure}

\subsection{Thread Control Block}

The \emph{\vindex{thread control block}} (TCB)\pindex{TCB (thread
  control block)} is the central place in the kernel where information
about a thread is held. In the times when people used to speak about
processes instead of threads, the TCB was called the PCB\pindex{PCB
  (process control block)} which stands for \emph{\vindex{process
    control block}}. 

One main purpose of the TCB is to store the \emph{processor state} of
a thread (sometimes also called \emph{context}) during the times when
it is not assigned to a physical processor. Remember that threads are
only virtual processors who in general not always have a physical
processor supporting them. Note that the processor state is not the
same as the thread state. As seen above, the state of a thread can be
[[running]], [[blocked]] etc. The processor state is all information
that is necessary to pretend that the processor has never executed any
other thread as the one to which the TCB belongs.

The TCB contains (amoung others) the following information:
%
\begin{itemize}

\item A unique identifier of the thread. This is the so-called
  \emph{\vindex{thread identifier}} (TID)\pindex{TID (thread
    identifier)}. In previous times, the TID was often called
  PID\pindex{PID (process identifier)} for \emph{\vindex{process
      identifier}}.

\item Storage space to save the processor context, i.e., the
  registers, the stack pointer(s), etc.

\item Depending on the thread state, the TCB contains an indication
  on what event the thread is waiting for if it is in state [[blocked]].

\item Information about the address space which this thread is running
  in.

\item Any other information which may be useful to keep the system
  running efficiently. For example, statistical information could be
  stored here on how often the thread has been running in the past.
  This can help the scheduler make efficient scheduling decisions.

\end{itemize}

Note that the information about the address space must be handled
differently in PCBs and in TCBs. In a system where multiple threads
can run within one address space, there is a $n:1$ mapping between
threads and address spaces. In a classical Unix system with processes
(one address space with exactly one thread), the mapping is $1:1$ and
each thread can store the full address space information in the PCB
itself. With a $n:1$ mapping, an extra data structure is necessary
(the \vindex{address space table}, see
Section~\ref{sec:address:space:table}) to avoid having redundant
information in the TCBs.

So here is the declaration of the TCB structure. We have an entry for
the thread identifier [[tid]], the processor context consisting of the
general purpose registers and the special purpose registers (USP and
PC), plus a reference to the address space in which the thread runs.
More entries will follow later.

<<kernel declarations>>=
#define GPR_REGISTERS 6   //       REMOVE THIS!!!!
#define EAX 0
#define EBX 1
#define ECX 2
#define EDX 3
#define ESI 4
#define EDI 5

#define CMDLINE_LENGTH 50   // how long can a process name be?
typedef struct {
  thread_id tid;
  thread_id ppid;   // parent process
  unsigned int context[GPR_REGISTERS]; // general purpose registers
  // unsigned int esp; // user stack pointer  ((brauch ich den???)
  unsigned int esp0; // kernel stack pointer
  unsigned int eip; // program counter
  unsigned int ebp; // base pointer
  char* kstack;
  addr_space_id addr_space;
  int state;
  struct regs regs;  // for the new implementation!!!!!!
  char cmdline[CMDLINE_LENGTH];
  <<more TCB entries>>
} TCB;

@

\subsection{Thread Table}
\label{sec:thread:table}

The TCBs of all threads are collected in a giant table within the
kernel. This table is called the \emph{\vindex{thread table}}.  Again,
in ancient times when the table was a collection of PCBs instead of
TCBs, it was called \emph{\vindex{process table}}.

The thread table is simply an array of [[TCB]]s. The size of the
table must be finite, so there exists a \vindex{maximum number of threads}
which can coexist at any point in time. 

<<kernel declarations>>=
#define MAX_THREADS 1024
TCB thread_table[MAX_THREADS];

@ We define the maximum number of threads here. It should somehow
correspond to the maximum number of address spaces [[MAX_ADDR_SPACES]]
defined earlier in Section~\ref{sec:address:space:descriptors}. For
example, it doesn't make sense to allow more address spaces than
threads (since every thread can have at most one address space).



\subsection{Thread Queues}
\label{sec:thread:queues}

The operating system has to perform bookkeeping of the state of
threads. This can be done in several ways. One approach would be to
store an entry [[state]] of an enumeration type in the TCB that can
have the values [[blocked]], [[ready]] or [[running]].  This is viable
but not actually necessary. In modern operating systems the thread
state is stored implicitly through the collection of linked
lists\pindex{linked list}. These lists contain threads and function as
queues. The \vindex{ready queue} for example is a list of threads
which all are in state [[ready]].

As global data structures we therefore need a couple of global
variables:
%
\begin{itemize}

\item For every CPU in the system we need a reference to the thread
  that is currently assigned to the processor. For monoprocessor
  systems it is sufficient to provide a global variable [[running]] of
  type [[thread_id]]. For multiprocessor systems we have to provide
  such a variable for every CPU in the system.

\item A \emph{\vindex{ready queue}} enumerating all threads that are
  in state [[ready]].

\item For every separate class of events which can cause a thread to
  go in to state [[blocked]], we need a \emph{\vindex{blocked queue}}
  enumerating all threads that wait for such an event.

\item In case we have a system with swapping, another list is
  necessary holding all swapped out threads. This is called the
  \emph{\vindex{swapped out queue}}.

\end{itemize}

Here is the global variable holding the thread identifier of the
currently running thread. If [[NUM_CPUS==1]] then it doesn't
matter whether we say [[running]] or [[running[0]]] in the code
accessing it.

<<kernel global variables>>=
#define NUM_CPUS 1   // MOVE THIS TO ANOTHER PLACE !!!
thread_id running[NUM_CPUS];
@


\subsection{Dispatcher and Scheduler}

The \emph{\vindex{dispatcher}} is the part in the kernel that contains
the code to perform state transitions of threads. It provides
implementations of the transition functions like [[block]],
[[deblock]], and [[assign]]. One reason to put all this code in one
place is that the tricky manipulations of the thread queues is
confined to one place, making it easier to add proper synchronization
(see Chapter~\ref{chap:synchronization}. The dispatcher belongs to the
most intricate parts of the operating system, since it implements the
\vindex{context switch} and has to deal with lots of special cases
like invoking the scheduler on an empty ready queue.

The \emph{\vindex{scheduler}} is the specific part of the dispatcher
that is responsible for selecting the next thread to run from the
ready queue. In \Ulix{} the scheduler is a simple function
[[schedule]] that selects a thread id from the ready queue, removes it
from there and returns it.

<<kernel declarations>>=
thread_id schedule();
@


<<kernel functions>>=
thread_id schedule() {
  return 0;
};
@



\section{Monoprocessor Scheduling}
\label{sec:monoprocessor:scheduling}

\subsection{Quality Metrics}

Scheduling is one of the best understood parts of operating systems
because it has such an important impact on system
performance. However, it is not so easy to say what the ``best
scheduler'' is because it depends very much on the definition of
quality used in a particular situation. Here are several common
quality metrics for scheduling algorithms, the more historical ones
are listed first:
%
\begin{itemize}

\item The metric of \emph{\vindex{CPU usage}} is one of the simplest
  notions of quality in the literature. It basically gives the
  percentage of time in which the CPU actually executed application
  instructions (in contrast to operating system instructions or being
  idle). The CPU usage is important if CPUs are very expensive (as it
  was in earlier times). Today, the CPU usage of common desktop
  computers is usually very low, since they are idle most of the time.

\item The \emph{\vindex{throughput}} of a system usually counts the
  numer of tasks that the system executed per time unit. This metric
  depends on the definition of ``task''. It comes from a time in which
  computers did batch processing: A number of computation jobs were
  ready in a physical entry queue (for example in the form of punched
  cards). The computer then started the processing of these jobs. The
  throughput counted the number of such jobs that the system could
  execute per hour (for example).

\item The \emph{\vindex{turnaround time}} of a thread is the time it
  takes for the thread to be scheduled again. In other words, it is
  the time between two successive selections of the thread by the
  scheduler. The turnaround time of the entire system is the averade
  turnaround time of all threads. The turnaround time can be regarded
  as a refined throughput metric. While throughput refers to jobs,
  turnaround refers to threads.

\item The \emph{\vindex{waiting time}} of a thread is the average time
  it has to wait in the ready queue before it is scheduled. This is
  not the same as throughput since times when the thread is blocked do
  not count in the waiting time.

\item The \emph{\vindex{response time}} of a thread is the time it
  takes for the thread to respond to user input. This is similar to
  the turnaround and waiting time, only that responses to user inputs
  are counted instead of being scheduled again.

\item Finally, a scheduler is \emph{\vindex{real time}} if it manages to
  satisfy real time bounds.

\end{itemize}

\subsection{Preemptive vs.~Non-preemptive Scheduling}

There are two main classes of scheduling algorithms: \emph{preemptive}
ones and \emph{non-preemptive} ones.\pindex{preemptive~scheduling}
\pindex{non-preemptive scheduling} Roughly speaking, preemptive
scheduling algorithms allow that a thread is thrown off the processor
even if that thread does not want to be thrown off. In practice, all
scheduling algorithms are usually preemptive in order to prevent that
threads (accidentally) monopolize the system.

The precise definition is as follows: A scheduling algorithm is
\emph{preemptive}\pindex{preemptive scheduling algorithm} if an
asynchronous interrupt can cause a thread to be taken off from the
processor. This corresponds to the second way in which the operating
system can re-gain control over the CPU (see
Section~\ref{sec:preventing:cpu:monopolization}). As a rough
guideline, in case the handler for an asynchronous interrupt contains
a call to [[assign]] then the scheduler is preemptive.


\subsection{First-Come First-Served}

\begin{work}
  Ch 5, slide 36, 37, 38
\end{work}

\subsection{Shortest Job First}

\begin{work}
  Ch 5, slide 39, 40, 42
\end{work}


\subsection{Round Robin}

\begin{work}
  Ch 5, slide 43, 44
\end{work}

\subsection{Priority-Based Scheduling}

\begin{work}
  Ch 5, slide 46, 47, 48
\end{work}

\subsection{Multi-Level Scheduling}

\begin{work}
  Ch 5, slide 49, 50
\end{work}




\section{Real-Time Scheduling}
\label{sec:real:time:scheduling}

\begin{work}
  Probably not, if necessary, then: Ch 5, slides 52--63
\end{work}



\section{Multiprocessor Scheduling}
\label{sec:multiprocessor:scheduling}

\begin{work}
  Ch 5, slide 65, 66, 67, 69, 70
\end{work}


\section{Thread APIs}
\label{sec:thread:APIs}

\begin{work}
  Maybe not, if necessary, then: Ch 5, 73--82

  Discuss fork and exec (see Section~\ref{sec:address:space:creation}).

  Maybe just a minimal API, the one implemented by \Ulix{}:

  [[fork]] new thread in new virtual memory

  [[create_kl_thread(address)]] starts a new thread executing program
  starting at address in same virtual memory.

\end{work}





\codesection{Kernel Level Thread Dispatcher in \Ulix{}}
\label{sec:kernel:level:dispatcher:ulix}

We now have a look how the dispatcher is implemented in \Ulix{}. The
dispatcher operations like [[assign]], [[resign]], etc.~are very
critical in operating systems because they are invoked so often during
the lifetime of the system. Basically, the dispatcher operation
determine the main performance overhead of the operating system: Any
CPU cycle spent within a dispatcher routine cannot be used within an
application. In practice therefore, the code of the dispatcher is very
highly optimized, mostly written directly in assembly language.

There are of course many other factors which influence the performance
overhead of the dispatcher. Amoung them are the scheduling strategy,
the size and structure of the register set on the CPU, and the size and
structure of the different caches on the mainboard (including the TLB
within the MMU). Since \Ulix{} is not meant to be commercially relevant,
we have the privilege here to write dispatcher code here with main focus
on readability.

\subsection{Dispatcher Functions as Critical Sections}
\label{sec:dispatcher:funtcions:as:critical:sections}

The main work of implementing threads lies in the implementation of
the dispatcher. Roughly speaking, the dispatcher must offer the state
transition functions of the state model described in
Section~\ref{sec:simple:state:model}. All of the functions manipulate
lists of threads within the kernel. For example, [[assign]] removes a
thread from the [[ready]] list and assigns it to the processor.  As we
will see later in Chapter~\ref{chap:synchronization}, access to global
data structures like lists must happen atomically, i.e., in a mutually
exclusive fashion. The central abstraction to implement this is called
a \emph{\vindex{critical section}}. We will define this term more
precisely in Chapter~\ref{chap:synchronization}, but for now it
suffices to assume that dispatcher functions are executed in a
mutually exclusive way. Chapter \ref{chap:synchronization} also shows
how the necessary synchronization can be achieved using various
techniques.


\subsection{Implementing Lists of Threads}
\label{sec:implementing:lists:of:threads}

Queues are standard data structure offered by almost all modern
programming languages. As an example, Java offers the generic class
[[ArrayList<E>]] in which objects of any type [[E]] can be stored and
manipulated with standard operations like [[add()]], [[size()]] and
[[get()]]. Unfortunately, ``plain'' C does not offer this convenience
so we have to implement queues by ourselves.

As explained in Section~\ref{sec:thread:queues}, we have to maintain a
couple of thread queues within the kernel. In \Ulix{} we maintain
only two: the \vindex{ready queue} and the \vindex{blocked queue}.
In fact, the blocked queue is not a single queue but there can
be multiple blocked queues, one for every event upon which a thread
can wait. 

When implementing such queues, we could think about using the standard
implementation of a (double) linked list found in any introductory
textbook on programming. However these implementations usually are
examples of programming with dynamic memory allocation, e.g., in C
using the [[malloc]] library call to allocate fresh memory on the
heap. This would be a problem in \Ulix{} since we neither have a
heap nor a library to call into.

So how can we program linked lists without allocating memory?  The
first option is to do it like Knuth\pindex{Knuth, Donald E.} did it in
\TeX{}\pcindex{TeX}{\TeX{}} \cite{Knuth:1986:TTP} and provide both a
large memory area plus functions for memory allocation and
deallocation by ourselves.  Since this would be overkill, we choose
the second option, which is also the option taken in many operating
systems: We use the thread table to implement lists. The idea is to
declare two additional entries in the \vindex{thread control block}:
one entry called [[next]] and one called [[prev]]. Both point to other
entries in the thread table. So consider a thread control block [[TCB t]]. 
The entry [[t.next]] points to the ``next'' thread in the queue
in which [[t]] is in. Similarly, [[t.prev]] points to the ``previous''
thread in [[t]]'s queue. 

We define the range of these two pointers to be [[thread_id]]. 

<<more TCB entries>>=
thread_id next; // id of the ``next'' thread
thread_id prev; // id of the ``previous'' thread

@ An example of the semantics of the [[prev]] and [[next]] entries in
the thread table is shown in
Figure~\ref{fig:ready:queue:implementation}. It shows that the thread
identifier 0 is used as an ``end marker'' for the lists. It also shows
that the [[prev]] entry of the first entry in the queue points to the
last element in the queue. In this way, it is easily possible to
navigate through the queues in any way which is convenient. 

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/ready-queue-implementation.jpg}
  \caption{Implementation of ready queue and blocked queues. The
    beginning of the ready queue is implicitly defined by entry 0 in
    the thread table. The beginning of a blocked queue is a pair of
    thread identifiers pointing into the thread table from ``outside''.}
  \label{fig:ready:queue:implementation}
\end{figure}

Figure~\ref{fig:ready:queue:implementation} also shows a small
implementation \vindex{trick}. The \vindex{thread identifier} of the
thread itself is always equal to the index of the thread in the
\vindex{thread table}. Given a TID\pindex{TID (thread identifier)} of
[[t]], then [[thread_table[t]]] is the thread control block of that
thread. This also means that the entry [[tid]] in the \vindex{thread
  control block} is more or less superfluous.

Now since we are using the value 0 to mark the end of a list, the
entry 0 in the thread table has become more or less useless to store
thread information. We use it instead as the ``anchor'' of the
\vindex{ready queue}. So to access the first element in the ready queue,
we just need to look into: 
%
\begin{center}
  [[thread_table[0].next]]
\end{center}
%
The last entry in the ready queue can similarly be accessed using the
following expression:
%
\begin{center}
  [[thread_table[0].prev]]
\end{center}
%
The ready queue in the figure contains threads 1, 4, and 7 (in this
order).

Recalling the simple state model of threads in
Section~\ref{sec:simple:state:model}, every thread is in exactly one
state at any time. This means that a thread is either running, ready
or blocked. This also means that a thread can be in at most one queue
at a time. In case the thread is blocked instead of ready, we can
re-use the [[prev]] and [[next]] entries in the thread table
to implement the blocked list. We only need to have an anchor
for this blocked list. This anchor will be a structure similar to 
the 0-th entry in the thread table.

<<declaration of blocked queue>>=
typedef struct {
  thread_id next; // id of the ``next'' thread
  thread_id prev; // id of the ``previous'' thread
} blocked_queue;

@ So assume [[b]] is a variable of type [[blocked_queue]] representing
a blocked list. If both entries in [[b]] are 0, then the list is
empty.  If not, then using the thread table we can now find the first,
second etc.~element by following the [[next]] pointers.  Following the
[[next]] pointers in this way, we can traverse the entire list until
we reach an entry in which [[next==0]]. That's the \vindex{end of the
  list}.  Looking again at
Figure~\ref{fig:ready:queue:implementation}, the blocked queue
contains threads 2, 5 and 6 (in this order).

Finally, here's a useful function to initialize a blocked queue.
This is just to encapsulate the semantics of ``emptiness''.

<<kernel functions>>=
void initialize_blocked_queue(blocked_queue* q) {
  q->prev = 0;
  q->next = 0;
}
@


\subsubsection{Implementing the Ready Queue}

We now provide some convenient functions to add and remove
threads from the queues. We start with the ready queue. The
function [[add_to_ready_queue(t)]] adds the thread with
identifier [[t]] to the \emph{end} of the ready queue. It assumes
that the TCB of thread [[t]] has been set up and initialized
already.

The function [[remove_from_ready_queue(t)]] removes the thread
with identifier [[t]] from the ready queue. It assumes that
[[t]] is contained in the ready queue.


<<kernel declarations>>=
void add_to_ready_queue(thread_id t);
void remove_from_ready_queue(thread_id t);

@ Adding to the end of the ready queue is as easy since
we have a double linked list.

<<kernel functions>>=
void add_to_ready_queue(thread_id t) {
  thread_id last = thread_table[0].prev;
  thread_table[0].prev = t;
  thread_table[t].next = 0;
  thread_table[t].prev = last;
  thread_table[last].next = t;
}

@ Removing is similarly easy.

<<kernel functions>>=
void remove_from_ready_queue(thread_id t) {
  thread_id prev_thread = thread_table[t].prev;
  thread_id next_thread = thread_table[t].next;
  thread_table[prev_thread].next = next_thread;
  thread_table[next_thread].prev = prev_thread;
}

@ We initialize the ready queue to be empty.

<<initialize kernel global variables>>=
thread_table[0].prev = 0;
thread_table[0].next = 0;
@


\subsubsection{Implementing a Blocked Queue}

Blocked queues are implemented similar to the ready queue, except that
the functions are parametrized with a blocked list anchor defined
above. We provide again two functions to add and remove a thread from
a blocked list. Adding to the queue happens at the ``end'' of the
queue. An additional function allows to inspect the ``front'' queue
element.

<<kernel declarations>>=
void add_to_blocked_queue(thread_id t, blocked_queue* bq);
void remove_from_blocked_queue(thread_id t, blocked_queue* bq);
thread_id front_of_blocked_queue(blocked_queue bq);

@ We implement the easy inspector function to retrieve the front of a
blocked queue first. It is so easy that we could have avoided writing
this function alltogether (using a noweb macro), but we spell it
out for students who have learnt the concept of information hiding.

<<kernel functions>>=
thread_id front_of_blocked_queue(blocked_queue bq) {
  return bq.next;
}

@ We now implement [[add_to_blocked_queue]]. Adding happens
at the \emph{end} of the queue. The following code is an adaption
of the code for the ready queue. The conditional statement at
the end is necessary since [[thread_table[0]]] is not the
anchor of a blocked queue.

<<kernel functions>>=
void add_to_blocked_queue(thread_id t, blocked_queue* bq) {
  thread_id last = bq->prev;
  bq->prev = t;
  thread_table[t].next = 0; // [[t]] is ``last'' thread
  thread_table[t].prev = last;
  if (last == 0) {
    bq->next = t;
  } else {
    thread_table[last].next = t;
  }
}

@ Removal is similar to the function of the ready queue, except
for again the special cases at the end.

<<kernel functions>>=
void remove_from_blocked_queue(thread_id t, blocked_queue* bq) {
  thread_id prev_thread = thread_table[t].prev;
  thread_id next_thread = thread_table[t].next;
  if (prev_thread == 0) {
    bq->next = next_thread;
  } else {
    thread_table[prev_thread].next = next_thread;
  }
  if (next_thread == 0) {
    bq->prev = prev_thread;
  } else {
    thread_table[next_thread].prev = prev_thread;
  }
}

@ Note that with the above functions we can easily write code
that deblocks the ``front'' element from a blocked queue (if it
exists) as follows:
%
\begin{center}
  [[deblock(front_of_blocked_queue(bq), &bq);]]
\end{center}

@ Looking back, we could have implemented the ready queue using the
functions of the blocked queue and just passing [[thread_table[0]]]
instead of a blocked queue anchor. The code for the ready queue
is however a little simpler, and therefore we decided to leave
it as it is.





\subsection{Allocating and Initializing a New TCB}

\begin{work}
  Do the following:
  \begin{enumerate}
  \item Find free slot in thread table for new TCB
  \item Allocate virtual memory (if necessary) and link it into TCB
  \item Initialize common TCB context (state of common registers)
  \item Initialize special TCB context (return address for PC)
  \end{enumerate}

  How do we know that a TCB is empty?
\end{work}


\black


We add a [[used]] entry to the thread control block structure
[[TCB]]:

<<more TCB entries>>=
boolean used;
@

(Since we initialize the TCB structures with null bytes, we use
[[used]] and not [[free]]: remember that [[false]]=0.)

This will allow us to quickly find a free TCB when we create a new
thread. Instead of adding such a field, we could have used a bitmap,
but since we restrict ourselves to 1024 TCBs, not much space is
wasted this way, and searching for a free TCB will be quick.

So searching for a free TCB looks like this:

<<kernel global variables>>=
int next_pid = 1;
@

<<find free TCB entry>>=
boolean tcbfound = false;
int tcbid;
for ( tcbid=next_pid; ((tcbid<MAX_THREADS) && (!tcbfound)); tcbid++ ) {
  if (thread_table[tcbid].used == false) {
    tcbfound = true;
    break;
  }
};
// continue searching at 1
if (!tcbfound) {
  for ( tcbid=1; ((tcbid<next_pid) && (!tcbfound)); tcbid++ ) {
    if (thread_table[tcbid].used == false) {
      tcbfound = true;
      break;
    }
  };
};
// update next_pid:
if (tcbfound) next_pid = tcbid+1;
// either tcbfound == false or tcbid == index of first free TCB
@

Once we have a free address space (or reuse one) and also have
a free TCB, we can connect them:

<<kernel functions>>=
int register_new_tcb (int as_id) {
  <<find free TCB entry>>
  if (!tcbfound) {
    return -1; // no free TCB!
  };
  thread_table[tcbid].used = true;         // mark as used
  thread_table[tcbid].addr_space = as_id;  // enter address space ID
  return tcbid;
}  
@

Note that so far we have not entered the new TCB in the ready or
one of the blocked queues. This will happen later when the thread
has been fully initialized.

\green



\subsection{Simple Dispatcher Operations}

We now look at the implementations of the three simplest dispatcher
operations. These are [[add]], [[retire]] and [[deblock]]. They
are simple because they basically only move threads from one
queue to the other.

The functions [[add]] and [[retire]] take as parameter the identifier
of the thread which is newly born or about to die. The function
[[deblock]] needs another argument: The blocked queue from which the
thread is to be removed.

<<kernel functions>>=
void add(thread_id t) {
  add_to_ready_queue(t);
}
void retire(thread_id t) {
  remove_from_ready_queue(t);
}

void deblock(thread_id t, blocked_queue* q) {
  remove_from_blocked_queue(t, q);
  add_to_ready_queue(t);
}
@


\subsection{Dispatcher Operations Involving CPU Context}

\subsubsection{Implementing resign}

We now start to look at the more intricate dispatcher operations, the
first is [[resign]]. Conceptually, [[resign]] should do the following:
%
\begin{enumerate}

\item Save the current processor context to the TCB of the currently
  running thread.

\item Put the TID of the currently running thread into the [[ready]] queue.

\end{enumerate}
% 
So the first approximation of [[resign]] is this:

<<kernel functions>>=
void resign(int cpuid) {
  <<save processor context of running thread>>
  add_to_ready_queue(running[cpuid]);
}

@ Regarding the first point: What is the current processor context?
Most of this is clear: The processor registers, the stack pointers
etc.  

\begin{work}
  Discuss inline assembler
\end{work}

<<save processor context of running thread>>=
  __asm__ ("\
    .intel_syntax noprefix; \
    mov %0, eax; \
    mov %1, ebx; \
    mov %2, ecx; \
    mov %3, edx; \
    mov %4, esi; \
    mov %5, edi; \
    .att_syntax"
    :
    
    "=r"(thread_table[running[cpuid]].context[EAX]),   // eax
    "=r"(thread_table[running[cpuid]].context[EBX]),   // ebx
    "=r"(thread_table[running[cpuid]].context[ECX]),   // ecx
    "=r"(thread_table[running[cpuid]].context[EDX]),   // edx
    "=r"(thread_table[running[cpuid]].context[ESI]),   // esi
    "=r"(thread_table[running[cpuid]].context[EDI])    // edi
  );

  // WHAT ABOUT stack and PC?


/*
asm( "move int thread_table[running[cpuid]].R[0], R0"
     "move int thread_table[running[cpuid]].R[1], R1"
     "move int thread_table[running[cpuid]].R[2], R2"
     "move int thread_table[running[cpuid]].R[3], R3"
     "move int thread_table[running[cpuid]].R[4], R4"
     "move int thread_table[running[cpuid]].R[5], R5"
     "move int thread_table[running[cpuid]].R[6], R6"
     "move int thread_table[running[cpuid]].R[7], R7"
     "move int thread_table[running[cpuid]].R[8], R8"
     "move int thread_table[running[cpuid]].R[9], R9"
     "move int thread_table[running[cpuid]].R[10], R10"
     "move int thread_table[running[cpuid]].R[11], R11"
     "move int thread_table[running[cpuid]].R[12], R12"
     "move int thread_table[running[cpuid]].R[13], R13"
     "move int thread_table[running[cpuid]].R[14], R14"
     "move int thread_table[running[cpuid]].R[15], R15"
     "move int thread_table[running[cpuid]].USP, USP" );
*/
@ 

\subsubsection{Finding the Correct Program Counter Value}

Storing general purpose registers and the stack pointer is not
all. What about things like the program counter?  To see why this is
problematic, consider an example where [[resign]] is used. The example
is a system call named [[yield]] which basically gives up the
processor for the current thread. This system call is implemented
using a [[TRAP]] and a jump to the service routine for the system call
which could look like this:

\begin{work}
  have one handler per CPU, use the cpu id to invoke resign(id) and
  assign(id)
\end{work}

<<kernel functions>>=
void yield_interrupt_handler() {
  resign(0);     /* check argument: CPU id  **hge** */
  assign(0);
  /*  asm( "RTI" );  */
}

@ Remember that a context switch always happens in system mode. This
means that the CPU has already switched to system mode before the
interrupt handler is invoked. During this procedure, part of the
original processor context has been saved already because [[TRAP]] is
like a forced procedure call. In particular, the program counter,
which conceptually is an important part of the thread context, is
\emph{not} the program counter which we originally wanted --- it is
now the program counter from within the interrupt handler and not the
one within the user program.

But where is the ``correct'' value of the program counter? This
depends on the architecture and is the reason why the critical
dispatcher operations which handle the thread context are so different
and complex in every operating system. 


\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/correct-program-counter.jpg}
  \caption{Where to find the correct value of the program counter? In
    the \Ulix{} hardware it is on the system stack.}
  \label{fig:correct:program:counter}
\end{figure}

\begin{work}
  For the \Ulix{} architecture, the real value of the program counter
  is somewhere on the system stack.

  Explain Figure~\ref{fig:correct:program:counter}.
\end{work}

<<save processor context of running thread>>=
/*
asm( "move int thread_table[running[cpuid]].PC, [SSP+8]" );
*/
@

\subsubsection{Implementing assign}

The dispatcher operation [[assign]] is something like the ``inverse''
to [[resign]] it \emph{loads} the thread context into the CPU. But
before doing this, it has to select the ``next'' thread which is to be
taken on to the processor. This is done within the
\emph{\vindex{scheduler}} which is implemented as a function
[[schedule()]]. It simply selects from the ready queue the next thread
to run.

<<kernel functions>>=
void assign(int cpuid) {
  running[cpuid] = schedule(); // invoke the scheduler
  <<load processor context of running thread>>
}

@ Here we load the processor context.

\begin{work}
  explain
\end{work}
  
<<load processor context of running thread>>=
  __asm__ ("\
    .intel_syntax noprefix; \
    mov eax, %0; \
    mov ebx, %1; \
    mov ecx, %2; \
    mov edx, %3; \
    mov esi, %4; \
    mov edi, %5; \
    .att_syntax"
    :: 
    
    "r"(thread_table[running[cpuid]].context[EAX]),   // eax
    "r"(thread_table[running[cpuid]].context[EBX]),   // ebx
    "r"(thread_table[running[cpuid]].context[ECX]),   // ecx
    "r"(thread_table[running[cpuid]].context[EDX]),   // edx
    "r"(thread_table[running[cpuid]].context[ESI]),   // esi
    "r"(thread_table[running[cpuid]].context[EDI])    // edi
  );
  
  // WHAT ABOUT stack and PC?
  
  // update TSS (new stack) 

/*

asm( "move int R0, thread_table[running[cpuid]].R[0]"
     "move int R1, thread_table[running[cpuid]].R[1]"
     "move int R2, thread_table[running[cpuid]].R[2]"
     "move int R3, thread_table[running[cpuid]].R[3]"
     "move int R4, thread_table[running[cpuid]].R[4]"
     "move int R5, thread_table[running[cpuid]].R[5]"
     "move int R6, thread_table[running[cpuid]].R[6]"
     "move int R7, thread_table[running[cpuid]].R[7]"
     "move int R8, thread_table[running[cpuid]].R[8]"
     "move int R9, thread_table[running[cpuid]].R[9]"
     "move int R10, thread_table[running[cpuid]].R[10]"
     "move int R11, thread_table[running[cpuid]].R[11]"
     "move int R12, thread_table[running[cpuid]].R[12]"
     "move int R13, thread_table[running[cpuid]].R[13]"
     "move int R14, thread_table[running[cpuid]].R[14]"
     "move int R15, thread_table[running[cpuid]].R[15]"

     "move int USP, thread_table[running[cpuid]].USP"
     "move int [SSP-8], thread_table[running[cpuid]].PC" );
*/
@ 

\begin{work}
  Need to check/explain restoration of interrupt levels: current
  version of assign only works if [[assign]] is initiated only on the
  lowest interrupt level, i.e., after all upper levels have been
  restored. Think of [[assign]] being invoked in an IO handler which
  was initiated within a timer interrupt handler. In this case the new
  thread will jump back into the timer interrupt handler (depending on
  how assign is implemented). 
\end{work}


\subsubsection{Implementing block}

Block is just a variant of [[resign]], except that the
thread goes into the blocked queue instead of the ready
queue.

<<kernel functions>>=
void block(int cpuid, blocked_queue* q) {
  <<save processor context of running thread>>
  add_to_blocked_queue(running[cpuid], q);
}

@

\subsection{Handling an Empty Ready Queue}

\begin{work}
  Ch 5, slide 98
\end{work}

\begin{work}
  More details on KL threads: excercise 7
\end{work}



\codesection{User Level Threads Package in \Ulix{}}
\label{sec:user:level:threads:package:ulix}




\begin{work}
  Ch 5, slide 101, 102 plus excercise 9

  slide 102 is already here as
  Figure~\ref{fig:user:level:threads:on:kernel:level:threads}.
\end{work}


\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/user-level-threads-on-kernel-level-threads.jpg}
  \caption{Using a virtual multiprocessor to exploit concurrency
    within a user level threads package.}
  \label{fig:user:level:threads:on:kernel:level:threads}
\end{figure}

\section{Summary}

\begin{work}
  Summary and outlook
\end{work}






\black









\codesection{Processes and Threads in \Ulix{}}

\subsection{User Mode and the TSS Structure}

In order to enter user mode we will have to create a structure
called TSS (task state segments).

\begin{figure}[t]
  \centering
  \includegraphics[width=10cm]{pics/intel-tss.png}
  \caption{The TSS structure (source: Intel \cite[p. 303]{intel-part3}).}
  \label{fig:intel-tss}
\end{figure}

\red
<<kernel declarations>>=
typedef unsigned short u16int;
typedef struct {
   uint   prev_tss;   // Previous TSS
   uint   esp0;       // The stack pointer to load when we change to kernel mode.
   uint   ss0;        // The stack segment to load when we change to kernel mode.
   uint   esp1, ss1;  // Unused...
   uint   esp2, ss2;
   uint   cr3;
   uint   eip;
   uint   eflags;
   uint   eax, ecx, edx, ebx, esp, ebp, esi, edi;
   // Values to load into ES when switching to kernel mode
   uint   es, cs, ss, ds, fs, gs;
   uint   ldt;        // Unused...
   u16int trap;       // just the lowest bit
   u16int iomap_base;
} __attribute__((packed)) tss_entry_struct;

tss_entry_struct tss_entry;
@ %def tss_entry tss_entry_struct
\black

We add this to the GDT definition (see page ....):

<<install GDTs for User Mode>>=
gdt_set_gate(3, 0, 0xFFFFFFFF, 0xFA, 0xCF);
gdt_set_gate(4, 0, 0xFFFFFFFF, 0xF2, 0xCF);
write_tss(5, 0x10, 0x0);
@


Here's the definition of [[write_tss]]:

<<kernel declarations>>=
static void write_tss(int num, u16int ss0, uint esp0);
@

<<kernel functions>>=
// Initialise our task state segment structure.
static void write_tss(int num, u16int ss0, uint esp0)
{
   // Firstly, let's compute the base and limit of our entry into the GDT.
   uint base = (uint) &tss_entry;
   uint limit = base + sizeof(tss_entry);

   // Now, add our TSS descriptor's address to the GDT.
   gdt_set_gate(num, base, limit, 0xE9, 0x00);

   // Ensure the descriptor is initially zero.
   memset(&tss_entry, 0, sizeof(tss_entry));

   tss_entry.ss0  = ss0;  // Set the kernel stack segment.
   tss_entry.esp0 = esp0; // Set the kernel stack pointer.

   // Here we set the cs, ss, ds, es, fs and gs entries in the TSS. These specify what
   // segments should be loaded when the processor switches to kernel mode. Therefore
   // they are just our normal kernel code/data segments - 0x08 and 0x10 respectively,
   // but with the last two bits set, making 0x0b and 0x13. The setting of these bits
   // sets the RPL (requested privilege level) to 3, meaning that this TSS can be used
   // to switch to kernel mode from ring 3.
   tss_entry.cs   = 0x0b;
   tss_entry.ss = tss_entry.ds = tss_entry.es = tss_entry.fs = tss_entry.gs = 0x13;
} 
@

<<flush TSS>>=
tss_flush();
@

It is defined in the assembler file:

\red
<<tss flush code in start.asm>>=
[section .text]
[GLOBAL tss_flush]    ; Allows our C code to call tss_flush().
tss_flush:
   mov ax, 0x2B      ; Load the index of our TSS structure - The index is
                     ; 0x28, as it is the 5th selector and each is 8 bytes
                     ; long, but we set the bottom two bits (making 0x2B)
                     ; so that it has an RPL of 3, not zero.
   ltr ax            ; Load 0x2B into the task state register.
   ret
@
\black

<<kernel declarations>>=
extern void tss_flush();
@


\subsection{Process Creation --- 1st attempt}

I create processes from simple C programs (with a \verb#main()#
function) with the following script:

<<script to create process>>=
NAME=p1
gcc -std=c99 -Wall -O0 -fstrength-reduce -fomit-frame-pointer \
  -finline-functions -nostdinc -fno-builtin -c -o $NAME.o $NAME.c
ld -T process.ld -o $NAME.com $NAME.o

echo "static char procbin[] __attribute__ ((aligned (4096))) = {" \
  > $NAME.hex
hexdump $NAME.com | cut -c 9- | fmt -n 2 | sed -e \
  's/^/0x/' -e 's/$/, /' | fmt -n 60 | sed -e 's/0x,//g' >> $NAME.hex
echo "};" >> $NAME.hex
@

with this linker script:

<<process.ld>>=
OUTPUT_FORMAT("binary")
ENTRY(main)
phys = 0x0;
SECTIONS {
  . = phys;
  
  .text : AT(phys) {
    code = .;
    *(.text)
    *(.rodata*)
    . = ALIGN(4096);
  }

  .data : {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }

  .bss : {
    bss = .;
    *(COMMON*)
    *(.bss*)
    . = ALIGN(4096);
  }
  end = .;
}
@

It defines the output format as [[binary]] because we don't 
want to have any ELF headers or other non-program data in the
created file---currently there is no intelligent program
loader that would be able to read ELF headers \& Co.

The binary file created by the linker has a [[.com]] ending
for the following reason: MS-DOS (and CP/M) worked with 
[[.com]] files, and Wikipedia
(\url{http://en.wikipedia.org/wiki/COM_file})
says this about [[.com]] files:

\begin{quotation}
``It is very simple; it has no header, and contains no metadata, 
only code and data.''
\end{quotation}

---which is exactly, what our [[.com]] file does. Later, when
we have a filesystem and a program loader, program files on
the disk may also have a [[.com]] extension.

For the following sample program

<<sample user mode program>>=
int main () {
  int i;
  int j=0;
  for (i=1; i<10; i++) {
    j += i;
    j = j+1;
  };
  __asm__ ("movl $0xabcd,%eax");
  __asm__ ("int $0x80\n");
  return j;
}
@

this creates a C variable declaration:

<<created C variable declaration>>=
static char procbin[] __attribute__ ((aligned (4096))) = {
0x83, 0xec, 0x10, 0xc7, 0x44, 0x24, 0x0c, 0x00, 0x00, 0x00,
0x00, 0xc7, 0x44, 0x24, 0x08, 0x01, 0x00, 0x00, 0x00, 0xeb,
0x10, 0x8b, 0x44, 0x24, 0x08, 0x01, 0x44, 0x24, 0x0c, 0xff,
0x44, 0x24, 0x0c, 0xff, 0x44, 0x24, 0x08, 0x83, 0x7c, 0x24,
0x08, 0x09, 0x7e, 0xe9, 0xb8, 0xcd, 0xab, 0x00, 0x00, 0xcd,
0x80, 0x8b, 0x44, 0x24, 0x0c, 0x83, 0xc4, 0x10, 0xc3, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 
};
@

Syntactically, there's a comma too much, which could easily 
be removed in the script, but I wanted to keep it simple...
Also note that there are some trailing null bytes after the
[[ret]] command ([[0xc3]]), but they don't disturb us.

This array declaration can be included in the \UlixI{} sources. It will
create a page-aligned array which fits in one or more pages so that
a page table for the new process can be setup.

For dissassembling I use \verb#udis86# and the included command line tool
\verb#udcli# (\url{http://udis86.sourceforge.net/}).

Disassembling the intermediate file (\verb#*.com#) reveals
the assembler code for our C program\footnote{Running the C compiler
with the [[-S]] option will also produce readable assembler code, but
the output of [[udcli]] nicely presents the addresses.}:

<<disassembled .com file>>=
0000000000000000 83ec10           sub esp, 0x10           
0000000000000003 c744240c00000000 mov dword [esp+0xc], 0x0
000000000000000b c744240801000000 mov dword [esp+0x8], 0x1
0000000000000013 eb10             jmp 0x25                
0000000000000015 8b442408         mov eax, [esp+0x8]      
0000000000000019 0144240c         add [esp+0xc], eax      
000000000000001d ff44240c         inc dword [esp+0xc]     
0000000000000021 ff442408         inc dword [esp+0x8]     
0000000000000025 837c240809       cmp dword [esp+0x8], 0x9
000000000000002a 7ee9             jle 0x15                
000000000000002c b8cdab0000       mov eax, 0xabcd         
0000000000000031 cd80             int 0x80                
0000000000000033 8b44240c         mov eax, [esp+0xc]      
0000000000000037 83c410           add esp, 0x10           
000000000000003a c3               ret                     
@

(If you want to see the AT\&T assembler syntax which we also use
for inline assembler code in C programs, use the \verb#udcli#
option \verb#-att#.)

<<kernel declarations>>=
#define boolean unsigned int
#define true 1
#define false 0
#define null 0
typedef unsigned char byte;  /* will use "byte" type */
@


The [[cpu_usermode]] routine prepares a stack that will create
the first user mode process when executing [[iret]]. Since [[iret]]
performs a change of privilege level (from ring 0 to ring 3), it will
pop the following:

\begin{itemize}
\item instruction pointer [[EIP]]
\item code segment selector [[CS]]
\item [[EFLAGS]] register
\item stack pointer [[ESP]]
\item stack segment selector [[SS]]
\end{itemize}

The other segment selectors ([[DS]], [[ES]], [[FS]], and [[GS]]) can be
set via [[mov]] instructions.

\red
<<start.asm>>=
; code from http://f.osdev.org/viewtopic.php?t=23890&p=194213 (Jezze)

global cpu_usermode
cpu_usermode:
    cli
    mov ax, 0x23           ; code selector 0x20 + RPL3: 0x03
                           ; RPL = requested protection level
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov eax, esp
    push 0x23              ; code selector 0x20 + RPL3: 0x03
    mov eax, [esp + 12]    ; stack address is 2nd argument
    push eax               ; stack pointer
    ; push 8192              ; set my own stack pointer (8192)
    pushf                  ; EFLAGS
    pop eax                ; reenable interrupts when doing iret
    or eax, 0x200
    push eax
    push 0x1B              ; code selector 0x18 + RPL3: 0x03
    mov eax, [esp + 20]    ; set address (1st argument) for after iret
    push eax
    iret
@

<<kernel declarations>>=
extern void cpu_usermode(uint address, uint stack);  /* assembler */
@

\black

Here's a test: The following program makes a syscall and then
returns.

<<kernel declarations>>=
char testprocess2[] __attribute__ ((aligned (4096))) = {
0xb8, 0xcd, 0xab, 0x00, 0x00, 0xcd, 0x80, 0xeb, 0xfe } ;
// 0xb8, 0xcd, 0xab, 0x00, 0x00, 0x90, 0x90, 0xeb, 0xfe } ;
//                            0x90=nop

// print "A"
char testprocess[] __attribute__ ((aligned (4096))) = {
0xb8, 0x01, 0x10, 0x00, 0x00, 0xbb, 0x41, 0x00, 0x00, 0x00,
0xcd, 0x80, 0xbb, 0x42, 0x00, 0x00, 0x00, 0xcd, 0x80, 

// 0xbb, 0x43, 0x00, 0x00, 0x00, 0xcd, 0x80, 0xbb, 

0xb8,
0x02, 0x10, 0x00, 0x00, 0xcd, 0x80, 0xb8, 0x01, 0x10, 0x00,
0x00, 0xcd, 0x80, 0xeb, 0xfe, 0x00, 0x00, 0x00, 0x00, 0x00 };

extern int printf(const char *format, ...);
extern int debug_printf(const char *format, ...);

void kernelprocess_a() {
  // print "A", syscall scheduler, repeat
  __asm__ ("\
    .intel_syntax noprefix; \
    starta: mov eax, 0x1001; \
    mov ebx, 'A'; \
    int 0x80; \
    mov eax, 0x9001; \
    int 0x80; \
    jmp starta; \
    .att_syntax; \
  ");
};

void kernelprocess_b() {
  // print "B", syscall scheduler, repeat
  __asm__ ("\
    .intel_syntax noprefix; \
    startb: mov eax, 0x1001; \
    mov ebx, 'B'; \
    int 0x80; \
    mov eax, 0x9001; \
    int 0x80; \
    jmp startb; \
    .att_syntax; \
  ");
};


void testprocess_func() {
  // uses syscall 0x5000 to restart shell. doesnt work yet
  // (shell starts, but faults on readline)

  //printf ("PEEK(0xd000.0000): ");
  //printf ("%d \n", PEEK(0xd0000000));
  
  // char st[21];
  // ureadline ((char*)&st, 20);
  //printf ((char*)&st);
  
  // kputch ('a');
  
  __asm__ ("\
    .intel_syntax noprefix; \
    label: ; \
    mov eax, 0x5000; \
    int 0x80; \
    mov eax,0x1002; \
    int 0x80; \
    mov eax,0x1001; \
    int 0x80; \
    mov eax, ebx; \
    int 0x80; \
    mov eax,0x1001; \
    mov ebx,'Z'; \
    int 0x80; \
    jmp label; \
    mov eax, 0x1001; \
    mov ebx, 0x43; \
    int 0x80; \
    mov ebx, 0x42; \
    int 0x80; \
    mov ebx, '\n'; \
    int 0x80; \
    mov eax, 0x5000; \
    int 0x80; \
    ret; \
    .att_syntax \
  ");

};

void switch_to_user_mode() {
   // ???? set_kernel_stack (0);
   // Set up a stack structure for switching to user mode.
   /*
   __asm__ __volatile__ ("  \
     cli; \
     mov   $0x23, %ax; \
     mov   %ax, %ds; \
     mov   %ax, %es; \
     mov   %ax, %fs; \
     mov   %ax, %gs; \
                   \
     mov   %esp, %eax; \
     pushl $0x23; \
     pushl %eax; \
     pushf; \
     pop   %eax; \
     orl   $0x200, %eax; \
     push  %eax; \
     pushl $0x1B; \
     push $1f; \
     iret; \
     1:\
     add   $4, %esp; \
   ");
   */
   
   
   /* code from http://articles.manugarg.com/systemcallinlinux2_6.html */
   /*
   __asm__ __volatile__ (" \
     movl $1f, %edx; \
     movl %esp, %ecx; \
     xorl %ebp,%ebp; \
     sti; \
     sysexit; \
     1: \
   ");
   */
   
   kputs ("TEST DONE\n");
   return;
}
@

([[switch_to_user_mode]] copied from 
\url{http://www.jamesmolloy.co.uk/tutorial_html/10.-User Mode.html},
with two modifications: instead of pushing the address of the end of
this function, we push 0 so that execution continues at 0; syntax
error in [[or]] instruction corrected)

Now, in order to run this code we have to do the following:


<<kernel declarations>>=
void simple_shell();
@

<<kernel declarations>>=
// kernel stack (per process): 1 page = 4 KByte
#define KERNEL_STACK_PAGES 4
#define KERNEL_STACK_SIZE PAGE_SIZE * KERNEL_STACK_PAGES
@

<<kernel functions>>=
void run_first_process () {
  kputs ("Address of testprocess_func: ");
  printhex ((uint)&testprocess_func); kputch ('\n');
  // switch_to_user_mode();

  // reserve kernel stack (old code)
  char *kstack;
  kstack = (char*) request_new_page (0);
    
  tss_entry.esp0 = (uint)kstack+KERNEL_STACK_SIZE;
 
  tss_flush();

  // cpu_usermode ((uint)&testprocess_func);
  // cpu_usermode ((uint)&simple_shell);
  
  printf ("TEST\n");
};
@


\subsection{Creating the First Process}

Here we will create the first (init) process; all further processes
will be created using [[fork]]. This is what we need to do:

\begin{itemize}\itemsep-1pt
\item Setup the TCB (thread control block) list.
\item Mark the first TCB as used.
\item Create a new address space
\item Reserve memory for user mode (low addresses, with user access)
\item Load process binary
\item Reserve memory for the process' kernel stack (low addresses, without
  user access)
\item Enter all the information in the TCB
\item update user mode TSS
\item enter user mode and jump to start of process
\end{itemize}

Step by step:

<<kernel declarations>>=
volatile int current_task;

<<kernel functions>>=
<<create init process>>
@

<<create init process>>=
void init_process () {
  // can use labels and jmp, because jmp is relative, not absolute
  asm {
    // xchg bx,bx
    // mov eax, 0x12345678
    // mov eax, 0x58494c55
    // push eax; push eax; push eax; push eax; push eax; push eax; push eax; push eax
    null:
    call dofork
    call dofork
    call dofork
    call dofork
    // mov ebx, esp
    // mov eax, 0x1003
    // int 0x80
    mov eax, 20
    int 0x80
    mov ebx, 0x500  // store pid in 0x500
    mov [ebx], eax
    loop:
    call doshowpid
    jmp loop
    dofork:
    mov eax,2
    int 0x80
    ret
    doshowpid:
    mov eax, 20
    int 0x80
    mov eax,0x500
    mov ebx,[eax]
    add ebx,'a'-1
    mov eax,0x1001    // 0x1001: syscall for char output
    int 0x80
    ret
  }
};


void init_processy () {
  // can use labels and jmp, because jmp is relative, not absolute
  asm {
    mov eax, 2
    int 0x80
    mov eax, 5
    mov ebx, 0
    int 0x80
    mov eax, 3
    mov ebx, 10
    int 0x80
    loopx:
    jmp loopx
    ret
  }
};

/*
void init_processy () {
  // can use labels and jmp, because jmp is relative, not absolute
  asm (".intel_syntax noprefix; \
    mov eax, 2; \
    int 0x80; \
    mov eax, 5; \
    mov ebx, 0; \
    int 0x80; \
    mov eax, 3; \
    mov ebx, 10; \
    int 0x80; \
    loopx: \
    jmp loopx; \
    ret; \
    .att_syntax");
};
*/
@

Actually creating the [[init]] process is not much work: We start
with defining a thread ID as 1 and then create a new address space
which has 8 KByte of private virtual memory:

<<create init process>>=
void create_init_process() {
  int tid = 1;                                // init process has pid 1
  int as = create_new_address_space(64*1024);    // should be bigger...
@

Remember that [[create_new_address_space]] copies the kernel's page 
directory -- page tables are not copied, the new page directory
uses the same page tables as the original one. Only the user space
area of virtual memory (addresses below \hexaddr{C000.0000}) will be
private to each process.

<<create init process>>=
  int tcbid = register_new_tcb (as);
  thread_table[tcbid].tid = tid;
  // thread_table[tcbid].eip = 0;                // start at 0
  
  // tcbid is number of used TCB
  activate_address_space (as);
  memcpy (0, (void*)&init_process, 200); 
  
  char* kstack = (char*)request_new_page(0);
  uint adr = (uint)kstack;                     // one page for kernel stack
  tss_entry.esp0 = adr+KERNEL_STACK_SIZE;
  tss_entry.esp = 32*1024;
  thread_table[tcbid].kstack = kstack;
  current_task = tid;                         // current_task is global!  
  
  add_to_ready_queue (tcbid);
  ENABLE_SCHEDULER;
  cpu_usermode (0, 32*1024);
};
@


\subsection{Alternative approach: load process from disk}

With some kind of hard disk code available, we will provide a function
that loads a program from the disk and starts it.

<<kernel declarations>>=
int find_free_TCB_entry ();
@

<<kernel functions>>=
int find_free_TCB_entry () {
  int new_tid = 0;   // start with 1
  int i;
  for (i = 1; i < 1024; i++) {
    if (thread_table[i].tid > new_tid)
      new_tid = thread_table[i].tid;
  }
  new_tid++;  // +1

  if (new_tid==1024) {
    printf ("ERROR: no free thread id\n");
    return -1;
  }
  return new_tid;
}
@

<<kernel functions>>=
#define PROGSIZE 32768
int start_program_from_disk (char *progname) {
  // secno: program is located in this sector
  unsigned char buf[PROGSIZE];
  
  // newer code: launch sh from MINIX floppy
  int mfd = mx_open (progname, O_RDONLY);
  mx_read (mfd, (char*)&buf, PROGSIZE);
  mx_close (mfd);
  
  // new code: launch sh from floppy
  /*
  int fd = simplefs_open ("sh");
  simplefs_read (fd, (char*)&buf, PROGSIZE);
  simplefs_close (fd);
  */
  
  // address space
  int as = create_new_address_space(64*1024);
  int tid = register_new_tcb (as);
  thread_table[tid].tid = tid;
  thread_table[tid].ppid = 0;
  thread_table[tid].new = false;  // not freshly created via fork()
  
  thread_table[tid].terminal = 0;  // default terminal: 0

  memcpy (&thread_table[tid].cmdline, "new", CMDLINE_LENGTH);

  // copy program to process memory
  activate_address_space (as);
  memcpy (0, &buf, PROGSIZE);   // process memory starts at 0.

  // kernel stack:

  // OLD VERSION
  /*
  page_table* stackpgtable = (page_table*)request_new_page(0);
    // this must be removed when the process terminates!!!!!!!!!
  memset (stackpgtable, 0, sizeof(page_table));
  KMAPD ( &current_pd->ptds[767], mmu (0, (uint)stackpgtable) );
  uint frameno = request_new_frame ();
  as_map_page_to_frame (current_as, 0xbffff, frameno);
  char* kstack = (char*)0xbffff000;
  uint adr = (uint)kstack;                     // one page for kernel stack
  tss_entry.esp0 = adr+KERNEL_STACK_SIZE;
  tss_entry.esp = 64*1024;
  thread_table[tid].kstack = kstack;
  */
  
  
  // reserve kernel stack (new code, more than 1 page)
  
  uint framenos[KERNEL_STACK_PAGES];   // frame numbers of kernel stack pages
  int i; for (i=0; i<KERNEL_STACK_PAGES; i++)
    framenos[i] = request_new_frame();
  page_table* stackpgtable = (page_table*)request_new_page(0);
  // this must be removed when the process terminates!!!!!!!!!
  memset (stackpgtable, 0, sizeof(page_table));
  KMAPD ( &current_pd->ptds[767], mmu (0, (uint)stackpgtable) );
  for (i=0; i<KERNEL_STACK_PAGES; i++)
    as_map_page_to_frame (current_as, 0xbffff - i, framenos[i]);
  char* kstack = (char*) (0xc0000000-KERNEL_STACK_SIZE);
  uint adr = (uint)kstack;                     // one page for kernel stack
  tss_entry.esp0 = adr+KERNEL_STACK_SIZE;
  tss_entry.esp = 64*1024;
  thread_table[tid].kstack = kstack;  

  
  
  debug_printf ("DEBUG. start_from_disk, kstack   = 0x%x\n", adr);
  debug_printf ("DEBUG. start_from_disk, tss.esp0 = 0x%x\n", tss_entry.esp0);
  
  /** 2012/11/29 **/
  thread_table[tid].esp0 = (uint)kstack + KERNEL_STACK_SIZE;
  thread_table[tid].ebp = (uint)kstack + KERNEL_STACK_SIZE;
  
  
  // set current directory
  memcpy (thread_table[tid].cwd, "/", 2);

  current_task = tid;                         // current_task is global!  
  
  add_to_ready_queue (tid);
  thread_table[tid].state = TSTATE_READY;
  
  // ENABLE_SCHEDULER;
  
  return 0;   // WARNING, WE JUMP TO USERMODE ELSEWHERE
  
  
  if (tid == 1) {
    // first thread; jump to usermode
    cpu_usermode (0, 64*1024);
  }
};
@ 
  

\subsection{fork}

\begin{work}

Things to think of when forking:

\begin{itemize}
\item Copy process' address space
\item Create new process entry in process list
\item After having duplicated the process, there are two
processes which are BOTH just inside the OS' implementation
of fork(). So we need to be prepared that both processes
will (at some time) continue in kernel mode and finish the
execution of fork(). see \url{http://www.jamesmolloy.co.uk/tutorial_html/9.-Multitasking.html} for a fork() implementation
\end{itemize}

\end{work}


Here's a first attempt at forking:

<<kernel declarations>>=
// Thread states
#define TSTATE_READY     1
#define TSTATE_FORK      3
#define TSTATE_EXIT      4
#define TSTATE_WAITFOR   5
#define TSTATE_ZOMBIE    6
#define TSTATE_WAITKEY   7   // wait for key press event
#define TSTATE_WAITFLP   8   // wait for floppy
#define TSTATE_LOCKED    9   // wait for lock
#define TSTATE_STOPPED  10   // stopped by SIGSTOP signal

char* state_names[9] = { "---", "READY", "---", "FORK", "EXIT", "WAIT4", "ZOMBY", "W_KEY", "W_FLP" };

int ulix_fork ();
void print_thread_table();
@


<<kernel functions>>=
void print_thread_table() {
  int i;
  printf ("Thread IDs: ");
  for (i=0; i<1024; i++) {
    if (thread_table[i].used) {
      printf ("%d, ", thread_table[i].tid);
    }
  };
  printf ("\n");
}
@

<<kernel functions>>=
<<fork>>
@

We start our [[fork]] implementation by cloning the current TCB
into a free TCB which we first have to search for:

<<kernel declarations>>=
void inline copy_frame (int out, int in) __attribute__((always_inline));
@

<<kernel global variables>>=
int INSIDE_FORK = false;    // FOR DEBUGGING, REMOVE LATER
@


%void bochs_dump_paging (int as) {
%  bochs_puts ("PAGE DIRECTORY, ADDRESS SPACE = ");
%  bochs_printint (as); bochs_puts ("\n");
%  int j;
%  for (int i = 0; i<1024*1024; i++) {
%    j = mmu_p(as,i);
%    if (j != -1) {
%      bochs_printhex (i); bochs_puts (" -> "); bochs_printhex (j);
%      bochs_puts ("\n");
%    };
%  };
%  return;
%};

We start with a simple helper function that copies page frames:
<<fork>>=
void inline copy_frame (int out, int in) {
  uint outaddr = out << 12;
  uint inaddr  = in  << 12;
  // printf ("DEBUG: phys.frame.copy 0x%05x <- 0x%05x\n", out, in);
  memcpy ((void*)PHYSICAL(outaddr),(void*)PHYSICAL(inaddr),PAGE_SIZE);
};
@

Next comes the definition of [[ulix_fork]]. This function will be called
when the [[fork]] system call is executed.

<<fork>>=
int ulix_fork (struct regs_syscall *r) {
  TCB *t_old; TCB *t_new;
  struct regs rr;
  int i;
  int tid, new_tid;

  asm ("cli");

  INSIDE_FORK = true;
  
  debug_printf ("ULIX fork\n");
  
  int as = current_as;  tid = current_task;  int ppid = tid;
  int new_as = create_new_address_space (0);  // clones kernel part of page dir.
  new_tid = register_new_tcb (new_as);

  t_old = &thread_table[tid];
  t_new = &thread_table[new_tid];
  
  *t_new = *t_old;   // copy the TCB
    // get rid of the copying; some data were already setup in register_new_tcb()
  t_new->state = TSTATE_FORK;
  t_new->tid = new_tid;
  t_new->ppid = tid;    // parent process
  t_new->addr_space = new_as;

  // copy registers to new thread
  rr = *(struct regs*)r;
  rr.ebx = 0;  // for child: return value is 0
  t_new->regs = rr;
  
  asm ("mov %%esp, %0" : "=r"(t_new->esp0));  

  // copy the memory
  address_spaces[new_as].memstart = address_spaces[as].memstart;
  address_spaces[new_as].memend   = address_spaces[as].memend;
    // create_new_address_space() also creates a new page directory

  <<fork: create new kernel stack and copy the old one>>
  <<fork: copy user mode memory>>
  <<fork: compare address spaces>>
  
  // mark new thread as ready and new
  t_new->state = TSTATE_READY;
  t_new->new = true;
  
  debug_printf ("ULIX new_fork, return\n");
  

  uint eip = get_eip();
  
  debug_printf ("AFTER GET_EIP: current_task = %d, ppid = %d\n", current_task, ppid); 
  asm ("mov %%ebp,%0" : "=r"(tmp_ebp)); 
  debug_printf ("EBP = %x\n", tmp_ebp);
  debug_printf ("&ppid = %x\n", &ppid);

  if (current_task == ppid) {
    uint esp; asm volatile("mov %%esp, %0" : "=r"(esp));
    uint ebp; asm volatile("mov %%ebp, %0" : "=r"(ebp));
    thread_table[new_tid].ebp = ebp;
    thread_table[new_tid].eip = eip;
    thread_table[new_tid].esp0 = esp;
    debug_printf ("DEBUG: Writing eip  = %x to thread table\n", eip);
    debug_printf ("DEBUG: Writing esp0 = %x to thread table\n", esp);
    debug_printf ("DEBUG: Writing ebp  = %x to thread table\n", ebp);
    
    add_to_ready_queue (new_tid);

    debug_printf ("fork going to return %d\n", new_tid);
    asm ("sti");
    INSIDE_FORK = false;
    return new_tid;
  } else {
    debug_printf ("fork going to return 0 \n");
    asm ("sti");
    INSIDE_FORK = false;
    return 0;
  }
} 
@

<<fork: create new kernel stack and copy the old one>>=
  // create new kernel stack and copy the old one

  page_table* stackpgtable = (page_table*)request_new_page(0);
  // this must be removed when the process terminates!!!!!!!!!
  memset (stackpgtable, 0, sizeof(page_table));
  page_directory *tmp_pd;
  tmp_pd = address_spaces[new_as].pd;
  KMAPD ( &tmp_pd->ptds[767], mmu (0, (uint)stackpgtable) );
  
  uint framenos[KERNEL_STACK_PAGES];   // frame numbers of kernel stack pages
  for (i=0; i<KERNEL_STACK_PAGES; i++)
    framenos[i] = request_new_frame();
    
  // debug_printf ("fork: new kernel stack at frame %x\n", frameno);

  // as_map_page_to_frame (new_as, 0xbffff, frameno);

  for (i=0; i<KERNEL_STACK_PAGES; i++)
    as_map_page_to_frame (new_as, 0xbffff - i, framenos[i]);

  // char* kstack = (char*)0xbffff000;
  char* kstack = (char*) (0xc0000000-KERNEL_STACK_SIZE);

  thread_table[tid].kstack = kstack;
  
  t_new->kstack = t_old->kstack;
  
  debug_printf ("ulix_fork: memcpy(%x,%x,%x)\n",
           (void*)PHYSICAL(mmu(new_as, 0xbffff000)),
           (void*)PHYSICAL(mmu(as, 0xbffff000)),
           KERNEL_STACK_SIZE );
  // assert ( mmu(as, 0xbffff000) != -1 );
  if ( mmu(as, 0xbffff000) == -1 ) {
    printf ("MMU ERROR. as=%d\n", as);
  };
  
  // copy each page separately: they need not be physically connected or in order
  for (i=0; i<KERNEL_STACK_PAGES; i++)
    memcpy ( (void*)PHYSICAL(mmu(new_as, 0xc0000000-KERNEL_STACK_SIZE + i*PAGE_SIZE)),
             (void*)PHYSICAL(mmu(as,     0xc0000000-KERNEL_STACK_SIZE + i*PAGE_SIZE)),
             PAGE_SIZE );
  debug_printf ("ulix_fork: memcpy done\n");
@

<<kernel declarations>>=
extern uint get_eip();
@

<<fork: copy user mode memory>>=
  // clone first 3 GB (minus last directory entry) of address space
  page_directory *pd;  page_directory *new_pd;
  page_table *pt;      page_table *new_pt;
  pd     = address_spaces[as].pd;
  new_pd = address_spaces[new_as].pd;
  int j, frameid;
  for (i = 0; i<767; i++) {     // only 0..766, not 0..767
    if (pd->ptds[i].present) {
      // copy page table descriptor
      memcpy (&(new_pd->ptds[i]), &(pd->ptds[i]), sizeof(page_table_desc));
      frameid = request_new_frame();  // reserve new frame
      new_pd->ptds[i].frame_addr = frameid;
      // walk through the entries of the page table
      pt = (page_table*)PHYSICAL(pd->ptds[i].frame_addr << 12);
      new_pt = (page_table*)PHYSICAL(frameid << 12);
      memset (new_pt,0,4);  // clear descriptor
      for (j=0; j<1024; j++) {
        if (pt->pds[j].present) {
          // copy physical frames
          frameid = request_new_frame();

          debug_printf ("ulix_fork: memcpy begin, frameid=%d, pt->pds[j].frame_addr=%d, (i,j)=(%d,%d)\n",
            frameid, pt->pds[j].frame_addr, i, j);
          copy_frame (frameid, pt->pds[j].frame_addr);
          debug_printf ("ulix_fork: memcpy done\n");
          
          new_pt->pds[j].frame_addr = frameid;
          new_pt->pds[j].present = true;
          new_pt->pds[j].writeable = true;
          new_pt->pds[j].user_accessible = true;
        };
      };
    };
  };
@
  

For debugging:

<<fork: compare address spaces>>=
int reg_esp0;
__asm__ __volatile__("mov %%esp, %0": "=r"(reg_esp0));
// printf ("Reg. ESP0: 0x%08x\n", reg_esp0);

uint testa1, testa2;
unsigned char c1, c2;
// printf ("DEBUG: compare as -- Ungleiche Inhalte in: \n");

int count = 0;
for (i = 0; i<8192; i++) {
  // if (count>10) break;
  testa1 = mmu(as, i);
  testa2 = mmu(new_as, i);
  c1 = PEEKPH (testa1);
  c2 = PEEKPH (testa2);
  if (c1 != c2) {
    printf ("<compare address space>: 0x%08x: 0x%08x = %02x, 0x%08x = %02x \n", 
      i, testa1, c1, testa2, c2);
    count++;
  };
};
// printf ("count = %d\n",count);
@

% --------------------------------------------------------------------------


\subsection{exec: the ELF loader}

In this section we look at \UlixI{}'s [[exec]] function which is able to
load ELF binaries (Executable and Linking Format) from disk.\footnote{This
section uses a lot of code from Frank Kohlmann who developed the initial
implementation of the ELF loader as part of his Bachelor's thesis 
\cite{Kohlmann:2013:Bachelor} which was supervised by Hans-Georg E\ss{}er.} Bla.





% ----------------------------------------------------------------------
\green
\chapter{Synchronization}
\label{chap:synchronization}
\label{chap:ulix:sync}%

\section{Motivation}

In previous chapters, we had a look at the basic abstractions
implemented by the operating system: virtual memory abstracting
physical memory and virtual processors (threads) abstracting physical
processors. Virtual processors may now execute concurrent programs
in which the concurrent threads often have to interact in some
specific way. There are two basic \vindex{interaction patterns}:
%
\begin{itemize}

\item A \emph{\vindex{competitive interaction pattern}} occurs when
  two threads want to perform the same operation, however only one of
  them is permitted to do so at the same time. This means that one
  thread must go first and the other must wait until the first has
  finished his operation. Classic examples of this interaction pattern
  are accesses to exclusive resources or critical code sections which
  were already mentioned above in
  Section~\ref{sec:dispatcher:funtcions:as:critical:sections}. In this
  interaction pattern, the competing threads often don't know of each
  other, i.e., some mediator (i.e., the operating system) has to
  synchronize the threads in a convenient and fair manner.

\item A \emph{\vindex{cooperative interaction model}} occurs when two
  threads know each other and want to exchange information in a
  well-defined way. This interaction pattern occurs for example in
  client/server-type systems where one thread requests information
  which another thread provides.  

\end{itemize}
%
The question for \Ulix{} is: Which thread synchronization abstractions
make sense and how can they be implemented? 

Depending on the basic implementation mechanisms, we distinguish
between memory-based synchronization abstractions and message-based
synchronization abstractions. The most relevant ones for us are the
former ones which are based on the availability of shared memory
between threads. They can therefore be utilized in those operating
systems using service combinations which primarily depend on the
availability of shared memory (see
Section~\ref{sec:combining:necessary:services}). 

As we will see later, message-based synchronization can be simulated
on top of memory-based synchronization and vice versa. So from an
algorithmical standpoint using one or the other doesn't
matter. However, memory-based synchronzation is usually much more
basic and efficient, which additionally justifies the focus we put on
this synchronization type in this chapter.

\subsection{Outline}

We first present the central abstraction of competitive thread
synchronization in Section~\ref{sec:critical:sections}. Then we go
through different ways of implementing critical sections. The first
way is nothing more than an intellectual exercise:
Section~\ref{sec:synchronization:based:on:atomic:assignments} looks at
how synchronization ca be achieved using ``high level'' assignments
(of values to variables). Since assignments are not atomic on most
modern hardware, we turn to more low-level and more practical
synchronization techniques based on special hardware operations in
Section~\ref{sec:hardware:based:synchronization}. 

We then climb again up the abstraction ladder and look at two
higher-level concepts. The first one are \emph{semaphores}. They can
be regarded as an operating system service which is more useable than
low-level hardware. They are treated in
Section~\ref{sec:semaphores}. The second one are \emph{monitors},
discussed in Section~\ref{sec:monitors}. Monitors are the first
\emph{language-based} synchronization concept because the concept
contains programming language concepts which allow a rather high-level
formulation of critical sections and synchronization.

We will discuss the implementation of these concepts in \Ulix{} as we
go along. We present a standard implementation of semaphores based on
atomic hardware operations. Since \Ulix{} by default does not offer a
programming environment, monitors are not offered in \Ulix{}. However,
we sketch an implementation based on semaphors which can be extended
to a programming environment within student exercises in the future.


\section{Critical Sections}
\label{sec:critical:sections}

\subsection{The Case of the Lost List Element}

Consider an implementation of a linked list. This \emph{could} for
example be the implementation of the \vindex{ready queue} within the
dispatcher (for the real implementation see
Section~\ref{sec:implementing:lists:of:threads}). Imagine a list
element consists of the real content of the element together with a
pointer to the next list element. Adding an item to the front of the
queue is usually implemented like this:

<<code example: adding an item to a linked list>>=
void put(list ready, element e) {
  e.next = ready; // operation 1
  ready = e; // operation 2
}

@ The actions performed by the [[put]] operation are illustrated in
Figure~\ref{fig:linked:list}. First, the next pointer of the new element
is set to the ``old'' front of the list. Second, the global list pointer
is set to the ``new'' front of the list. If you follow the final pointer
structure you will see that the new list element has been correctly
inserted to the front of the list.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/linked-list.jpg}
  \caption{Example of adding an element into a linked list.}
  \label{fig:linked:list}
\end{figure}

The claim now is that the list implementation from above can cause
problems if multiple threads try to put different elements into the
list at the same time.  To see this, consider
Figure~\ref{fig:linked:list:problems}. There, two threads $A$ and $B$
invoke the implementation of [[put]] from above at almost the same
time. The scheduling of the two threads is somewhat unfortunate in
that $A$ is interrupted after the first operation, then $B$ adds its
element, and then thread $A$ can finalize its insertion by executing
the second operation. In total there are four pointer assignments,
which are reflected in the figure. If you follow the final pointer
structure of the ready queue, you will see that one element (namely
that of thread $B$) has been lost: It is not contained in the list
anymore.

The reason for this is the unfortunate scheduling of the machine
instructions. Operation 2 of thread $A$ overwrites the effect of the
two operations of thread $B$, because it implicitly assumes that 
nothing has happened after it executed its own operation 1. These
problems would have been avoided if there were a guarantee that
whenever some thread executes operation 1 it can also execute
operation 2 without being interrupted.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/linked-list-problems.jpg}
  \caption{Concurrent threads trying to add two elements to a linked
    list: The list can loose elements when operations are interleaved
    in a special way.}
  \label{fig:linked:list:problems}
\end{figure}

\subsection{Defining Critical Sections}

A \emph{\vindex{critical section}} is a sequence of instructions of a
program which access shared resources. In the example above, the
linked list is the shared resource. Manipulation of shared resources
should be protected by an \emph{entry}\pindex{entry protocol} and
\emph{\vindex{exit protocol}}. These should guarantee \vindex{mutual
  exclusion} between critical sections. This is defined as follows:

\begin{description}
\item[Mutual exclusion:] At any time there is at most one thread
  executing within its critical section.
\end{description}

Note that critical sections are something very abstract. They have a
meaning at almost any level of abstraction, be it operating system,
user program or programming language level. When dealing with
critical sections it is merely necessary to mark the begin and
end of the critical sections. The runtime system must then guarantee
that no two critical sections at the same level of abstraction are
executed concurrently.

In the \Ulix{} kernel, we mark begin and end of critical sections with
the two macros [[ENTER_MUTEX]] and [[EXIT_MUTEX]]. This is an
abbreviation for entering and exiting mutual exclusion. These two
macros will later implement the entry and exit protocol for the given
environment. So if we write our list operation from above again, we
should mark the critical section in the following way:

<<code example: adding an item to a linked list within a critical section>>=
void put(list ready, element e) {
  ENTER_MUTEX
  e.next = ready; // operation 1
  ready = e; // operation 2
  EXIT_MUTEX
}

@ We will learn about many ways to implement critical sections in this
chapter. For the time being, imagine a global token which must be
acquired before a thread can enter its critical section. 

\begin{work}
  Explain Figure~\ref{fig:mutual:exclusion:preliminary:example} (from
  Ch 6, slide 8)
\end{work}

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/mutual-exclusion-preliminary-example.jpg}
  \caption{Simple example of mutual exclusion between two
    threads. Using a global token, one thread has to wait until the
    other thread returns the token to enter its critical section.}
\label{fig:mutual:exclusion:preliminary:example}
\end{figure}


\section{Synchronization Based on Atomic Assignments}
\label{sec:synchronization:based:on:atomic:assignments}

\begin{work}
  Ch 6, slides 11--17
\end{work}


\section{Hardware-based Synchronization}
\label{sec:hardware:based:synchronization}

As we have seen, synchronization based on atomic assignments is pretty
cumbersome and a rather unnatural way to achieve, for example, mutual
exclusion. In a certain sense it is also impractical because
assignments in high-level programming languages like C most often have
to be compiled into a sequence of CPU instructions and therefore are
not atomic. A simple assignment of [[a = b;]] for example usually
involves loading the value of variable [[b]] from main memory into a
CPU register and then storing it into the memory location representing
variable [[a]]. The inherent reason for this non-atomicity is that the
hardware usually doesn't support atomic move operations from one
memory location to another. All this indicates that hardware support
is vital for efficient and effective synchronization. 

In this section we will consider synchronzation based on explicit
hardware support. We will look at the simplest thinkable mechanism
first and then at more refined ways based on special CPU operations.

\subsection{Disabling Interrupts}
\label{sec:disabling:interrupts}

The simplest way to achieve mutual exclusion on a single CPU is to
switch off the interrupts\pindex{switch off
  interrupts}\pindex{interrupts, disable}\pindex{diable interrupts},
which is also often called \emph{\vindex{interrupt
    masking}}.\pindex{masking of interrupts} Every modern
multi-purpose CPU which has an interrupt mechanism allows to disable
certain or all interrupts. The effect is that the interrupt handler is
not invoked when the interrupt is signalled. Hence, asynchronous
interrupts, which are usually the source for non-atomicity in critical
sections, can be effectively eliminated.

The \Ulix{} hardware also offers a mechanism to mask interrupts (see
Section~\ref{sec:interrupt:masking}). Conceptually, every CPU should
offer such instructions like [[INTERRUPTS_OFF]] and [[INTERRUPTS_ON]].
We encapsulate these within two named chunks.

<<disable interrupts>>=
INTERRUPTS_OFF;
@

<<enable interrupts>>=
INTERRUPTS_ON;

@ Whenever a kernel programmer needs to ensure mutual exclusion of
a critical section in system mode, he will now have to write
the following.

<<example: mutual exclusion using interrupt masking>>=
<<disable interrupts>>
// critical section
<<enable interrupts>>

@ Note that masking interrupts can only be performed in system
mode. (If normal programs could invoke the interrupt masking
operations in user mode then they could monopolize the CPU.) Also,
interrupts should only be disabled for relatively short periods of
time. Otherwise, interrupts which are only flagged a certain period of
time like asynchronous I/O interrupts could be missed. So overall,
disabling interrupts is only advisable for rather short code sections
within the kernel.  Another disadvantage of this mechanism is that it
only works for monoprocessor systems since turning off interrupts on
one CPU does not affect the program executed on another CPU.

Using a trick it is possible to improve the situation slightly: Using
a global bit [[busy]] as a lock it is possible to extend the duration
within a critical section without loosing interrupts. The idea is to
use the global lock bit as an indication whether some process is
within the critical section and just use interrupt masking to access
this bit. The entry and exit protocols [[ENTER_MUTEX]] and
[[EXIT_MUTEX]] for critical sections can then be programmed as
follows.

<<example: mutual exclusion using global lock bit and interrupt masking>>=
global boolean busy = false; // critical section is free

ENTER_MUTEX() {
  <<disable interrupts>>
  while (busy == true) { // critical section is locked
    <<enable interrupts>>
    NOP;   // turn on interrupts for a short period of time
    <<disable interrupts>>
  }
  busy = true; // lock critical section
  <<enable interrupts>>
}

EXIT_MUTEX() {
  busy = false; // make critical section free
}

@ Two processes wishing to enter their critical sections will
``race'' for the lock bit during the entry protocol. The process
which is able to switch off interrupts first will be able to
grab the lock bit (in case it is free). In case the lock bit
is not free, some other process is in its critical section.
So we have to turn on the interrupts at least for a short period
of time to allow that process to interrupt and exit the critical
section.


\subsection{Using Special Hardware Instructions}
\label{sec:using:special:hardware:instructions}

Most processors today offer machine instructions which are specially
tailored towards synchronization so that it can be achieved without
having to mess around with the interrupts. The most common such
instructions are either called \emph{\vindex{test-and-set}} or
\emph{lock}\pindex{lock (hardware instruction)}. They are designed in
such a way so that mutual exclusion can be achieved by ``grabbing a
token'' in a similar way as the global lock bit was used in
Section~\ref{sec:disabling:interrupts}.


\subsubsection{Test-and-Set}

Assume you have a global lock bit [[busy]] which is initially
[[false]]. The test-and-set instruction takes two arguments: the first
is the name (or address) of the global lock bit, the second a local
variable (usually a register). Invoking 
%
\begin{center}
  [[Test-and-Set(busy, local)]]  
\end{center}
%
then results in the following two actions performed as one atomic
(i.e., uninterrupted) operation:
%
\begin{enumerate}
\item The value of [[locked_bit]] is copied into [[local]] (``test''), and
\item the [[locked_bit]] is set to [[true]] (``set'').
\end{enumerate}
%
In pseudocode this can be expressed as:
%
\begin{center}
  [[Test-and-Set(busy, local) { local = busy;  busy = true; }]] 
\end{center}

The idea of this operation is that after it has been performed you can
safely check whether you have ``grabbed the token'' or not. If you
have grabbed the token, then the result of the operation (i.e., the
value stored in [[local]]) should be [[false]] since it reflects the
value of [[busy]] \emph{before} it was set to [[true]].

\subsubsection{Lock Instruction}

Another common machine instruction you can find is called [[Lock]].
Our presentation here follows Nehmer and Sturm \cite{Nehmer:1998:SGM}
who introduce it in the form of a boolean function which implicitly
refers to the global lock bit [[busy]].

In pseudocode, [[Lock]] does the following:
%
\begin{center}
  [[boolean Lock() { tmp = busy; busy = true; return tmp; }]]
\end{center}
%
In effect, [[Lock]] does the same as [[Test-and-Set]] in that it
copies the value of [[busy]] \emph{before} it is set to [[true]] and
then returns this value. Note again that all this is done 
in a uninterruptible way.

\subsubsection{Spin Locks}

Now we can implement [[ENTER_MUTEX]] and [[EXIT_MUTEX]] without having
to use priviliged hardware instructions. We first have a look at
the implementations based on [[Test-and-Set]].

<<example: synchronization using [[Test-and-Set]]>>=
boolean busy = false;

ENTER_MUTEX() {
  repeat {
    Test-and-Set(busy, local);
  } until (local == false);
}
EXIT_MUTEX() {
  busy = false;
}

@ Here is the implementation based on [[Lock]].

<<example: synchronization using [[Test-and-Set]]>>=
ENTER_MUTEX() {
  while (Lock() == true); // loop over empty instruction
}
EXIT_MUTEX() {
  busy = false;
}

@ Note that both implementations do not access priviliged machine
instructions.

The construction using [[Test-and-Set]] and [[Lock]] in the preceding
examples is called a \emph{\vindex{spin lock}}. In such a spin lock,
threads waiting to enter their critical section must ``spin'' in a
loop until they are allowed to enter. A spin lock is a form of
\emph{\vindex{busy waiting}} which is often encountered in low-level
synchronization. Busy waiting however is a very inefficient form of
waiting since CPU cycles are used up without actually contributing to
any form of computation. Imagine how many machine instructions a 3
Gigahertz CPU spinning in a loop could have donated to some
computation. So similar to interrupt masking, spin locks are only
allowed if critical sections are relatively short. The advantage of
spin locks over interrupt masking however is that they can be
performed without going in to kernel mode.


\subsection{Monoprocessor vs.~Multiprocessor Synchronization}
\label{sec:multiprocessor:synchronization}

To achieve mutual exclusion on a monoprocessor system, it is
sufficient to turn interrupts off when entering and turning them on
again when leaving the critical section. As noted above, this
is not sufficient on a multiprocessor system. In a multiprocessor
system we additionally have to use spin locks. The strategy
is as follows:
%
\begin{enumerate}
\item First we achieve \emph{local mutual exclusion per CPU} by
  disabling interrupts.
\item Then we go into a spin lock to achieve \emph{global mutual
    exclusion over all CPUs}.
\end{enumerate}

\begin{work}
  motivate why both is necessary. See ex. 8

  reference methods for fine tuning spin locks \cite{Herlihy:2008:AMP}.
\end{work}

It is generally advisable to avoid busy waiting whenever possible. At
the lowest level of abstraction (e.g., synchronizing CPUs on the
hardware level) busy waiting cannot be totally avoided. However, on
higher levels of abstraction it generally can using more abstract
synchronization primitives like semaphores.


\section{Semaphores}
\label{sec:semaphores}


As seen above in
Section~\ref{sec:using:special:hardware:instructions}, the simplest
way of implementing blocking is \emph{\vindex{busy waiting}}. However,
busy waiting is a rather inefficient way to implement blocking as it
consumes CPU cycles that could have been used for threads that are
ready to run. Busy waiting can be avoided by offering the right
synchronization abstractions within the operating system. The
operations [[ENTER_MUTEX]] and [[EXIT_MUTEX]] can, for example, then
directly influence the state of threads. This is depicted in
Figure~\ref{fig:avoiding:busy:waiting} where three threads are
scheduled in two CPUs. In the example, thread $T_1$ enters its
critical section while running on $\id{CPU}_1$ and thread $T_2$
running on $\id{CPU}_2$ calls [[ENTER_MUTEX]]. Because $T_1$ is
already in its critical section, $T_2$ must block. Instead of waiting
actively in a loop, it could go to sleep (change its state to
[[blocked]]) and allow a different ready-to-run thread $T_3$ to run on
$\id{CPU}_2$.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/avoiding-busy-waiting.jpg}
  \caption{Avoiding busy waiting by running a different thread.}
  \label{fig:avoiding:busy:waiting}
\end{figure}

The most popular abstraction for synchronization in operating systems
is the \emph{\vindex{semaphore}}. The name semaphore stems from a
special type of signal used in railway systems. There, a critical
section is a single track railway line. At any time, at most one train
is allowed to run on such a line and so entering and exiting this part
is governed by special signals.  Note that designing proper semantics
to such signals is not as easy at it seems because the signals at both
ends must be synchronized. For example, it must be ensured that
of two trains concurrently approaching the signals from opposite ends 
only one is allowed to pass. Also, leaving the critical section on
one end must allow another followup train waiting at the opposite end
to enter the track too.

Inspired by real-world semaphores, Edsger W. Dijkstra\pindex{Dijkstra,
  Edsger W.} introduced semaphores as a synchronization abstraction
within his ``THE'' operating system\pindex{THE (operating system)} in
1968 \cite{Dijkstra:1968:SMS}. The name ``THE'' stands for
``Technische Hogeschool Eindhoven'' where Dijkstra was a professor at
that time. Ever since, Dijkstra evolved into one of the most prominent
and fascinating figures in computer science. Not only did he influence
many of today's programming languages through his work on the language
ALGOL, but he also invented a lot of clever algorithms (like the
famous shortest path algorithm for graphs).

\begin{work}
  Add more on Dikstra
\end{work}

\subsection{Semantics of Semaphores}

A semaphore is an operating system abstraction offering two primitive
operations called $P$ and $V$. The operation $P$ (which can be read as
``pass'') is invoked by a thread when it wishes to enter its critical
section. Conversely, the operation $V$ (which can be read as ``leaVe'')
is invoked when a process leaves its critical section. 

A semaphore guarantees \emph{$k$-mutual exclusion}\pcindex{k-mutual
  exclusion}{$k$-mutual exclusion}. The formal statement of this
concept can be defined as follows.

\begin{definition}[$k$-mutual exclusion]
  % 
  If all threads properly encapsulate their critical section with $P$
  and $V$, then the semaphore guarantees that at most $k$ threads are
  in their critical sections at the same time.
  % 
\end{definition}

The concept of $k$-mutual exclusion is a generalization of simple
mutual exclusion for which $k=1$. The actual value of $k$ must be
passed to the semaphore upon initialization.

It is possible to break down $k$-mutual exclusion to specific
semantics of the individual semaphor operations $P$ and $V$ as
follows.

\begin{definition}[semantics of $P$ and $V$]
  %
  Assume semaphore $S$ is initialized with $k$. Then the operations
  $P$ and $V$ on $S$ (written $P(S)$ and $V(S)$) have the following
  meaning:
  % 
  \begin{itemize}

  \item $P(S)$ blocks in case exactly $k$ threads have passed $P(S)$
    without passing $V(S)$.

  \item $V(S)$ deblocks a thread which is blocked at a $P(S)$ in case
    such a thread exists.

  \end{itemize}
  % 
\end{definition}

For $k=1$, the operations $P$ and $V$ therefore clearly resemble the
semantics of a form single necessary to protect a single track railway
line. More generally, they resemble the semantics for protection
signals of a $k$-track railway line segment.

\subsection{Single Mutual Exclusion}

The notion of $k$-mutual exclusion for $k=1$ is often simply called
\emph{\vindex{mutual exclusion}} or \emph{\vindex{mutex}} for short.
The name ``mutex'' is often also used for the semaphor protecting a
simple critical section where at most one thread is allowed to enter.
Such a critcal section can be implemented easily with semaphores as
follows.

<<example: classical mutual exclusion with semaphores>>=
Semaphore Mutex = 1; // initialization

// code of the thread
P(Mutex); // enter critical section
// critical section
V(Mutex); // leave critical section
// continued code of the thread

@ Incidentally, this is exactly what we would need if we want to
implement [[ENTER_MUTEX]] and [[EXIT_MUTEX]] without busy waiting
at the operating system level. The question of course is: Can we
implement semaphores without busy waiting? 


\subsection{Initialization of Semaphores}

We now look at a simple implementation of semaphores at the operating
system level. These semaphore are consequently called
\emph{\vindex{kernel level semaphores}}. Semaphores at that level
basically encapsulate a counter and a list of threads. This list can
be thought of as being at the same level as the \vindex{ready queue}
in the \vindex{dispatcher}. In fact, it implements one type of
\vindex{blocked queue} in the system (see
Section~\ref{sec:thread:queues}).

We first declare the semaphore type, a structure consisting of a
counter and a queue. All declarations and functions on this type of
semaphore are prefixed with [[kl_]] to identify them as kernel level
semaphores and clearly separate them from \vindex{user level semaphores}
discussed later. We allow for additional ``implementation'' fields 
at the end of the semaphore structure which are not of interest for
the general idea of semaphores.

<<kernel declarations>>=
struct kl_semaphore {
  int counter;
  blocked_queue bq;
  <<more [[kl_semaphore]] entries>>  // uninteresting implementation details
};

@ The structure [[kl_semaphore]] is the internal representation of
semaphores. In later code we will refer to semaphores by a unique
identifier instead of a pointer to such a structure. Basically, this
identifier will be a pointer into a global semaphore table implemented
later.

<<kernel declarations>>=
typedef int kl_semaphore_id;

@ The function [[new_kl_semaphore(k)]] returns the identifier of a new
semaphore initialized with [[k]]. The return value -1 is used as an
\vindex{error code} meaning that something went wrong during
allocation. This usually means that the internal table is full,
usually a bad sign. 

We also provide a function to release a semaphore. Releasing a 
semaphore implies that all threads which may be blocked on that
semaphore are deblocked.

Here are the forward declarations. We'll implement the function later.

<<kernel declarations>>=
kl_semaphore_id new_kl_semaphore(int k);
void release_kl_semaphore(kl_semaphore_id s);
@

\subsection{Implementing $P$ and $V$}

The idea of the implementation of $P$ and $V$ is as follows. The
counter of the semaphore represents the remaining ``potential'' of the
semaphore, i.e., the number of threads which are still allowed to pass
without being blocked. To actually block and deblock threads, we can
simply used the operations provided by the kernel level dispatcher
(see Section~\ref{sec:simple:state:model} for the general description
and Section~\ref{sec:kernel:level:dispatcher:ulix} for the
implementation).

The idea of the operation $P$ is to check the remaining potential of
the semaphore and block in case the potential is used up. To
understand the condition under which a thread is blocked
([[sem.counter < 0]]), remember that a semaphore initialized with 1
allows one thread to pass. Since the counter is decremented before the
check, a condition [[counter < 1]] would not be correct.

<<kernel functions>>=
void kl_P(kl_semaphore_id sid) {
  struct kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  sem.counter = sem.counter - 1;
  if (sem.counter < 0) {
    block(0, &sem.bq);
    assign(0);
  }
}

@ The operation $V$ is slightly simpler than $P$ because there is
no danger of a context switch. The function just checks whether
a thread is still blocked on the semaphore queue and deblocks
this thread in case there is.

<<kernel functions>>=
void kl_V(kl_semaphore_id sid) {
  struct kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  if (sem.counter < 0) {
    // ERROR IN NEXT LINE. WHAT'S HAPPENING HERE?
    // ->  bq -> sem.bq ?
    //! deblock(front_of_blocked_queue(bq), &bq);
  }
  sem.counter = sem.counter + 1;
}

@ The above implementation of semaphores is probably the simplest
one but still leaves some room for variation. For example, the
implementation of the semaphore queue can be performed in different
ways. The simplest way is probably to use a simple FIFO queue,
but priority queues can be used too. The FIFO processing order
is probably the one which is implicitly assumed most often
when using semaphore, because it guarantees that the thread
which has waited longest is deblocked first.




\codesection{Semaphores in \Ulix{}}

The main effort to implement kernel level semaphores has been already
done in previous sections. Here we fill in the final gaps. 

Allthough semaphores (like threads and virtual address spaces) can be
allocated and freed, we have to implement them without dynamic memory.
Therefore semaphores are held in a large \vindex{semaphore table} called
[[kl_semaphore_table]]. It is an array of [[kl_semaphore]]
structures. 

<<kernel declarations>>=
#define MAX_SEMAPHORES 32
struct kl_semaphore kl_semaphore_table[MAX_SEMAPHORES];

@ There's a \vindex{maximum number of semaphores} that can
be allocated in the kernel.

Since both used and unused semaphores are held in a table, we need
additional information to distinguish both. So each 
semaphore has a counter and a queue, but it also has
an additional field storing the semaphore state. The value
[[false]] means the semaphore entry is free.

<<more [[kl_semaphore]] entries>>=
boolean used; 

@ Now it's also clear how we can initialize the fields.

<<initialize kernel global variables>>=
for (int i=0; i < MAX_SEMAPHORES; i++) {
  kl_semaphore_table[i].counter = 0;
  initialize_blocked_queue(&kl_semaphore_table[i].bq);
  kl_semaphore_table[i].used = false;
}

@ Since we didn't mention the semaphore table earlier, we need
to fill in the mapping between the semaphore identifier  [[sid]]
and the semaphore structure in the table.

<<semaphore structure with identifier [[sid]]>>=
kl_semaphore_table[sid]

@ Finally, we have to implement the two functions [[new_kl_semaphore]]
and [[release_kl_semaphore]]. Allocation of new semaphores is done
in a round robin fashion (like in the FIFO allocation scheme for
pages). We use a counter [[next_kl_semaphore]] to point to the
next semaphore entry in the table which can be allocated.

<<kernel global variables>>=
kl_semaphore_id next_kl_semaphore = 0;

@ To allocate a new semaphore we check the next table entry and
use it if it is free. While looking for a free entry in the table
we use a check counter to catch the case where the semaphore table
is full.

<<kernel functions>>=
kl_semaphore_id new_kl_semaphore(int k) {
  int check = MAX_SEMAPHORES;
  while (kl_semaphore_table[next_kl_semaphore].used == true) {
    next_kl_semaphore = (next_kl_semaphore + 1) % MAX_SEMAPHORES;
    check = check - 1;
    if (check <= 0) {
      return -1;
    }
  }
  kl_semaphore_table[next_kl_semaphore].used = true;
  kl_semaphore_table[next_kl_semaphore].counter = k;
  initialize_blocked_queue(&kl_semaphore_table[next_kl_semaphore].bq);
  return next_kl_semaphore;
}

@ Releasing a semaphore is a little tricky. Just resetting
the state field in the semaphore table is not enough since threads
may be blocked in the semaphore queue. These threads must be
released to the ready queue.

<<kernel functions>>=
void release_kl_semaphore(kl_semaphore_id s) {
  kl_semaphore_table[s].used = false;
  while (front_of_blocked_queue(kl_semaphore_table[s].bq) != 0) {
    thread_id t = front_of_blocked_queue(kl_semaphore_table[s].bq);
    // ERROR IN NEXT LINE
    //! remove_from_blocked_queue(t, kl_semaphore_table[s].bq]);
    add_to_ready_queue(t);
  }
}
@




\codesection{Synchronization in the Kernel}

The implementation of the $P$ and $V$ operations of semaphores
involves list manipulations at the level of the kernel and therefore
should be treated as a critical section by itself. So should we
declare these functions as critical sections using [[ENTER_MUTEX]] and
[[EXIT_MUTEX]]? This question is more complex than it seems and
so deserves a section of its own.

We have already argued that manipulation of global kernel data
structures like the thread table, the semaphore table and alike must
be performed in mutual exclusion. But what else should be performed
atomically in the kernel? And how should mutual exclusion be achieved?

\subsection{Achieving Mutual Exclusion}

We begin by discussing the question how to achieve mutual
exclusion in the kernel. There are basically two ways:
%
\begin{itemize}
\item Use special hardware instructions (interrupt masking and spin locks).
\item Use kernel level semaphores.
\end{itemize}
% 
It is relatively easy to see that the first approach will work because
it is so low level. Could we also achieve the same results by using
kernel level semaphores?

Imagine an interrupt handler that manipulates a global data structure
like the ready queue and assume that at the beginning of the interrupt
handler code we see a [[kl_P(mutex)]] on a kernel level semaphore
[[mutex]]. There is no additional interrupt masking or spin lock.
What happens if a thread gets into this interrupt handler?

Since we know how semaphores are implemented, we can follow the
code. First the semaphore counter is decremented. If the potential of
the semaphore is used up, the thread is blocked in the semaphore
queue, etc.  If not, the thread continues to run within the interrupt
handler. But wait! Since there is no interrupt masking, an interrupt
can occur between decrementing the semaphore counter and the
counter checking. A different thread can enter the exact same
interrupt handler, also decrement the counter and perform counter
checking. By the time control returns to the original thread,
the semaphore counter can look totally different than it looked
when the thread initially entered the interrupt handler. This
can lead to irregular behavior of semaphores: threads can block
allthough the semaphore was still ``free'' or fail to block when
they actually should. 

So the body of the [[kl_P]] operation should be declared as critical
section. But how should we protect it if we only have kernel level
semaphores? Protecting a kernel level semaphore requires another
kernel level semaphore. This paradoxical situation can only be
relieved by reverting to ``lower level'' (hardware) synchronization
primitives again. So at the lowest level in the kernel, we \emph{must}
use hardware synchronization mechanisms.  However, this discussion also
shows that there can be multiple levels of synchronization in the
kernel.


\subsection{Strict Kernel Synchronization}

We now turn to the question of what parts of the kernel should be
treated as a critical section.  The conceptually easiest and simplest
answer is ``everything''. This implies that a critical section begins
as soon as the system enters the kernel (e.g., through a system
call). Technically this is achieved by adding [[ENTER_MUTEX]] to every
place where the system enters system mode and [[EXIT_MUTEX]] to every
place where it leaves this mode. In general, all interrupt handlers
(synchronous and asynchronous interrupts) have to be wrapped. More
specifically, we need to declare all system calls and all interrupt
handlers as critical sections. This approach is called
\emph{\vindex{strict kernel synchronization}}.

It is relatively easy to see that strict kernel synchronization
achieves mutual exclusion in a way that should work.  User level
programs are by definition interruptible, so we don't care what
happens in user space. When the system enters kernel space we want
this operation to run to completion before any other thread can 
enter the kernel. We do not have to worry about the kernel stack since
it belongs exclusively to the routine which is running in kernel
mode. For multiprocessor systems there is even less risk, since at any
time at most one processor can be in system mode. Others must wait
in a spin lock if they want to enter kernel mode.

Because of its conceptual and code simplicity, \Ulix{} uses strict
kernel synchronization.

\subsection{Concurrent Kernel Synchronization}

Strict kernel synchronization has a lot of disadvantages.  In fact,
almost no real operating system uses strict kernel
synchronization. The main reason is that critical sections should be
as short as possible for better performance and critical sections at
the level of system calls can be very long. If only those parts of the
kernel code are declared as critical sections that explicitly access
global data structures, then multiple threads can be in kernel mode at
the same time increasing concurrency. This idea is called
\emph{\vindex{concurrent kernel synchronization}}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/kernel-synchronization-levels.jpg}
  \caption{Possible levels where kernel synchronization can be
    achieved. Strict kernel synchronization performs mutual exclusion
    at the system call interface; concurrent kernel synchronization
    just performs mutual exclusion on critical sections of kernel
    code.}
  \label{fig:kernel:synchronization:levels}
\end{figure}

The difference between strict and concurrent kernel synchronization is
visualized in
Figure~\ref{fig:kernel:synchronization:levels}. Concurrent kernel
synchronization is just above the manipulation routines for the
critical data structures like the thread queues. So [[ENTER_MUTEX]]
and [[EXIT_MUTEX]] would in these cases occur directly within the
dispatcher functions like [[block]] or [[resign]]. In strict kernel
synchronization, these [[ENTER_MUTEX]] and [[EXIT_MUTEX]] occur at a
much higher level (in fact at the highest level possible).

Concurrent kernel synchronization is much harder to grasp and
understand than strict kernel synchronization. With concurrent
kernel synchronization, multiple threads can be in kernel
mode concurrently. On multiprocessor systems, multiple threads
can in fact \emph{execute} in kernel mode simultaneously.

\begin{work}
  Discuss effects on system stack, give example that improve
  understanding.
\end{work}


\black
\begin{work}
Test-and-Set on Intel 32-bit:

\verb#lock cmpxchg#

\verb#__sync_lock_test_and_set# (gcc internal)
\end{work}


\green


\section{Using Semaphores}

\begin{work}
  Maybe the example from Nehmer and Sturm, described in 
  Ch 6, slides 34--36 in a separate section

  refer to chapter \ref{chap:concurrent:programming} for more.
\end{work}





\black


\codesection{Ulix Locks}

We use the [[gcc]] built-in function 
[[__sync_lock_test_and_set]] to provide locking:

<<kernel declarations>>=
typedef struct {
  short int l;       // the lock
  short int used;    // using this lock?
  blocked_queue bq;  // queue for this lock
} lock_t;
typedef lock_t* lock;

lock_t kernel_locks[100];
@

<<kernel functions>>=
int tsl_test_and_set (lock lockvar) {
  short int res;
  res = __sync_lock_test_and_set (&(lockvar->l), 1);
  return res;
}

void tsl_reset (lock lockvar) {
  __sync_lock_release (&(lockvar->l));
  return;
}

void LOCK (lock lockvar) {
  if (current_task == 0) return;  // no process!
  debug_printf ("ENTER LOCK()\n");
  int count=0;
  while ( tsl_test_and_set (lockvar) != 0 ) {
  
  
  
    debug_printf ("GOING TO CALL add_to_blocked_queue; count=%d\n", count++);
    if (count==0) {
      // put process to sleep
      remove_from_ready_queue (current_task);
      add_to_blocked_queue (current_task, &(lockvar->bq));
      thread_table[current_task].state = TSTATE_LOCKED;
      printf ("DEBUG: add thread %d to bq %x\n", current_task, &(lockvar->bq));
      printf ("DEBUG: bq: ");
      blocked_queue bq = lockvar->bq;
      int tid = bq.next;
      for (;;) {
        printf ("%d ", tid);
        if (tid == 0) 
          break;
        else if (thread_table[tid].next == tid)
          break;
        else
          tid = thread_table[tid].next;
      }
      printf ("\n");
    }

    // calling yield (via syscall 66)
    debug_printf ("LOCK going to call yield()\n");
    asm {
      sti;
      mov eax, 66;
      int 0x80;
    }
  }
  return;
}

void UNLOCK (lock lockvar) {
  if (current_task == 0) return;  // no process!
  debug_printf ("UNLOCK\n");
  tsl_reset (lockvar);
  // wake a process
  blocked_queue bq = lockvar->bq;
  thread_id head = bq.next;
  if (head != 0) {
    remove_from_blocked_queue (head, &bq);
    add_to_ready_queue (head);
    thread_table[head].state = TSTATE_READY;
    printf ("DEBUG: remove thread %d from bq\n", head);
    
    // If one thread is waiting, yield!
    // TODO: THIS DOES NOT HELP, CHECK IT...
    // calling yield (via syscall 66)
    debug_printf ("UNLOCK going to call yield()\n");
    asm {
      sti; 
      mov eax, 66;
      int 0x80;
    }
  }
}

lock get_new_lock () {
  int i;
  LOCK (kernel_locks);  // lock the list of kernel locks, we use kernel_locks[0]
  for (i=1; i<100; i++) {
    if (!kernel_locks[i].used) {
      kernel_locks[i].used = true;
      kernel_locks[i].bq.next = kernel_locks[i].bq.prev = 0;
      UNLOCK (kernel_locks);  // unlock access to the list
      return &kernel_locks[i];
    }
  }
  return NULL;
}
@


\section{Summary}


\begin{work}
  mention Herlihy's book
\end{work}

\black

% ----------------------------------------------------------------------





\chapter{Scheduling}
\label{chap:ulix:scheduling}%

Scheduling is one of the most important tasks of a multi-tasking
operating system. It actually encompasses two separate tasks:

\begin{itemize}
\item deciding when to switch from one task to another and 
\item actually performing the task switch.
\end{itemize}

The first problem is what scheduling strategies are about, and this
is where researchers regularly develop new schedulers. But we will
first focus on the second problem since most operating system books
neglect this---and technically it is not simple.

\codesection{Performing a task switch in \UlixI{}}

Understanding the switch basically means looking at the functions
and stacks. When switching from process $A$ to process $B$, we expect
the following to happen:

\begin{enumerate}
\item Process $A$ is executing, it runs in user mode, using its
user mode stack.
\item A timer interrupt (IRQ 0) occurs. The CPU switches to kernel mode;
this also switches the stack to the kernel stack. (Its address is
in the TSS.)
The CPU stores the current process' EIP and ESP on the kernel stack (???).
It then jumps to the interrupt handler registered for interrupt 0 which
does the following:

{\small\begin{verbatim}
irq0:
    cli
    push byte 0
    push byte 32
    jmp irq_common_stub

irq_common_stub:
    pusha; push ds; push es; push fs; push gs

    mov ax, 0x10; mov ds, ax; mov es, ax; mov fs, ax; mov gs, ax
    mov eax, esp

    push eax
    mov eax, irq_handler
    call eax
    pop eax

    pop gs; pop fs; pop es; pop ds; popa
    add esp, 8
    iret
\end{verbatim} }

So after pushing 0 (an empty error code) and 32 (that is 32+0, where
0 is the IRQ number) onto the stack, it saves all relevant registers
on the stack and then calls [[irq_handler]] which is a C function:

{\small\begin{verbatim}
void irq_handler(struct regs *r) {
  ...
  handler = irq_routines[r->int_no - 32];
  if (handler) { handler(r); }
}
\end{verbatim} }

The generic [[irq_handler]] looks up the correct interrupt service
routine for the timer (it calculates [[r->int_no-32]] which in this
case is $32-32=0$, finds the entry in [[irq_routines]]
(that is [[timer_handler]]) and then calls it.

\item Next, the [[timer_handler]] checks whether it is time to call
the scheduler and (if so) calls it:

{\small\begin{verbatim}
if (system_ticks % 5 == 0) {
  ...
  scheduler (r, SCHED_SRC_TIMER);
  ...
}
\end{verbatim} }

\item So if it decides to call the scheduler, it enters

{\small\begin{verbatim}
void scheduler(struct regs *r) {
  ...
}
\end{verbatim} }

\end{enumerate}


\subsection{Stack Usage}
We need to keep track of which stacks are in use and what contents
are stored on these stacks. Every process has a private user mode stack
and a private kernel mode stack.

\begin{enumerate}

\item When the current process runs (in user mode) and a timer interrupt
occurs, the CPU checks the Task State Segment (TSS) to find the current
top of the stack for kernel mode: it is stored in the [[ESP0]] entry.
(It also retrieves the new value for the [[SS]] register.)
It switches to the new stack (by changing the [[ESP]] and [[SS]] registers)
and pushes the old values of [[SS]] and [[ESP]] as well as the contents 
of [[EFLAGS]], [[CS]], and [[EIP]] onto the new stack. Then it starts
executing the interrupt handler code.

The kernel stack now looks like this:

\begin{verbatim}
SS
ESP
EFLAGS
CS
EIP   <- Stack (t=0)
\end{verbatim}

\item The interrupt handler entry [[irq0]] (for IRQ 0) pushes 0 and 32 onto 
the stack and jumps to [[irq_common_stub]] which pushes
EAX, ECX, EDX, EBX, ESP (t=0), EBP, ESI, EDI, DS, ES, FS, and GS, resulting in

\begin{verbatim}
SS
ESP
EFLAGS
CS
EIP   <- Stack (t=0)
0     (err_code)
32    (int_no)
EAX
ECX
EDX
EBX
ESP (t=0)
EBP
ESI
EDI
DS
ES
FS
GS   <- Stack (t=1)
\end{verbatim}

Then it pushes ESP (t=1) again and calls the C 
function [[irq_handler]] (which pushes the return address and jumps
to the entry address of the C function's code).

\item The [[irq_handler]] function takes a [[struct regs *]] as argument,
and the stack has just been prepared so that it exactly fits this
structure:

\begin{verbatim}
struct regs {
  uint gs, fs, es, ds;
  uint edi, esi, ebp, esp, ebx, edx, ecx, eax;
  uint int_no, err_code;
  uint eip, cs, eflags, useresp, ss;
};
\end{verbatim}

\item [[irq_handler]] calls the C function 



\end{enumerate}






*********


Let's first assume that we do \emph{not} enter the scheduler
(because [[system_ticks %5]] $\neq 0$). In that case we just return
and do not modify anything relevant to scheduling---we expect the
current process to continue running, as it does after other
interrupt treatments.

If we've just entered the [[scheduler]], what does the stack look like
right now? We don't really have to care because all the important
information is available.

Note that at the beginning of the interrupt handling we stored the
contents of all registers on the stack, in just the order which
conveniently fits the [[struct regs]] structure definition. We also
pass the pointer to this structure to all further functions which
get called (when calling [[handler(r)]] and then [[scheduler(r)]]).
So within the [[scheduler]] we can look at [[r]] to see the state
as it was before the timer interrupt occurred. We can also modify
the register values in [[r]], and when we later return from the
scheduler and switch back to user mode, the changes we make will
be written back to the registers (the [[pop]] commands at the end of
[[irq_common_stub]] do this for us).

Coming from user mode vs. coming from kernel mode??
Should not matter, all relevant registers are saved and restored.

When we schedule, we select the new process and then
store all registers (stuff that [r] points to) in the old TCB,
then load the new TCB contents in the registers. Then change
the page tables and return.

QUESTIONS:

-- Do we have to switch the kernel stack? If so, when exactly?

-- What to do about fork and exec? When we create a new process
(directly), it must have proper values in TCB.regs. When we fork
a process, what happens? Does the 0x12345 trick still work?

When we fork, we must somehow tell the two processes apart...

If fork() copies the kernel stack then all (kernel) addresses on 
the new kernel stack are wrong since they point to the old stack.
See \url{http://newlife.googlecode.com/svn-history/r90/kernel/schedule/Scheduler.cpp},
section with \emph{copy kernel stack}.

Can we live with a single kernel stack, see \cite{Warton05singlekernel},
file: Warton-Single-Kernel-Stack.pdf.
See also \cite{Draves:1994:Control-Transfer} (PhD thesis: Control Transfer).

See also \cite{Mukherjee93asurvey} (A Survey of Multiprocessor Operating System Kernels)

See FreeBSD scheduler \cite{Vidstrom:2004:FreeBSD-ia32}.


IDEE: put kernel stack in the TCB, then we need not memorize
the starting address of the stack (e.g. stack = TCB+4096)

TODO: COMPLETE REWRITE OF FORK() AND EXEC().

\subsection{The Implementation}

Here's our simple scheduler:

<<kernel declarations>>=
void scheduler ();
int scheduler_is_active = false;
#define ENABLE_SCHEDULER scheduler_is_active = true
#define DISABLE_SCHEDULER scheduler_is_active = false
@

We add a new entry [[new]] to the thread control block structure
[[TCB]]---it will be set to [[true]] during creation of a new
process via [[fork]]:

<<more TCB entries>>=
boolean new;  // was this process freshly forked?
@

We declare two global variables in the kernel address space which
will later come in handy when we have to remember information about
the current and next process:

<<kernel declarations>>=
TCB *t_old; static TCB *t_new;
@

<<kernel functions>>=
void scheduler (struct regs *r, int source) {
  debug_printf ("*");
  inside_yield = false;   // reset inside_yield value
                          // it may have been set from syscall_yield
  
  <<check for zombies>>     // deal with zombies if we have any
  
  // check if we want to run the scheduler
  if (!scheduler_is_active)  return;
  if (!thread_table[2].used) return;    // are there already two threads?

  int tid = current_task; t_old = &thread_table[tid];
    
  <<find next process and set [[t_new]]>>
  
  if (t_new != t_old) {
    // debug_printf ("Going to context switch from process %d to %d\n", 
    //               t_old->tid, t_new->tid);
    current_task = tid;
    <<context switch>>
  }
  return;
}
@


The search goes like this:

<<find next process and set [[t_new]]>>=
search:
if (source == SCHED_SRC_WAITFOR) {
  // we cannot use the ->next pointer!
  debug_printf ("scheduler called from syscall_waitpid(). tid(old) = %d, ", tid);    
  tid = thread_table[1].next;   // ignore idle process
  debug_printf ("tid(new) = %d\n", tid);
} else {
  tid = t_old->next;
}
if (tid==0)  // end of queue reached
  tid = thread_table[1].next;   // ignore idle process
if (tid==0)  // still 0? run idle task
  tid = 1; // idle
t_new = &thread_table[tid];
if (t_new->addr_space == 0)       goto search;
if (t_new->state != TSTATE_READY) goto search;
@

Here's the code which does the actual context switch. It is only executed if
[[t_new]] $\neq$ [[t_old]]:


<<kernel declarations>>=
int tmp_as;          // temporary address space variable, for context switching
int create_as = -1;  // this as is currently being created; do not modify AS
uint tmp_esp0;       // temporary kernel ESP value, for context switching
uint tmp_ebp;
@

The following code block shows what needs to be done in the context
switch.

We first observe the following facts:

\begin{itemize}

\item We only enter the scheduler (and thus also the context switcher) via
timer interrupts.

\item Once we're running inside the scheduler, we know that the kernel
stack has been set up in a way that will allow the system to continue
operation of the interrupted process---whether it was running in user mode
or kernel mode before the interrupt occurred.

\item When we switch the address space, we also switch the kernel stack.
However, the stack pointer register [[esp]] will still point to the
top of the old process' kernel stack. We need to remedy that and have it
point to the top of the new process' kernel stack.

\item We also need to check whether the process we're switching to is
new (i.\,e., it has just been created by [[fork]])), because in that case
it does not have a proper kernel stack. Our new process has the contents
of the kernel stack as they were when the [[fork]] system call handler
was executed. We will need to modify this stack so that on returning from
the scheduler, the [[fork]] handler can finish its work and return to
the new process' user mode.
\end{itemize}

To make the code more readable, we provide some functions to copy values
between variables and the [[ESP]], [[EBP]], and [[CR3]] registers:

<<kernel declarations>>=
#define DUMP_REGS debug_printf ("REGS: eax=%x, ebx=%x, ecx=%x, eip=%x,\n" \
  "REGS: ebp=%x esp=%x, useresp=%x, cs=%x, &r=%x\n", \
  r->eax, r->ebx, r->ecx, r->eip, r->ebp, r->esp, r->useresp, r->cs, r)
#define COPY_VAR_TO_ESP(x)  asm volatile ("mov %0, %%esp" :         : "r"(x) )
#define COPY_VAR_TO_EBP(x)  asm volatile ("mov %0, %%ebp" :         : "r"(x) )
#define COPY_ESP_TO_VAR(x)  asm volatile ("mov %%esp, %0" : "=r"(x)          )
#define COPY_EBP_TO_VAR(x)  asm volatile ("mov %%ebp, %0" : "=r"(x)          )
#define WRITE_CR3(x)        asm volatile ("mov %0, %%cr3" :         : "r"(x) )
@

<<context switch>>=
// Store current
t_old->regs = *r;         // save registers in thread table
COPY_ESP_TO_VAR (t_old->esp0);  // current esp (kernel)
COPY_EBP_TO_VAR (t_old->ebp);   // current ebp

// activate_address_space t_new->addr_space
uint mem  = mmu(0, (uint)address_spaces[t_new->addr_space].pd);
WRITE_CR3 (mem);
current_as = t_new->addr_space;
current_pd = address_spaces[t_new->addr_space].pd;

// Restore new
COPY_VAR_TO_ESP (t_new->esp0);
COPY_VAR_TO_EBP (t_new->ebp); 
*r = t_new->regs;

if (FROM_KERNEL_MODE) {
  debug_printf ("NOTICE: scheduler was called from kernel mode. Prepare for crash :/ \n");
};

if (t_new->new) {
  <<fix kernel stack for a freshly forked process>>
}
@



This is what needs to be done with the kernel stack of a freshly forked
process:

<<kernel declarations>>=
#define BREAK asm ("xchg %bx,%bx");
@

<<fix kernel stack for a freshly forked process>>=
  debug_printf ("This process is new!\n");
  debug_printf ("current_task = %d\n", current_task);
  thread_table[current_task].new = false;
  asm ("push %0" : : "r"(thread_table[current_task].eip));
  // asm ("cli");
  asm ("ret");
@




Note:

{\it
\begin{itemize}

  \item If the handler procedure is going to be executed at a numerically lower privilege level, a stack switch occurs. When the stack switch occurs:

  \begin{itemize}
    \item[a.] The segment selector and stack pointer for the stack to be used by the handler are obtained from the TSS for the currently executing task. On this new stack, the processor pushes the stack segment selector and stack pointer of the interrupted procedure.

    \item[b.] The processor then saves the current state of the EFLAGS, CS, and EIP registers on the new stack (see Figures 5-4).

    \item[c.] If an exception causes an error code to be saved, it is pushed on the new stack after the EIP value.
  \end{itemize}

  \item If the handler procedure is going to be executed at the same privilege level as the interrupted procedure:

  \begin{itemize}
    \item[a.] The processor saves the current state of the EFLAGS, CS, and EIP registers on the current stack (see Figures 5-4).

    \item[b.] If an exception causes an error code to be saved, it is pushed on the current stack after the EIP value.
  \end{itemize}
\end{itemize}

\raggedleft (Intel® 64 and IA-32 Architectures Software Developer´s Manual\\
\raggedleft Volume 3A: System Programming Guide, Part 1, p. 199)\\

}


See \url{http://www.jamesmolloy.co.uk/tutorial_html/9.-Multitasking.html}


We still need to check for zombies:

<<check for zombies>>=
{
  int pid, ppid;
  for (pid=0; pid < MAX_THREADS; pid++) {
    if (thread_table[pid].state == TSTATE_ZOMBIE) {
      ppid = thread_table[pid].ppid;
      if ( (thread_table[ppid].state == TSTATE_WAITFOR) &&
           (thread_table[ppid].waitfor == pid) ) {
        debug_printf ("exit: remove_from_blocked_queue (%d,%x)\n", ppid, &waitpid_queue);
        remove_from_blocked_queue (ppid, &waitpid_queue);
        add_to_ready_queue (ppid);
        thread_table[ppid].state = TSTATE_READY;   // mark parent as ready
        thread_table[pid].state = TSTATE_EXIT;
        // thread_table[pid].used = false;
      }
    }
  }
}
@








\chapter{Disk I/O and Filesystems}
\label{chap:ulix:fs}%


In this chapter we describe how operating systems store files on
hard disks and floppy disks. The central concept for organizing directories
and files is the filesystem: it is an abstract description of the needed
data structures.

Later, in section \ref{sec:disk-i-o}, we will look at what is needed to actually talk
to a physical drive, but for now let's just assume that there is some
mechanism which is able to read and write ``blocks'': these are small
chunks of disk storage into which we partition a disk---quite similar to
the way that we've split memory into page frames. 

In the following section, we start with an overview of filesystem concepts,
and afterwards (in section \ref{sec:fs-implementation}) we jump into the 
implementation in \UlixI{}.


\section{Introduction to Filesystems}

TO DO

\subsection{FAT vs.{} Inodes}

MS-DOS and DOS-based Windows versions used FAT (File Allocation Table)
as their standard filesystem; FAT-formatted media are still readable on
modern Windows systems (and also on most Unix versions) which is why
many USB sticks still come pre-formatted with FAT.

The idea of a file allocation table is simple: A filename and a list of
data blocks (together with extra data such as access permissions) make up 
a directory entry. If we do not consider sub-directories, a FAT disk
basically contains such a list of filename $\longrightarrow$ block list
mappings, and reading a file means looking up the directory entry and
then reading the (data) blocks whose block numbers stand close to the
file entry.



\section{Filesystem Implementation in \UlixI{}}
\label{sec:fs-implementation}

Filesystems are not a central concept of this book (and thus of the \UlixI{}
implementation). We want a filesystem that is just good enough so that we
can store files, and we want it to be compatible to something that can be
read on a Linux machine, e.\,g. for debugging purposes.

We have decided to implement the original Minix filesystem (version 2),
but with some restrictions:

\begin{itemize}
\item No time stamps: For compatibility reasons, our implementation will
have a field for the (one) timestamp that can be saved for files, but it will
always contain 0, so when mounting it on a Linux machine, all timestamps will
be [[Jan 1 1970 00:00:00 UTC]] which is also called the Unix epoch. 
If somehow a non-zero timestamp exists on a filesystem, it will be ignored.
\item \red What about special files, e.g. device inodes, fifos etc.?\black
\item ...
\end{itemize}


\subsection{Virtual Filesystem}

\UlixI{} shall use a virtual filesystem (VFS). That means that different real
filesystems might be used, and the FVS provides an abstraction so that
generic functions such as [[open]], [[read]], and [[write]] may be used
for accessing these.

Whenever a file is being accessed, we want \UlixI{} to take the following
steps:

\begin{enumerate}
\item Calculate the absolute path of the file. Note that a filename may
already be given as an absolute path (\eg\ \verb#/usr/bin/ps#), but it
may also be given as a relative path (\eg\ \verb#../ps#). In the latter
case we construct the absolute path from the current working directory
and the relative path.
\item Scan the mount table to find out on which filesystem the file is
located. This will return two values: a pointer to the filesystem and
a path which is local to this filesystem. 
In case of \verb#/mnt/tmp/file.txt# this may lead to the number 1 (standing
for filesystem number 1 which is mounted on \verb#/mnt#) and the path
(\verb#tmp/file.txt#) within that filesystem.
\item Depending on the service function which was called (\eg\ \verb#open#),
find a registered function that can talk to this kind of filesystem
(\eg\ \verb#mx_open# for a Minix filesystem or \verb#fat_open# for a 
DOS/FAT filesystem) and call it.
\end{enumerate}

The filesystem-specific functions should assume that they can access
the filesystem as a large, consecutive block of data. \UlixI{} will
provide generic functions [[read_block]] and [[write_block]] which
can be used to access the raw data, be they on a disk partition, a
floppy disk or inside RAM.

We will restrict the number of mounts to 16.

A mount table entry looks like this:

<<mount table>>=
typedef struct {
  char mountpoint[256];
  short fstype;     /* filesystem type, e.g. Minix, RAMfs */
  short device;     /* e.g. DEV_FD0, DEV_RAM0 */
  short mount_flags;
} mount_table_entry;

mount_table_entry mount_table[16];
@

The information in such an entry corresponds roughly to the data
you can observe in \verb#/etc/mtab# on a Linux system:

<<Linux mtab entry>>=
/dev/sda2 / ext3 rw,errors=remount-ro 0 0
@

(This line shows the device filename, the mount point, the
filesystem type, the options, and dump and filesystem check
options which we will not deal with in \UlixI{}.)

A mount table entry is unused if [[fstype]] is 0.


We will provide three concrete implementations of filesystems:

\begin{itemize}
\item a Minix filesystem implementation which describes how to (logically)
read and write Minix-formatted media,
\item a [[/proc]] filesystem similar to Linux which will hold process
and system information,
\item and a [[/dev]] filesystem, also similar to Linux, which provides
information about known devices (such as [[/dev/fd0]] for the first
floppy drive).
\end{itemize}

The architecture will be such that it is possible to add support for other
filesystems, for example FAT (from MS-DOS/Windows). Since \UlixI{} belongs
to the Unix family, we will provide abstract Unix filesystem features
(such as symbolic and hard links, user and group information, classical Unix
access rights, and timestamps) and have to map them to the data which are
available in a concrete filesystem.

The other layer is the hardware: It shall be possible to use all supported
filesystems on any kind of device for which there are [[blockread]] and
[[blockwrite]] functions. Thus, when \UlixI{} tries to [[open]] 
a file and [[read]] from it, the system will start with executing the
virtual [[open]] or [[read]] function, then call (for example) Minix-related
[[mx_open]] or [[mx_read]] functions and finally end in calls to the
hardware-specific [[readblock]] functions. The overall process of executing
[[fd = open("/mnt/tmp/test");]] with the second floppy drive mounted on
[[/mnt/]] is shown in Figure \ref{fig:calling-open}.

\begin{figure}[t]
\begin{centering}
\small
\begin{verbatim}
open ("/mnt/tmp/test"):
  get_dev_and_path ("/mnt/tmp/test", &dev, &fs, &localpath)
  -> dev = DEV_FD1
     fs  = FS_MINIX
     localpath = "/tmp/test"

  open_fun   = filesystems[fs].open    = mx_open
  blockread  = devices[dev].blockread  = fd_blockread
  blockwrite = devices[dev].blockwrite = fd_blockwrite

  mx_open ("/tmp/test", DEV_FD1)

mx_open (...):
  ext_ino = mx_pathname_to_ino ("/tmp/test", DEV_FD1)
  
mx_pathname_to_ino (...):
  loop i:
  mx_read_dir_entry (1, i, DEV_FD1)

mx_read_dir_entry:
  mx_read_inode (1, DEV_FD1) 

mx_read_inode:
  blockno = ... 
  devices[DEV_FD1].blockread (DEV_FD1, blockno, &buf)

fd_blockread:
  fdc_read_sector ()
\end{verbatim}
\end{centering}
\caption{Opening a file}
\label{fig:calling-open}
\end{figure}


On the hardware side, \UlixI{} will provide drivers for floppy disks and
RAM disks. We choose
the floppy disk (instead of a hard disk) because accessing a floppy drive
is easier than talking to a hard disk controller, and \UlixI{} will typically
be used inside a virtual machine.

Combining all features, it will be possible to have Minix filesystems on
floppies and in RAM, with the [[proc]] filesystem being an exception

We'll describe all the VFS code in [[<<VFS declarations>>]] and [[<<VFS code>>]]:

<<kernel declarations>>=
<<VFS declarations>>
@

<<VFS declarations>>=
<<mount table>>
@

<<kernel functions>>=
@



%What information does the VFS implementation need? For each mounted
%filesystem, we will store the following data:
%
% < <VFS declarations> >=
%typedef struct {
%  char mountpoint[40];  // where is it mounted?
%  int  fstype;          // ramfs, /proc or minix?
%  char device[40];      // for physical media: device
%  char options[40];     // mount options, e.g. read-only
%} vfs_entry;
%@



The following definition of the [[stat]] structure is taken from
Tanenbaum \cite{Tanenbaum:1987:OSD}.


<<VFS stat>>=
struct stat {
  short st_dev;             /* device where i-node belongs */
  unsigned short st_ino;    /* i-node number */ 
  unsigned short st_mode;   /* mode word */
  short st_nlink;           /* number of links */
  short st_uid;             /* user id */
  short st_gid;             /* group id */
  short st_rdev;            /* major/minor device for special files */
  long st_size;             /* file size */
  long st_atime;            /* time of last access */
  long st_mtime;            /* time of last modification */
  long st_ctime;            /* time of last change to i-node */
};
@



\subsubsection{Finding the Device and Local Path}

Let's look at a possible szenario: Assume we have two floppy disks ([[fda]], [[fdb]]) and two
RAM disks ([[ram0]], [[ram1]]) mounted like this:

\begin{verbatim}
/dev/fda  on  /             (minix)
/def/fdb  on  /home         (minix)
/dev/ram0 on  /mnt          (minix)
/dev/ram1 on  /home/ramtest (minix)
\end{verbatim}

Since the path \path!/home/ramtest! does not exist before [[fdb]] has been mounted
on \path!/home/!, the second RAM disk must have been mounted \emph{after} the second floppy
disk. Thus, if we assume that we store the mount information in the order in which it
was created by [[mount]], we can search the mount table backwards, starting with the
last entry, and compare each mount point to the leading chraracters of the absolute
path name:

<<find device and local path>>=
int get_dev_and_path (char *path, int *dev, int *fs, char *localpath) {
  int i;
  int mount_entry;
  for (i=last_mount; i>=0; i--) {
    if string_starts_with (mount_table[i].mountpoint, path) {
      mount_entry = i;
      break;
    }
  }
@

Note that this loop cannot fail since the first mount entry always has
the mount point \path!/!, and every syntactically correct absolute path
begins with \path!/!. This only works because we search backwards: if we
were searching forwards, we would always find the root filesystem and
ignore all further mounts.

Once we found the relevant entry we can split off the leading mount point
and also know the device and filesystem type:

<<find device and local path>>=
  split_mountpoint (mount_table[mount_entry].mountpoint, path, localpath);
  *dev = mount_table[mount_entry].device;
  *fs  = mount_table[mount_entry].fstype;
  return 0;
}
@
That is really all there is to do. Every call to this function (with a
syntactically correct absolute path) must be successful, however that does
not mean that the path truly exists: Other functions must check whether
the local part of the path ([[localpath]]) is available on the device---but
we know where to look now.

We need to implement the two helper functions [[string_starts_with]] 
(which is similar to [[strcmp]]) and
[[split_mountpoint]]:

<<global path helper functions>>=
int string_starts_with (char *str, char *start) {
  if (strlen(start) > strlen(str)) return false;   // cannot be a sub-string
  while (*start != '\0') {
    if (*start++ != *str++) return false;  // found different character
  };
  return true;   // parsed all of start; match!
}

char *strcpy(char *dest, const char* src) {
  char *ret = dest;
  while (*dest++ = *src++ != '\0') ;
  return ret;
}

void split_mountpoint (char *mountpoint, char *path, char *localpath) {
  // input:  mountpoint, e.g. /home
             path,       e.g. /home/user/file.txt
  // output: localpath,  e.g. /user/file.txt
  int len = strlen(mountpoint);
  strcpy (localpath, path+len+1);
}
@


\subsection{A Look at the Minix Filesystem}

We will first look at the Minix filesystem by creating one on a Linux
machine and trying to understand some of its properties. For that purpose
we format a floppy image with the Minix filesystem. We create a 1440 KByte
image file with \verb#dd#:

<<create 1.4 MB disk file>>=
$ dd if=/dev/zero of=minixfs.img bs=1k count=1440
1440+0 Datensätze ein
1440+0 Datensätze aus
1474560 Bytes (1,5 MB) kopiert, 0,219079 s, 6,7 MB/s
@

and then format it with \verb#mkfs.minix#:

<<format the disk image with minix fs>>=
$ /sbin/mkfs.minix minixfs.img 
480 inodes
1440 blocks
Firstdatazone=19 (19)
Zonesize=1024
Maxsize=268966912
@

As a next step, \verb#hexdump# will show that there is not much data on
a freshly formatted Minix filesystem:

<<look at the image with hexdump>>=
$ hexdump -C minixfs.img
00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000400  e0 01 a0 05 01 00 01 00  13 00 00 00 00 1c 08 10  |................|
00000410  8f 13 01 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000420  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000800  03 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000810  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000830  00 00 00 00 00 00 00 00  00 00 00 00 fe ff ff ff  |................|
00000840  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00000c00  03 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000c10  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000cb0  00 c0 ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
00000cc0  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00001000  ed 41 e8 03 40 00 00 00  ee 1c 45 4e e8 02 13 00  |.A..@.....EN....|
00001010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00004c00  01 00 2e 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c10  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c20  01 00 2e 2e 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c30  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c40  00 00 2e 62 61 64 62 6c  6f 63 6b 73 00 00 00 00  |...badblocks....|
00004c50  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00168000
@

Finally we ask \verb#fsck.minix# to display as much information as
it can, the \verb#file# commands also recognizes the file type:

<<fsck on a minix filesystem>>=
$ /sbin/fsck.minix -sfv minixfs.img 
Forcing filesystem check on minixfs.img.
480 inodes
1440 blocks
Firstdatazone=19 (19)
Zonesize=1024
Maxsize=268966912
Filesystem state=1
namelen=30


     1 inodes used (0%)
    20 zones used (1%)

     0 regular files
     1 directories
     0 character device files
     0 block device files
     0 links
     0 symbolic links
------
     1 files

$ file minixfs.img 
minixfs.img: Minix filesystem, V1, 30 char names, 40965 zones
@

Now we want to see what happens when we write a file onto that
filesystem. For that purpose we mount the image and then create
a file:

<<write file to disk image>>=
$ sudo mount -o loop minixfs.img /mnt
$ sudo echo "Hello World" > /mnt/hello.txt
$ sudo umount /mnt
$ hexdump -C minixfs.img
00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000400  e0 01 a0 05 01 00 01 00  13 00 00 00 00 1c 08 10  |................|
00000410  8f 13 01 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000420  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000800  07 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000810  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000830  00 00 00 00 00 00 00 00  00 00 00 00 fe ff ff ff  |................|
00000840  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00000c00  07 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000c10  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00000cb0  00 c0 ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
00000cc0  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00001000  ed 41 e8 03 60 00 00 00  36 1f 45 4e e8 02 13 00  |.A..`...6.EN....|
00001010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00001020  a4 81 e8 03 0c 00 00 00  36 1f 45 4e e8 01 14 00  |........6.EN....|
00001030  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00004c00  01 00 2e 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c10  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c20  01 00 2e 2e 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c30  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00004c40  02 00 68 65 6c 6c 6f 2e  74 78 74 00 00 00 00 00  |..hello.txt.....|
00004c50  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00005000  48 65 6c 6c 6f 20 57 6f  72 6c 64 0a 00 00 00 00  |Hello World.....|
00005010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00168000
@

So what happened here?




\subsection{Implementation of the Minix Filesystem}

We begin our description of the Minix filesystem's implementation with
an overview of the data structures used within the filesystem; after
that we look at ways to access files and directories and show how to
develop the code step by step.

For the following we assume that we have a Minix floppy disk image
called \emph{minix1.img} that was created with [[dd]] and [[mkfs.minix]]
using the following commands on a Linux machine:

{\small
\begin{verbatim}
# dd if=/dev/zero of=minix1.img bs=1024 count=1440
1440+0 Datensätze ein
1440+0 Datensätze aus
1474560 Bytes (1,5 MB) kopiert, 0,00353603 s, 417 MB/s
# mkfs.minix -v minix1.img 
480 inodes
1440 Blöcke
Firstdatazone=34 (34)
Zonesize=1024
Maxgröße=2147483647
\end{verbatim}
}

In order to fill the fresh filesystem with some data, we loop-mounted
it on [[/mnt]] and created some files:

\begin{itemize}
\item We copied the file \emph{Testdatei1.txt} (6144 bytes, hex.: 0x1800, exactly six blocks) onto the filesystem. 
\item With [[sed -e 's/ei1.txt/ei2.txt' < Testdatei1.txt > Testdatei2.txt]] we created a slightly modified copy (\emph{Testdatei2.txt}), 
\item then used [[ln]] to create a hard link (\emph{Hardlink.txt}) 
\item and [[ln -s]] to create a symbolic link \emph{Symlink.txt} (of \emph{Textdatei1.txt}).
\end{itemize}

When listing the filesystem's root directory with [[ls]], we get:

{\small
\begin{verbatim}
/mnt# ls -il
insgesamt 19
2 -rw-r--r-- 2 root root 6144 2012-06-04 23:32 Hardlink.txt
4 lrwxrwxrwx 1 root root   14 2012-06-04 23:33 Symlink.txt -> Testdatei1.txt
2 -rw-r--r-- 2 root root 6144 2012-06-04 23:32 Testdatei1.txt
3 -rw-r--r-- 1 root root 6144 2012-06-04 23:32 Testdatei2.txt
/mnt# ls -ild /mnt
1 drwxr-xr-x 2 root root 192 2012-06-04 23:33 /mnt
\end{verbatim}
}

The output shows that the inodes with numbers 1--4 are in use (see first column of the [[ls]] output). If you look at the image with [[hd minix1.img]] ([[hexdump]]), you can detect the root directory's table of contents and the contents of the two files.

The following blocks are in use:

\begin{itemize}
\item The root directory / uses block 34.
\item The file \emph{Testdatei1.txt} uses blocks 35--40.
\item The file \emph{Testdatei2.txt} uses blocks 41--46.
\item The symbolic link \emph{Symlink.txt} uses block 47. (Symbolic links need data blocks as well!)
\item No further blocks are in use, the hard link is just a further entry in the root directory.
\end{itemize}

The inode bitmap has the following contents:

{\footnotesize
\begin{verbatim}
# bindump -r < minix1.img
[...]
00000800  11111000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000808  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000810  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{verbatim}
}

Those five ones represent inode numbers 0--4---however, there is no inode 0. This is what the zone bitmap looks like:

{\footnotesize
\begin{verbatim}
# bindump -r < minix1.img
[...]
00000c00  11111111 11111110 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c08  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c10  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{verbatim}
}

The 15 set bits refer to block numbers 33--47. Block 33 is used by the inodes and is not a data block!

When looking at a freshly created (empty) Minix filesystem (with no files and an empty root directory) the inode and zone bitmaps look like this:

{\footnotesize
\begin{verbatim}
# bindump -r < minix-empty.img
[...]
00000800  11000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000808  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
00000c00  11000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c08  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{verbatim}
}

% ######## HIER WEITER









Dort sind also zwei Inode-Nummern (0, 1) und die Blöcke 33 und 34 als belegt markiert. Inode 0 gibt es nicht, Inode 1 ist das Wurzelverzeichnis. Ein Verzeichnis ist nie leer, denn es enthält immer die Einträge [[.]] und [[..]].

In der letzten Zeile des Hexdumps von minix1.img finden Sie den Text Testdatei1.txt -- hier handelt es sich um den Inhalt des Symlinks: In dessen Datenblock wird der verlinkte Dateiname gespeichert.

minix2.img ist als Kopie des oben beschriebenen Image minix1.img entstanden, es wurden dann noch zwei weitere Dateien (Testdatei3.txt und bindump.c) hinzugefügt und diese schließlich alle mit [[cp -a *.c *.txt subdir/]] in ein mit [[mkdir]] erzeugtes Unterverzeichnis subdir/ kopiert. Sie können mit diesem Image zusätzlich arbeiten, um ein komplexeres Beispiel zu sehen.

{\small
\begin{verbatim}
root@ubu64:/mnt# ls -liRd
1 drwxr-xr-x 3 root root 288 2012-06-05 00:23 .
root@ubu64:/mnt# ls -liR
.:
insgesamt 36
6 -rw-r--r-- 1 root root  1236 2012-06-05 00:23 bindump.c
2 -rw-r--r-- 2 root root  6144 2012-06-05 00:11 Hardlink.txt
7 drwxr-xr-x 2 root root   256 2012-06-05 00:23 subdir
4 lrwxrwxrwx 1 root root    14 2012-06-05 00:12 Symlink.txt -> Testdatei1.txt
2 -rw-r--r-- 2 root root  6144 2012-06-05 00:11 Testdatei1.txt
3 -rw-r--r-- 1 root root  6144 2012-06-05 00:11 Testdatei2.txt
5 -rw-r--r-- 1 root root 13072 2012-06-05 00:23 Testdatei3.txt

./subdir:
insgesamt 35
12 -rw-r--r-- 1 root root  1236 2012-06-05 00:23 bindump.c
 8 -rw-r--r-- 2 root root  6144 2012-06-05 00:11 Hardlink.txt
 9 lrwxrwxrwx 1 root root    14 2012-06-05 00:23 Symlink.txt -> Testdatei1.txt
 8 -rw-r--r-- 2 root root  6144 2012-06-05 00:11 Testdatei1.txt
10 -rw-r--r-- 1 root root  6144 2012-06-05 00:11 Testdatei2.txt
11 -rw-r--r-- 1 root root 13072 2012-06-05 00:23 Testdatei3.txt
\end{verbatim}
}

Die Ausgabe mit [[bindump]] zeigt für die Inode- und Zone-Bitmaps:

{\footnotesize
\begin{verbatim}
# bindump -r < minix2.img
00000800  11111111 11111000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000808  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
00000c00  11111111 11111111 11111111 11111111 11111111 11111111 11111111 11111000  ........
00000c08  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
...
\end{verbatim}
}

Also belegte Inodes: 0--12, belegte Blöcke: 33--93.







\subsection{Our Minix Code}

Es gibt das Minix-Dateisystem in vier verschiedenen Varianten, welche sich u. a. in der maximalen Dateigröße und der maximalen Länge von Dateinamen (14 oder 30) unterscheiden. Sie können für ein Minix-Dateisystem-Image herausfinden, um welche Version es sich handelt. Wir behandeln hier nur die beiden Varianten, bei denen Dateinamen bis zu 30 Zeichen lang sein dürfen. Wenn Sie [[mkfs.minix]] nur den Image-Dateinamen übergeben, wird ein Dateisystem vom ersten Typ (minix1, 30 Zeichen pro Dateiname, ca. 256 MByte theoretische max. Dateigröße) erstellt, über die Option [[-v]] erzeugen Sie ein Dateisystem vom zweiten Typ (minix2, 30 Zeichen pro Dateiname, ca. 2 GByte max. Dateigröße).

Ein Minix-Dateisystem ist in Blöcke der Größe 1 KByte (1024 Byte) unterteilt. Der erste Block ist der Bootsektor (den werden wir ignorieren), der zweite Block ist der sog. Superblock, der alle wichtigen Informationen über das Dateisystem enthält.

<<kernel declarations>>=
<<our minix headers>>
@

<<kernel functions>>=
<<our minix code>>
@

<<our minix headers>>=
#define BLOCK_SIZE 1024
<<stdint headers>>
@

Some integer type definitions from the standard headers:

<<stdint headers>>=
typedef unsigned char         uint8_t;
typedef unsigned short       uint16_t;
typedef unsigned int         uint32_t;
typedef unsigned long long   uint64_t;
@

Der Superblock (also die absoluten Bytes 1024-2047 der Image-Datei) hat folgenden Aufbau:

<<our minix headers>>=
struct minix_superblock { 
  uint16_t s_ninodes;        uint16_t s_nzones; 
  uint16_t s_imap_blocks;    uint16_t s_zmap_blocks; 
  uint16_t s_firstdatazone;  uint16_t s_log_zone_size; 
  uint32_t s_max_size;       uint16_t s_magic; 
  uint16_t s_state;          uint32_t s_zones;
};
@

Die Typen [[uint16_t]] und [[uint32_t]] sind in der Datei /usr/include/stdint.h definiert und 16 Bit bzw. 32 Bit breite vorzeichenlose Integer-Zahlen. Der Superblock verwendet also nur 24 Bytes.

Wenn Sie den Superblock in einen [[struct minix_superblock]] kopieren, können Sie die Werte ausgeben lassen; eine Analyse dieser Werte sollte der erste Schritt sein.
Am Eintrag [[s_magic]] erkennen Sie, um welche Version des Minix-Dateisystems es sich handelt; uns interessieren nur die beiden Fälle

\begin{itemize}
  \item Minix v1 (30 Zeichen pro Dateiname): 5007 = 0x138F
  \item Minix v2 (30 Zeichen pro Dateiname): 9336 = 0x2478
\end{itemize}

(Für die Varianten mit kürzeren Dateinamen gibt es zwei weitere Magic-Nummern.) Ohne diese Information auszuwerten, ist kein Zugriff auf das Dateisystem möglich, weil die beiden Versionen sich in Größe und Inhalt eines Inodes unterscheiden.

Bei einem v1-Dateisystem steht die Anzahl der Blöcke im Eintrag [[s_nzones]], ein v2-Superblock verwendet dafür den Eintrag [[s_zones]]. Der jeweils andere Wert ist 0.

Statt von Blöcken spricht Minix immer von Zones, dabei ist i. d. R. eine Zone genau ein Block; theoretisch könnte aber eine Zone auch aus mehreren Blöcken bestehen: Es gilt

\[
\text{Zonengröße} = \text{Blockgröße} \times 2^{\text{[[s_log_zone_size]]}}
\]

(und der Wert [[s_log_zone_size]] ist normal 0). Für diese Aufgabe können Sie ungeprüft davon ausgehen, dass immer Zonengröße = Blockgröße = 1024 gilt.

[[s_imap_blocks]] und [[s_zmap_blocks]] geben an, wie viele Blöcke von der Inode-Bitmap und der Zone-Bitmap belegt sind: In diesen Bitmaps steht für jeden Inode bzw. für jeden Datenblock (jede Daten-Zone), ob diese frei oder belegt sind: 0 bedeutet frei, 1 bedeutet belegt.

Die Inode-Bitmap folgt direkt auf den Superblock, dahinter kommt die Zone-Bitmap. Gleich danach folgt die Inode-Tabelle, und schließlich beginnen die Datenblöcke.

In der Zone-Bitmap steht das erste Bit (Bit 0) für keinen Datenblock und ist immer gesetzt; das zweite Bit (Bit 1) steht für den ersten Datenblock, welcher immer die ersten Verzeichniseinträge des Wurzelverzeichnisses enthält und nie frei sein kann, also ist auch das zweite Bit immer gesetzt; die noch davor liegenden Blöcke werden hier nicht erfasst, weil sie keine Dateiinhalte aufnehmen können.

Ein Inode sieht -- abhängig von der Minix-Dateisystem-Version -- wie folgt aus:

<<our minix headers>>=
struct minix2_inode {
  <<external minix2 inode>>
};
@

<<external minix2 inode>>=
  uint16_t i_mode;           uint16_t i_nlinks;
  uint16_t i_uid;            uint16_t i_gid;
  uint32_t i_size;           uint32_t i_atime;
  uint32_t i_mtime;          uint32_t i_ctime;
  uint32_t i_zone[10];
@

We're placing the [[minix2_inode]] entries in a separate code chunk since we will later define another inode data structure for the in-memory management of open files; there we will also need these fields.

Die Größe eines Inodes ist also $14 + 2 \times 9 = 32$ Bytes (v1) bzw. $24 + 4 \times 10 = 64$ Bytes (v2), damit passen in einen Inode-Block $1024/32 = 32$ Inodes (v1) bzw. $1024/64 = 16$ Inodes (v2).

Betrachten wir das Layout einer 1,4-MByte-Diskette, die mit Minix v2 formatiert ([[mkfs.minix -v]]) wurde. Eine Analyse des Superblocks ergibt:

<<example minix super block>>=
s_ninodes:	480
s_nzones:	0
s_imap_blocks: 1
s_zmap_blocks: 1
s_firstdatazone: 34
s_log_zone_size: 0
s_max_size:	2147483647
s_magic:	9336
s_state:	1
s_zones:	1440
@

Wir haben 480 Inodes. Bei 16 Inodes pro Block benötigt die Inode-Tabelle $480/16 = 30$ Blöcke. Die Inode-Bitmap besteht nur aus 480 Bits (=60 Bytes) und passt in einen Block, der Rest dieses Blocks wird nicht verwendet (und beim Formatieren mit 1-Bits gefüllt).
Bei 1440 Blöcken werden 1440 Bits (=180 Bytes) für die Zone-Bitmap benötigt, auch das passt wieder in einen Block. Auch hier wird der Rest des Blocks mit 1-Bits gefüllt.
Daraus ergibt sich folgende Aufteilung:

\begin{tabular}{|l|l|l|l|}
\hline
Block 0 & unused (boot sector) & 0--1023 & 0x0000--0x03ff \\
\hline
Block 1 & super block & 1024--2047 & 0x0400--0x07ff\\
\hline
Block 2 & Inode-Bitmap & 2048--3071 & 0x0800--0x0bff \\
\hline
Block 3 & Zone-Bitmap & 3072--4095 & 0x0c00--0x0fff \\
\hline
Blocks 4--33 & Inode-Tabelle (30 Blöcke) & 4096--34815 & 0x1000--0x87ff \\
\hline
Blocks 34--1439 & Datenblöcke & 34816--\dots & 0x8800--\dots\\
\hline
\end{tabular}

Dass es in Block 34 mit den Daten losgeht, steht auch im Superblock im Feld [[s_firstdatazone]].

Um das Wurzelverzeichnis des Dateisystems zu lesen, muss man nun wissen, dass Minix für das Wurzelverzeichnis [[/]] die Inode-Nummer 1 verwendet und auch bei 1 zu zählen beginnt; Inode 1 findet sich also an Position 0 in der Tabelle, der zugehörige Bitmap-Eintrag ist aber Bit 1 (nicht Bit 0, siehe unten)!

Im Inode finden Sie nun in [[i_zone[0]]] die Nummer des ersten Datenblocks. Der Block besteht aus Verzeichniseinträgen, welche die folgende Struktur haben:

<<our minix headers>>=
struct minix_dir_entry {
  uint16_t inode;
  char name[30];
};
@

Jeder Eintrag ist also $2+30 = 32$ Bytes groß und enthält zuerst die Inode-Nummer und dann den zugeordneten Dateinamen. Achtung: Wenn der Dateiname 30 Zeichen lang ist, dann ist er nicht (!) 0-terminiert. Für die interne Speicherung von Dateinamen (in Ihrem Programm) sollten Sie also 31 Zeichen reservieren und immer für eine korrekte 0-Terminierung des Strings sorgen.

In einen Block passen $1024 / 32 = 32$ solche Verzeichniseinträge. Gibt es mehr als 32, werden weitere Blöcke für dieses Verzeichnis verwendet. Wie groß das Verzeichnis insgesamt ist, steht in seinem Inode-Eintrag [[i_size]].




For the following code we assume that we have functions

<<our minix headers>>=
// void readblock (int blockno, char* block);
// void writeblock (int blockno, char* block);

// #define readblock kernel_read_sector
// #define writeblock kernel_write_sector

int fdc_read_sector(int device, int block, char* buffer);
@

<<our minix code>>=
// define DEBUG_BUFFER
void readblock (int blockno, char* buffer) {
  char extrabuf[1024]; int errors = 0;
  debug_printf ("readblock: arg1 address: %x\n", &blockno);
  debug_printf ("readblock: arg2 address: %x\n", &buffer);
  debug_printf ("readblock(%d): entered\n", blockno);
  
  // check if data were in the buffer cache
  if (buffer_read (0, blockno, buffer) == 0) {
    #ifdef DEBUG_BUFFER
    // let's debug
    fdc_read_sector (1, blockno*2,     extrabuf);
    fdc_read_sector (1, blockno*2 + 1, extrabuf + 512);
    for (int i=0; i<1024; i++) {
      if (buffer[i] != extrabuf[i]) {
        errors++;
        if (errors==1) printf ("BUFFER: readblock(%d) differs: ", blockno);
        debug_printf ("%d,", i);
      }
    }
    if (errors > 0) printf (" -- %d errors.\n", errors);
    #endif
    
    return;
  }
  
  fdc_read_sector (1, blockno*2,     buffer);
  fdc_read_sector (1, blockno*2 + 1, buffer + 512);
  
  // update buffer cache
  buffer_write (0, blockno, buffer);
};

int fdc_write_sector(int device, int block, char* buffer);

void writeblock (int blockno, char* buffer) {
  fdc_write_sector (1, blockno*2,     buffer);
  fdc_write_sector (1, blockno*2 + 1, buffer + 512);

  // update buffer cache (if it is in the cache)
  if ( buffer_contains (0, blockno) )
    buffer_write (0, blockno, buffer);
};


@

In order to print the information contained in the super block, we can
do the following:

<<our minix code>>=
typedef unsigned char uchar;

void show_superblock() {
  // Aufgabe b)
  uchar block[1024];
  struct minix_superblock* sblock;
  readblock (1, (uchar*)block);    // Superblock = Block 1
  sblock = (struct minix_superblock*) &block;
  printf ("s_ninodes:       %d\n", sblock->s_ninodes);
  printf ("s_nzones:        %d\n", sblock->s_nzones); 
  printf ("s_imap_blocks:   %d\n", sblock->s_imap_blocks); 
  printf ("s_zmap_blocks:   %d\n", sblock->s_zmap_blocks); 
  printf ("s_firstdatazone: %d\n", sblock->s_firstdatazone); 
  printf ("s_log_zone_size: %d\n", sblock->s_log_zone_size); 
  printf ("s_max_size:      %d\n", sblock->s_max_size); 
  printf ("s_magic:         %d\n", sblock->s_magic); 
  printf ("s_state:         %d\n", sblock->s_state); 
  printf ("s_zones:%d\n", sblock->s_zones);
}
@

We need ways to access single bits in the inode and zone bitmaps,
such as the following:

<<our minix code>>=
unsigned int get_imap_bit (int i) {
  debug_printf ("get_imap_bit: entered\n");

  /*  
  uint reg_esp0;
  __asm__ __volatile__("mov %%esp, %0": "=r"(reg_esp0));
  printf ("get_imap_bit, Reg. ESP0: 0x%08x\n", reg_esp0);
  */
  
  // Aufgabe d)
  uchar block[1024];
  unsigned int byte;
  debug_printf ("get_imap_bit: before readblock()\n");
  readblock (2, (uchar*)&block);    // Inode-Map = Block 2
  debug_printf ("get_imap_bit: after readblock()\n");
    // vollstaendige Loesung: evtl. mehr als 1 Block bearbeiten
  byte = block[i/8];
  return (byte >> (i%8)) % 2;  
};

unsigned int get_zmap_bit (int i) {
  // Aufgabe d)
  uchar block[1024];
  unsigned int byte;
  readblock (3, (uchar*)&block);    // Zone-Map = Block 3
    // vollstaendige Loesung: evtl. mehr als 1 Block bearbeiten
  byte = block[i/8];
  return (byte >> (i%8)) % 2;  
};
@

Um aus einer 8-Bit-Integer-Zahl $n$ das Bit $i$ auszulesen ($0 \le i \le 7$), können Sie die Formel [[(n >> i) % 2]]
(Rechts-Shift um $i$ Positionen, dann mit [[%2]] das unterste Bit lesen) verwenden.

We also need to set and clear individual bits. Since the code for
accessing and changing a bit is almost identical for setting and
clearing, we write two functions [[set_clear_*]] which can both set
and clear; they are called by the [[set_*]] and [[clear_*]] functions
with appropriate arguments:

<<our minix code>>=
void set_clear_imap_bit (int i, int value) {
  // Aufgabe d), eine Funktion fuer set und clear
  uchar block[1024];
  unsigned int byte;
  readblock (2, (uchar*)&block);    // Inode-Map = Block 2
    // vollstaendige Loesung: evtl. mehr als 1 Block bearbeiten
  byte = block[i/8];
  if (value==0) {
    // Clear bit
    byte = byte & (255 - (1<<(i%8)));
  } else {
    // Set bit
    byte = byte | 1<<(i%8);
  }; 
  block[i/8] = byte;
  writeblock (2, (uchar*)&block);  
};

void set_clear_zmap_bit (int i, int value) {
  // Aufgabe d), eine Funktion fuer set und clear
  uchar block[1024];
  unsigned int byte;
  readblock (3, (uchar*)&block);    // Zone-Map = Block 3
    // vollstaendige Loesung: evtl. mehr als 1 Block bearbeiten
  byte = block[i/8];
  if (value==0) {
    // Clear bit
    byte = byte & (255 - (1<<(i%8)));
  } else {
    // Set bit
    byte = byte | 1<<(i%8);
  }; 
  block[i/8] = byte;
  writeblock (3, (uchar*)&block);  
};

void set_imap_bit (int i)   { set_clear_imap_bit (i, 1); };
void clear_imap_bit (int i) { set_clear_imap_bit (i, 0); };
void set_zmap_bit (int i)   { set_clear_zmap_bit (i, 1); };
void clear_zmap_bit (int i) { set_clear_zmap_bit (i, 0); };
@

Implementieren Sie zwei Funktionen [[request_inode()]] und [[request_block()]], welche mit Hilfe der jeweiligen Bitmap den ersten freien Inode (bzw. den ersten freien Block) finden, diesen als belegt markieren und die Inode-Nummer (bzw. die Blocknummer / Zone-Nummer) zurückgeben. Wenn alle Inodes bzw. alle Blöcke belegt sind, sollen die Funktionen -1 zurückgeben.

Beachten Sie, dass (wie weiter oben beschrieben) die Zone-Bitmap nicht mit dem Eintrag für Block 0 beginnt, sondern mit dem Zustand von Block 33. (Der erste Datenblock ist im Beispiel 34.) Um den Zustand von Block n abzufragen, können Sie also [[get_zmap_bit (n-s_firstdatazone+1)]] verwenden. (Überlegen Sie sich, warum das so ist -- setzen Sie n=34 ein.)

<<our minix code>>=
int request_inode () {
  // Aufgabe e)
  int no_inodes = 480;  // korrekte Loesung: S-Block auswerten
  int i;
  for (i = 0; i < no_inodes; i++) {
    if (get_imap_bit (i) == 0) {
      // Treffer!
      set_imap_bit (i);   // als belegt markieren
      return i;
    }
  }
  return -1; // nichts gefunden
};

int request_block () {
  // Aufgabe e)
  int no_zones = 1440;  // korrekte Loesung: S-Block auswerten
  int i;
  for (i = 0; i < no_zones; i++) {
    if (get_zmap_bit (i) == 0) {
      // Treffer!
      set_zmap_bit (i);   // als belegt markieren
      return i+33;        // Blocknr.: i+33 !!
    }
  }
  return -1; // nichts gefunden
};
@


Wir setzen die Implementierung des Minix-Dateisystems fort. Wenn Sie Aufgabe 12 nicht erfolgreich bearbeiten konnten, können Sie als Basis die rudimentäre Musterlösung von der Webseite verwenden (u7-mini-loesung.c), die allerdings keine Fehlerprüfung vornimmt und die Aufgabenstellung teilweise vereinfacht. (Sie sollten diese dann zu einem späteren Zeitpunkt mit Ihrem Lösungsansatz integrieren bzw. so ausbauen, dass sie auch Fehler abfängt und Situationen unterstützt, die in größeren Images auftauchen können.)

Sie können nun bereits den Superblock, die Inode-Bitmap und die Zone-Bitmap auslesen, in den Bitmaps einzelne Bits abfragen / setzen / löschen und generell ganze Blöcke lesen und schreiben. Mit diesen Mitteln lässt sich einiges anfangen, denn die Vorgehensweise beim Erstellen einer neuen Datei ist einfach:

\begin{enumerate}
\item Inode reservieren (mit [[request_inode]])
\item Benötigte Blöcke reservieren (mit [[request_block]]) und Blocknummern im Inode vermerken (dafür gibt es noch keine Code)
\item Inhalt in die reservierten Blöcke schreiben (mit [[writeblock]])
\item Eintrag im Verzeichnis erzeugen (Zuordnung Dateiname $\rightarrow$ Inode-Nummer)
\end{enumerate}

Das einzige, was Sie bisher nicht können, ist das Bearbeiten von Inodes und Verzeichnissen -- darum geht es in diesem Teil des Projekts. Nach dem Lösen der heutigen Aufgaben können Sie neue Dateien im Minix-Image anlegen (sofern deren Inhalte in sieben Datenblöcke passen, also maximal 7 KByte groß sind).

Vorab eine wichtige Erinnerung an die Pointer-Arithmetik: Sie werden bei den folgenden Aufgaben gelegentlich mit [[memcpy()]] Daten in die Mitte eines im Speicher gehaltenen Blocks schreiben müssen. Wenn Sie den Block als [[char block[1024]]]; deklariert haben und jetzt innerhalb das Blocks z. B. ab Position 512 einen 32 Byte langen Inhalt schreiben möchten, wird der Aufruf

<<pointer arithmetic test 1>>=
offset = 512; size = 32;
memcpy (&block + offset, &daten, size);
@

fehlschlagen. Wenn Sie block hingegen als [[char* block;]] deklarieren, funktioniert

<<pointer arithmetic test 2>>=
offset = 512; size = 32;
memcpy (block + offset, &daten, size);
@

wie erwartet. Das folgende Beispielprogramm verdeutlicht den Unterschied:

<<pointer arithmetic example>>=
#include <stdio.h>
int main () {
  char block[1024]; char* block2=(char*)&block; char daten[]="Test";
  int size = sizeof(daten); int offset = 512; long diff;

  printf ("&block:          %p \n", &block);
  printf ("&block + offset: %p \n", &block + offset);
  diff = (long)(&block+offset)-(long)&block;
  printf ("Differenz:       %ld \n", diff);
  
  printf ("block2:          %p \n", block2);
  printf ("block2 + offset: %p \n", block2 + offset);
  diff = (long)(block2+offset)-(long)block2;
  printf ("Differenz:       %ld \n", diff);
};
@

erzeugt die folgende Ausgabe:

{\small
\begin{verbatim}
esser@ubu64:/tmp/z2$ ./offset-test 
&block:          0x7ffff31802b0 
&block + offset: 0x7ffff32002b0 
Differenz:       524288                  /* das ist 512 x 1024 ! */
block2:          0x7ffff31802b0 
block2 + offset: 0x7ffff31804b0 
Differenz:       512                     /* so soll es sein... */
\end{verbatim}
}

Beim ersten Versuch wird also die Größe eines [[char[1024]]] berücksichtigt und mit dem Offset multipliziert (Pointer-Arithmetik). Darum müssen Sie in diesem Fall immer erst auf [[(char*)]] casten, sonst landen Sie an völlig falschen Speicherstellen.

Wir starten mit den Funktionen [[read_inode()]] und [[write_inode()]], die Sie wie folgt implementieren sollen:

<<tmp 1>>=
int read_inode  (int i, struct minix2inode* inodeptr);
int write_inode (int i, struct minix2inode* inodeptr);
@

Rückgabewert: 0 bei Fehler, sonst i (erlaubt Tests mit [[if (!read_inode(...) { /* Fehler */ }]]). Ein Fehler ist es auch, einen nicht belegten Inode anzufordern!

Sie können sich diese Aufgaben erleichtern, wenn Sie überlegen, welche Unterschiede zwischen dem Lesen und dem Schreiben bestehen und zunächst eine allgemeine Funktion

<<tmp 1>>=
int read_write_inode (int i, struct minix2_inode* inodeptr, 
                      int wr_flag);
@

schreiben, die beides kann (abhängig vom Flag [[wr_flag]]). 

<<our minix code>>=
int read_write_inode (int i, struct minix2_inode* inodeptr, int wr_flag) {
  debug_printf ("read_write_inode: entered\n");
  
  /*
  uint reg_esp0;
  __asm__ __volatile__("mov %%esp, %0": "=r"(reg_esp0));
  printf ("read_write_inode, Reg. ESP0: 0x%08x\n", reg_esp0);
  */
  
  // Aufgabe 13 a)
  // Funktion liest oder schreibt
  i--;  // erster Inode: Nr. 1, aber Position 0 in Tabelle
  if ((i<0) || (i > 479)) 
    return 0;  // korrekte Loesung wertet S-Block aus
  if (get_imap_bit(i+1) == 0) {
    printf ("DEBUG: get_imap_bit(%d) = %d in read_inode\n", i+1, get_imap_bit(i));
    return 0;  // unbelegter Inode
  }
  debug_printf ("read_write_inode: after get_imap_bit()\n");

  
  // Speicher fuer Inode schon reserviert
  const int inodesize = sizeof (struct minix2_inode);
  const int inodesperblock = BLOCK_SIZE / inodesize;
  
  int blockno, blockoffset;
  blockno = i / inodesperblock + 4;  // Tabelle ab Block 4
  blockoffset = i % inodesperblock;
  
  uchar block[1024];
  // Block muss auch bei write_inode() erst gelesen werden

  // printf ("DEBUG: read_inode; inodeno = %d, blockno = %d\n", i, blockno);
    

  readblock (blockno, (uchar*)&block);

  // Offset addieren, Vorsicht vor Pointer-Arithmetik!
  void* addr = (void*)&block;
  addr += blockoffset*inodesize;

  // lesen oder schreiben?
  if (!wr_flag) {
    memcpy (inodeptr, (uchar*)addr, inodesize);
  } else {
    memcpy ((uchar*)addr, inodeptr, inodesize);
    // ganzen Block ins Image zurueck schreiben
    writeblock (blockno, (uchar*)&block);
  };
  return (i+1);  // wieder Originalnummer...
};

int read_inode (int i, struct minix2_inode* inodeptr) {
  // printf ("DEBUG: read_inode %d\n", i);
  return read_write_inode (i, inodeptr, 0);  // 0 = false
}

int write_inode (int i, struct minix2_inode* inodeptr) {
  return read_write_inode (i, inodeptr, 1);  // 1 = true
}
@



Erstellen Sie zudem eine Funktion

<<tmp 1>>=
void show_inode (struct minix2_inode* inode);
@

welche die Felder eines vorher mit [[read_inode()]] eingelesenen Inodes ausgibt. Die Beschreibung der hier benötigten Datenstrukturen finden Sie auf dem letzten Aufgabenblatt.

<<our minix code>>=
void show_inode (struct minix2_inode* inode) {
  // Aufgabe 13 a)
  printf ("i_mode    : %o (oct)\n", inode->i_mode);
  printf ("i_nlinks  : %d\n", inode->i_nlinks);
  printf ("i_uid     : %d\n", inode->i_uid);
  printf ("i_gid     : %d\n", inode->i_gid);
  printf ("i_size    : %d\n", inode->i_size);
  printf ("i_atime   : %d\n", inode->i_atime);
  printf ("i_mtime   : %d\n", inode->i_mtime);
  printf ("i_ctime   : %d\n", inode->i_ctime);
  int i;
  for (i = 0; i<10; i++)
  printf ("i_zone[%d] : %d\n", i, inode->i_zone[i]);
};
@



Blocknummern sind vom Typ [[uint32_t]], also 32 Bit große vorzeichenlose Integers. Im Inode stehen die absoluten Blocknummern der verwendeten Datenblöcke. Einträge, die auf keinen Block zeigen sollen, enthalten die (ungültige) Blocknummer 0. 

Sie können eine Liste von zu belegenden Blöcken als Liste verwalten ([[uint32_t[]]] oder [[uint32_t*]]). Die Liste soll immer mit 0 terminiert sein. Schreiben Sie zwei Funktionen

<<tmp 1>>=
int read_block_list  (int i, uint32_t* blocklist);
int write_block_list (int i, uint32_t* blocklist);
@

welche zu einem angegebenen Inode (i) die zugehörigen Blöcke zurückgeben bzw. diese in den Inode schreiben. Der Rückgabewert beider Funktionen ist die Anzahl der Blöcke, im Fehlerfall -1. (Der Fehlercode ist nicht 0, weil es zulässig ist, eine Datei ohne Blöcke zu verwenden: eine leere Datei).

<<our minix code>>=
int read_block_list  (int i, uint32_t* blocklist) {
  // Aufgabe 13 b)
  struct minix2_inode inode;
  if (!read_inode (i, &inode)) return -1;
  for (i = 0; i<10; i++) {
    *blocklist++ = inode.i_zone[i];
    if (inode.i_zone[i]==0) return i;
  };
  *blocklist = 0;
  return i;
};

int write_block_list (int i, uint32_t* blocklist) {
  // Aufgabe 13 b)
  struct minix2_inode inode;
  if (!read_inode (i, &inode)) return -1;
  for (i = 0; i<10; i++) {
    inode.i_zone[i] = *blocklist++;
    if (inode.i_zone[i]==0) return i;
  };
  *blocklist = 0;
  return i;
};
@

Jetzt können Sie neue Datenblöcke, die Sie mit [[request_block()]] reserviert haben, mit [[write_block_list()]] in einen neuen Inode schreiben, welchen Sie mit [[request_inode()]] angefordert haben; der Code für das Erzeugen einer neuen (mit Nullen gefüllten) Datei sieht also so aus:

Implementieren Sie diese Funktion vollständig (bis auf den Verzeichniseintrag, darum geht es in Aufgabe d) -- die Funktion [[write_link()]] können Sie zunächst als Rumpf ohne Funktion ergänzen.

Hinweis: Beschränken Sie sich zunächst auf Dateien, die in sieben Datenblöcke passen -- für größere Dateien müssen Sie indirekte und ggf. doppelt indirekte Blockadressierung verwenden, siehe nächste Übung. (Dabei enthält [[inode->i_zone[7]]] die Adresse eines Indirektionsblocks, der Adressen von Datenblöcken speichert; [[inode->i_zone[8]]] enthält die Adresse eines Doppelindirektionsblocks, welcher Adressen von Indirektionsblöcken speichert. [[inode->i_zone[9]]] ist für künftige Verwendungen, etwa dreifache Indirektion, reserviert und wird nie benutzt. Mehr dazu in der nächsten Woche.)

Der Inode soll auch sinnvolle Angaben bei den Zugriffsrechten (mode=0644, oktal) und Besitzer und Gruppe (uid=gid=0) enthalten. Berücksichtigen Sie auch [[nlinks]]! Die drei Timestamps können Sie auf einen beliebigen Wert setzen (z. B. 1338847929 für ein aktuelles Datum).

Testen Sie die Funktion, indem Sie [[create_null_file()]] (mit einer Größe von maximal 7 KByte) aufrufen und sich dann den (neuen) Inode Nr. 5 ausgeben lassen.

<<our minix code>>=
void create_null_file (int size, char* filename) {
  // Aufgabe 13 c)
  int nblocks, i;
  if (size == 0)
    nblocks = 0;
  else
    nblocks = (size-1)/BLOCK_SIZE+1;  // Rechnerei...
    
  if (nblocks>7) {
    // Fehler: nicht genug Eintraege in Liste
    printf ("Fehler: mehr als 7 direkte Blockadressen\n");
    //!exit(1);
  };
  
  uint32_t* blist = kmalloc ((nblocks+1)*sizeof(uint32_t));
  uint32_t* tmp = blist;  // Adresse merken
  for (i = 0; i<nblocks; i++)
    *blist++ = request_block ();
  *blist = 0;
  blist = tmp;
  int inodenr = request_inode ();
  write_block_list (inodenr, blist);
  // weitere Eintraege im Inode
  struct minix2_inode inode;
  read_inode (inodenr, &inode);
  for (i = 0; i<nblocks; i++)
    inode.i_zone[i] = *blist++;
  inode.i_size = size;
  inode.i_atime = inode.i_ctime = inode.i_mtime = 9999;
  inode.i_uid = inode.i_gid = 0;
  inode.i_nlinks = 0;  // setzen wir erst spaeter auf 1
  inode.i_mode = S_IFREG | 0664;
  write_inode (inodenr, &inode);
  // Datenblöcke mit Nullen füllen
  // for (i = 0; i<nblocks; i++)
  //   ...
  // Verzeichniseintrag anlegen
  write_link (inodenr, filename);
  blist = tmp;
  kfree (blist);
};
@


Jetzt fehlt noch die Funktion [[write_link()]], welche dem Wurzelverzeichnis / einen neuen Eintrag hinzufügt: den Verweis von [[filename]] auf den Inode [[inodenr]].

Verzeichnisse sind, wie schon erwähnt, spezielle Dateien; das Wurzelverzeichnis hat die Inode-Nummer 1. Die von dort verlinkten Datenblöcke enthalten je bis zu 32 Verzeichniseinträge vom Typ:

{\small
\begin{verbatim}
struct minix_dir_entry {
  uint16_t inode;
  char name[30];
};
\end{verbatim}
}

(denn 32 x 32 = 1024). Ein nicht verwendeter Eintrag im Verzeichnis ist durch [[inode=0]] gekennzeichnet.

Um einen Verzeichniseintrag auszulesen bzw. zu schreiben, erstellen Sie die beiden Funktionen

<<tmp 1>>=
int read_dir_entry  (int inodenr, int entrynr, 
                     struct minix_dir_entry* entry);
int write_dir_entry (int inodenr, int entrynr, 
                     struct minix_dir_entry* entry);
@

Hier können Sie auch wieder den Trick aus Aufgabe a) verwenden und zunächst eine gemeinsame Funktion [[int read_write_dir_entry (..., int wr_flag)]] erstellen. Das erste Argument der Funktion gibt den Inode des Verzeichnisses an (damit lässt sich die Funktion später auf andere Verzeichnisse als / erweitern), danach folgt die Nummer des Verzeichniseintrags und schließlich ein Pointer auf einen Verzeichniseintrag ([[struct minix_dir_entry]]).

Wie schon beschrieben, passen in einen Block nur 32 Verzeichniseinträge -- wenn Sie mehr als 32 Einträge in einem Verzeichnis haben, müssen Sie 

\begin{itemize}
\item einen weiteren Block reservieren und in den Verzeichnis-Inode eintragen 
\item in diesem Block das Anlegen der Einträge fortsetzen
\end{itemize}

Genauso ist es später beim Löschen von Einträgen evtl. nötig, leer gewordene Zusatzblöcke wieder zu entfernen. Sie erleichtern sich die Lösung, indem Sie dieses Problem zunächst ignorieren und erst nach der erfolgreichen Implementierung für $\le$ 32 Einträge die Funktionen so erweitern, dass sie mit mehr als 32 Einträgen zurecht kommen. 

<<our minix code>>=
int read_write_dir_entry (int inodenr, int entrynr, 
  struct minix_dir_entry* entry, int wr_flag) {
  debug_printf ("read_write_dir_entry: entered\n");
  
  // unvollstaendige Loesung: nur 1 Block mit Eintraegen
  char block[1024];
  struct minix2_inode inode;
  debug_printf ("read_write_dir_entry: before read_inode()\n");
  read_inode (inodenr, &inode);  // Dir-Inode lesen
  debug_printf ("read_write_dir_entry: after read_inode()\n");
  int blockno;
  blockno = inode.i_zone[0];     // erster Block mit Eintraegen
  readblock (blockno, (uchar*)&block);
  
  int offset = 32*entrynr;       // jeder Eintrag 32 Bytes
  if (!wr_flag) {
    // lesen
    /*
    printf ("debug: &block        = %p\n", &block);
    printf ("debug: &block+offset = %p\n", ((char*)&block)+offset);
    printf ("debug: offset = %d\n", offset);
    */
    memcpy (entry, ((char*)&block)+offset, 32);
    if (entry->inode!=0)
      return 1; // true: hat Inhalt
    else
      return 0; // false: kein Inhalt
  } else {
    // schreiben
    memcpy (((uchar*)&block)+offset, entry, 32);
    writeblock (blockno, (uchar*)&block);
    return 1; // true
  };
};

int read_dir_entry (int inodenr, int entrynr, struct minix_dir_entry* entry) {
  read_write_dir_entry (inodenr, entrynr, entry, 0);  // 0 = false
};

int write_dir_entry (int inodenr, int entrynr, struct minix_dir_entry* entry) {
  read_write_dir_entry (inodenr, entrynr, entry, 1);  // 1 = true
};
@

Jetzt können Sie die in Aufgabe c) bereits erwähnte Funktion [[write_link()]] implementieren: Sie müssen nur in einer Schleife mit [[read_dir_entry()]] einen freien Eintrag suchen (erkennbar an [[entry.inode = 0]]) und diesen dann für den neuen Eintrag verwenden.

Während [[write_dir_entry()]] keine Überprüfungen durchführt, muss [[write_link()]] prüfen, ob ein Dateiname bereits vorhanden ist, denn derselbe Dateiname darf nicht mehrfach in einem Verzeichnis auftauchen.

Ihr Programm darf zur Vereinfachung annehmen, dass ein Verzeichnis nie mehr als 224 ($= 7 \times 32$) Einträge enthält -- dann passen die Einträge alle in die ersten sieben Datenblöcke, welche über den Verzeichnis-Inode direkt erreichbar sind ([[i_zone[0]]] bis [[i_zone[6]]]).

[[write_link()]] muss am Ende auch die Größe des Verzeichnisses anpassen (Eintrag [[i_size]] im Inode des Verzeichnisses)!



For dealing with pathnames we will sometimes need two helper functions:
[[dirname]] and [[base]] can be used to split a path into a directory (path)
and a file or directory name, for example
[[dirname ("/usr/bin/vi") = "/usr/bin"]] and [[basename ("/usr/bin/vi") = "vi"]].
This works similarly for relative paths, and the special case of a pathname
[[x]] without any slashes is handled by 
[[dirname ("x") = "."]] and [[basename ("x") = "x"]].

We will also recycle these functions in the user mode library, since it does not
matter whether the kernel or a program wants to split a pathname.
Instead of parsing the path in two separate functions, we write a combined function
[[splitpath (path, dirname, basename)]] and call this from [[basename]] and [[dirname]].

<<universal headers>>=
void splitpath (const char *path, char *dirname, char *basename);
char *basename (char *path);
char *dirname (char *path);
@

<<universal functions>>=
void splitpath (const char *path, char *dirname, char *basename) {
  char p[256];
  strncpy (p, path, 256);    // work on copy
  
  int pos = strlen (p) - 1;
  if (p[pos] == '/') {
    p[pos] = 0; pos--;       // strip trailing /
  }

  // search for / (from back to front)
  for (;;) {
    pos--;
    if (pos == -1) {
      // no single slash found
      strncpy (dirname, ".", 2);
      strncpy (basename, p, 256);
      return;
    }
    if (p[pos] == '/') {
      // slash found
      if (pos==0)
        strncpy (dirname, "/", 2);  // special case /
      else {
        memcpy (dirname, p, pos);
        dirname[pos] = 0;   // remove trailing /
      }
      strncpy (basename, p + pos + 1, 30);
      return;
    }
  }
}

char *basename (char *path) {
  static char bname[30];
  static char dname[256];
  splitpath (path, dname, bname);
  return (char *)bname;
}

char *dirname (char *path) {
  static char bname[30];
  static char dname[256];
  splitpath (path, dname, bname);
  return (char *)dname;
}
@


<<kernel declarations>>=
<<universal headers>>
@

<<kernel functions>>=
<<universal functions>>
@

<<our minix headers>>=
void write_link (int inodenr, const char* filename);
@

<<our minix code>>=
void write_link (int inodenr, const char* path) {
  printf ("DEBUG: write_link (%d, %s) entered.\n", inodenr, path);
  struct minix_dir_entry dentry;
  struct minix2_inode inode;
  increase_link_count (inodenr);
  int i;
  char dirname[256];
  char filename[30];
  // Pruefen, ob es den Namen schon gibt
  if (file_exists (path)) {
      printf ("FEHLER: Name %s schon vorhanden!\n", path);
      return;
  };
    
  // search for directory to enter file
  strncpy (dirname, path, 256);
  int tmp = strlen(dirname)-1;
  for (;;) {
    if (dirname[tmp] == '/') {
      dirname[tmp] = 0;   // truncate path at last slash
      break;
    }
    tmp--;
    if (tmp < 0) {
      printf ("ERROR: no directory in path %s\n", path);
      return;   // error: found no /
    }
  }
  strncpy (filename, path+tmp+1, 30);
  
  if (dirname[0] == 0) {
    dirname[0] = '/'; dirname[1] = 0;
  }
  
  int dir_inode_no = pathname_to_ino (dirname);
  
  printf ("DEBUG: dirname='%s' (ino: %d), filename='%s'\n", dirname, dir_inode_no, filename);

  // Freien Platz suchen und eintragen
  for (i=0; i<32; i++) {
    read_dir_entry (dir_inode_no, i, &dentry);   // 1: Inode von /
    if (dentry.inode==0) {
      // leerer Eintrag gefunden
      dentry.inode = inodenr;
      memcpy ((char*)dentry.name, filename, 30);
      write_dir_entry (dir_inode_no, i, &dentry);
      
      // Groesse anpassen
      read_inode (dir_inode_no, &inode);
      // printf ("debug: inode.i_size = %d\n", inode.i_size);
      if (inode.i_size < 32*(i+1)) {
        inode.i_size = 32*(i+1);
        write_inode (dir_inode_no, &inode);
      };
      return;
    };
  };
  // nichts gefunden?
  printf ("FEHLER: kein freier Eintrag im Directory\n");
  //!exit (1);
};
@

This function uses [[increase_link_count()]] which adds 1 to the
number of links for a given inode:

<<our minix headers>>=
int increase_link_count (int inodenr);
@

<<our minix code>>=
int increase_link_count (int inodenr) {
  struct minix2_inode inode;
  read_inode (inodenr, &inode);
  inode.i_nlinks++;
  write_inode (inodenr, &inode);
  return inode.i_nlinks;
};
@

Implementieren Sie eine Funktion [[void list_dir (int i)]], die als Argument die Inode-Nummer eines Verzeichnisses erhält (diese Nummer wird im Beispiel immer 1 für das Wurzelverzeichnis sein). Sie soll dann alle Verzeichniseinträge auslesen. Wenn ein Eintrag belegt ist, soll sie über die darin gespeicherte Inode-Nummer den zugehörigen Inode auslesen und dann in einer Zeile Inode-Nummer, Dateiname, Link-Count und Dateigröße ausgeben:

<<our minix code>>=
#define S_IRWXU  0000700    /* RWX mask for owner */
#define S_IRUSR  0000400    /* R for owner */
#define S_IWUSR  0000200    /* W for owner */
#define S_IXUSR  0000100    /* X for owner */

#define S_IRWXG  0000070    /* RWX mask for group */
#define S_IRGRP  0000040    /* R for group */
#define S_IWGRP  0000020    /* W for group */
#define S_IXGRP  0000010    /* X for group */

#define S_IRWXO  0000007    /* RWX mask for other */
#define S_IROTH  0000004    /* R for other */
#define S_IWOTH  0000002    /* W for other */
#define S_IXOTH  0000001    /* X for other */

#define S_ISUID  0004000    /* set user id on execution */
#define S_ISGID  0002000    /* set group id on execution */
#define S_ISVTX  0001000    /* save swapped text even after use */

#define S_IFMT   0170000    /* mask the fie type part */
#define S_IFIFO  0010000    /* named pipe (fifo) */
#define S_IFCHR  0020000    /* character special */
#define S_IFDIR  0040000    /* directory */
#define S_IFBLK  0060000    /* block special */
#define S_IFREG  0100000    /* regular */
#define S_IFLNK  0120000    /* symbolic link */
#define S_IFSOCK 0140000    /* socket */

void format_rights (int mode, char *str) {
  char c;
  switch (mode & S_IFMT) {
    case S_IFIFO:  c = 'f'; break; 
    case S_IFCHR:  c = 'c'; break;
    case S_IFDIR:  c = 'd'; break;
    case S_IFBLK:  c = 'b'; break;
    case S_IFREG:  c = '-'; break;
    case S_IFLNK:  c = 'l'; break;
    case S_IFSOCK: c = 's'; break;
  };
  str[0] = c;
  str[1] = (mode & S_IRUSR) ? 'r' : '-';
  str[2] = (mode & S_IWUSR) ? 'w' : '-';
  str[3] = (mode & S_IXUSR) ? 'x' : '-';
  str[4] = (mode & S_IRGRP) ? 'r' : '-';
  str[5] = (mode & S_IWGRP) ? 'w' : '-';
  str[6] = (mode & S_IXGRP) ? 'x' : '-';
  str[7] = (mode & S_IROTH) ? 'r' : '-';
  str[8] = (mode & S_IWOTH) ? 'w' : '-';
  str[9] = (mode & S_IXOTH) ? 'x' : '-';
  str[10] = 0;
  return;
};

// struct minix_dir_entry dentry;
void list_dir (int inodenr) {
  char rights[11];
  struct minix2_inode dirinode, inode;
  struct minix_dir_entry dentry;

  // check if this is a directory
  read_inode (inodenr, &inode);
  // printf ("Directory inode's i_mode: %o\n", inode.i_mode);
  if ((inode.i_mode & S_IFMT) != S_IFDIR) {
    printf ("ls: not a directory\n");
    return;
  }

  int i;
  // printf ("DEBUG: in list_dir (%d)...; before loop\n", inodenr);
  for (i=0; i<32; i++) {
    // printf ("DEBUG: in loop, before read_dir_entry \n");
    read_dir_entry (inodenr, i, &dentry);
    // printf ("DEBUG: in loop, after read_dir_entry \n");
    if (dentry.inode != 0) {
      read_inode (dentry.inode, &inode);
      format_rights (inode.i_mode, (char*)&rights);
      printf ("%2d %s %2d %4d %4d %6d %-30s\n", dentry.inode, rights,
              inode.i_nlinks, inode.i_uid, inode.i_gid, inode.i_size, dentry.name);
    }
  }
};
@

This generates output such as

{\small
\begin{verbatim}
 1 .                            2     192
 1 ..                           2     192
 2 Testdatei1.txt               2    6144
 3 Testdatei2.txt               1    6144
 2 Hardlink.txt                 2    6144
 4 Symlink.txt                  1      14
\end{verbatim}
}

REST AUS DEN ÜBUNGSAUFGABEN:

<<our minix code>>=
void show_inode_bitmap () {
  // Aufgabe c), benutzt Loesung zu d)
  int no_inodes = 480;  // korrekte Loesung: S-Block auswerten
  int i, j;
  for (i = 0; i<no_inodes; i+=64) {
    // print 64 entries
    printf ("%03d : ", i);  // Position
    for (j = i; j<i+64 && j<no_inodes; j++) {
      printf ("%d", get_imap_bit (j));
      if ((j%8)==7) printf (" ");
    };
    printf ("\n");
  };
  printf ("Belegte Inodes: ");
  for (i = 0; i<480; i++) {
    if (get_imap_bit (i)==1) printf ("%d, ", i);
  };
  printf ("\n");
}

void show_zone_bitmap () {
  // Aufgabe c), benutzt Loesung zu d)
  int no_zones = 1440;  // korrekte Loesung: S-Block auswerten
  unsigned int i, j;
  for (i = 0; i<no_zones-33; i+=64) {
    // -33: Liste ist nur 1440-33 Zeichen lang
    // korrekte Loesung: rausfinden, wie viele Bloecke Datenbloecke sind
    // print 64 entries
    printf ("%04d : ", i+33);  // Position, 1. Eintrag fuer Block 33
    for (j = i; j<i+64 && j<no_zones-33; j++) {
      // print entry j
      printf ("%d", get_zmap_bit (j));
      if ((j%8)==7) printf (" ");
    };
    printf ("\n");
  };
  printf ("Belegte Zones: ");
  for (i = 0; i<1440-33; i++) {
    if (get_zmap_bit (i)==1) printf ("%d, ", i+33);  // +33 !
  };
  printf ("\n");
}
@


% weiter mit Uebung 9, Aufgabe 14

Diesmal geht es darum, die Funktionen [[open()]], [[read()]], [[lseek()]] und [[close()]]nachzubilden. Es soll damit ein Zugriff auf Dateien im Wurzelverzeichnis des Minix-Dateisystems möglich sein, und Sie sollen bis zu 16 Dateien gleichzeitig geöffnet halten können. Die neuen Funktionen werden analog [[mx_open()]], [[mx_read()]], [[mx_lseek()]] und [[mx_close()]] heißen.

Datenstrukturen, die Sie im Programm benötigen, sind die folgenden:

\begin{itemize}
\item interner Inode: das ist eine Kopie des Inodes aus dem Minix-Dateisystem, aber mit zusätzlichen Elementen, z. B. einem Reference Count [[refcount]], der mitzählt, wie oft die darüber erreichbare Datei geöffnet ist. Sobald Sie eine Datei öffnen, legen Sie einen solchen internen Inode an; Änderungen an den Metadaten speichern Sie zunächst nur im internen Inode, erst beim Schließen der Datei werden diese Informationen ins Dateisystem zurückgeschrieben. (Für sofortiges Sichern der Daten wird es eine Funktion [[mx_sync()]] geben, siehe Aufgabe d.) Eines der nötigen Zusatzfelder im internen Inode heißt [[clean]] und ist 1, solange keine Änderungen am internen Inode vorgenommen wurden. Jede Änderung setzt den Wert auf 0, jeder Aufruf von [[mx_sync()]] setzt den Wert (am Ende) wieder auf 1.

<<our minix headers>>=
struct int_minix2_inode {
  <<external minix2 inode>>    // fields from the external inode
  int ino;                    // inode number
  unsigned int    refcount;   // how many users?
  unsigned short  clean;      // 0: changed; 1: unchanged (as on disk)
};

#define MAX_INT_INODES 256
struct int_minix2_inode inodes[MAX_INT_INODES] = { 0 };
@

Für interne Inodes wird bei Bedarf mit [[malloc()]] Speicherplatz organisiert und mit [[free()]] wieder freigegeben, wenn der interne Inode nicht länger verwendet wird.

\item GFD (Global File Descriptor): ein nicht-negativer Integer-Wert, den [[mx_open()]] zurückgibt und den die übrigen Funktionen für den Dateizugriff verwenden.

It has the same function as a normal file descriptor in user mode programs, however a global file descriptor is valid in the whole system, whereas each process counts file descriptors separately. When we later allow processes to work with files (via system calls), we will map process-local file descriptors to global file descriptors.

\item Dateistatus: Ein Struct, das die folgenden Elemente enthält:

  \begin{itemize}
  \item Zeiger auf einen internen Inode: Steht hier ein Nullzeiger, ist der Eintrag unbenutzt. Ansonsten handelt es sich um den internen Inode einer geöffneten Datei.

  \item Dateiposition: Der Standardinhalt (für unbenutzte Einträge) ist -1. Beim Öffnen einer Datei wird der Wert 0 eingetragen; Ausnahme: Beim Öffnen im Append-Modus wird [[i_size]] ein- getragen.

  \item Modus: [[O_RDONLY]], [[O_WRONLY]], [[O_RDWR]] oder [[O_APPEND]]
  \end{itemize}

Für die folgenden Beschreibungen nehmen wir an, dass der Aufbau so aussieht:

<<our minix code>>=
struct filestat { 
  struct int_minix2_inode* int_inode; 
  int pos; 
  short mode;
};
@

(Thus, if a file was opened twice, there will be one internal inode, referenced by the global file descriptor, and two [[filestat]] structures, since access mode and read/write position may be different.)

Modes for opening ara [[O_RDONLY]], [[O_WRONLY]], [[O_RDWR]], and [[O_APPEND]]:

<<kernel declarations>>=
#define O_RDONLY        0x0000     /* read only */
#define O_WRONLY        0x0001     /* write only */
#define O_RDWR          0x0002     /* read and write */
#define O_APPEND        0x0008     /* append mode */
#define O_CREAT         0x0200     /* create file */
@

We also declare the file types:

<<kernel declarations>>=
#define S_IFIFO         0010000    /* named pipe (fifo) */
#define S_IFCHR         0020000    /* character device */
#define S_IFDIR         0040000    /* directory */
#define S_IFBLK         0060000    /* block device */
#define S_IFREG         0100000    /* regular file */
#define S_IFLNK         0120000    /* symbolic link */
#define S_IFSOCK        0140000    /* socket */
@


\item Statusliste: Array, das 256 Dateistatus-Structs enthält: 

<<our minix code>>=
#define MAX_FILES 256
struct filestat status[MAX_FILES] = { 0 };
@

\end{itemize}


We need a function that looks up a filename in the directory and returns the inode number.
Assume we want to look up the path \path!/etc/passwd!: We start with checking that this
is an absolute path (there must be a leading \path!/!). Then we scan the path until we
reach the next \path!/! (or the string terminator [[\0]]).

% If -- on your way to find a file or directory -- we cannot find an entry, we return
% the negative inode number of the last found part: that's the directory in which we
% have to create something new

<<kernel declarations>>=
int pathname_to_ino (const char *path);
@

<<our minix code>>=
void relpath_to_abspath (const char *relpath, char *abspath) {
  if (strlen(thread_table[current_task].cwd) > 1) {
    // combine cwd and relpath, add "/" in the middle
    strncpy (abspath, thread_table[current_task].cwd, 256);
  } else {
    strncpy (abspath, "", 256);
  }
  strncpy (abspath+strlen(abspath)+1, relpath, 256-strlen(abspath)-1);
  abspath[strlen(abspath)] = '/';
  printf ("absolute path: %s\n", abspath);
  return;
}

int pathname_to_ino (const char *path) {
  debug_printf ("pathname_to_ino: entered\n");
  int i;
  struct minix2_inode dirinode, inode;
  struct minix_dir_entry dentry;
  char subpath[31];   // maximum name length: 30
  char searchbuf[256];
  char *search = (char*)searchbuf;
  strncpy (search, path, 256);  // do not modify path
  int dirinode_no = 1;     // inode no. of / directory
  int next_dirinode_no;
  short final = 0;              // final = 1 if looking at final part
  
  // check absolute path
  char newpath[256];
  
  if (*search != '/') {
    /*
    if (strlen(thread_table[current_task].cwd) > 1) {
      // combine cwd and path, add "/" in the middle
      strncpy (newpath, thread_table[current_task].cwd, 256);
    } else {
      strncpy (newpath, "", 256);
    }
    strncpy (newpath+strlen(newpath)+1, search, 256-strlen(newpath)-1);
    newpath[strlen(newpath)] = '/';
    */
    relpath_to_abspath (search, newpath);
    search = newpath;
  }
 
  search++;
  
  if (*search == '\0') return 1;    // searching for / : inode 1
  
  // work until end of path reached
  while (*search != '\0') {
    i = 0;
    while (*search != '\0' && *search != '/') {
      subpath[i] = *search;
      search++; i++;
    }
    subpath[i] = '\0';  // terminate subpath string

    if (*search == '\0') final = 1;   // looking at final part of path

    // look up subpath
    debug_printf ("DEBUG: searching for subpath %s in inode %d\n", subpath, dirinode_no);

    next_dirinode_no = -1;
    for (i=0; i<32; i++) {
      // FIX ME: check more than the first 32 entries

     if (dirinode_no==-1)
       printf ("FAIL: calling read_dir_entry (%d); i = %d, subpath = %s\n", dirinode_no, i, subpath);
      
      read_dir_entry (dirinode_no, i, &dentry);
      debug_printf ("pathname_to_ino: after read_dir_entry()\n");
      if (dentry.inode != 0) {
        if (strcmp (dentry.name, subpath) == true) {
          next_dirinode_no = dentry.inode;  // found it!
          break;  // leave for loop
        }
      }
    }
    // now next_dirinode_no is either -1 (not found) or points
    // to next step
    
    if (next_dirinode_no == -1) return -1;   // not found!
    
    dirinode_no = next_dirinode_no;
    
    debug_printf ("DEBUG: subpath = %s, inode = %d\n", subpath, dirinode_no);
    if (*search != '\0') 
      search++;
    else
      break;  // finished
  } // end while
  debug_printf ("DEBUG: returning inode no %d\n", next_dirinode_no);
  return next_dirinode_no;
};
@


We also need two helper functions that give us the index of a free [[inodes[]]] and a free [[status[]]] entry. The code is similar: We loop over the respective array and check whether an entry is free. [[inodes[i]]] is free if its [[refcount]] element is 0; [[status[i]]] is free if its [[int_inode]] element is a [[NULL]] pointer.

<<our minix code>>=
int get_free_inodes_entry () {
  // return an internal inode number
  int i;
  for (i=0; i<MAX_INT_INODES; i++) {
    if (inodes[i].refcount == 0) return i;
  }
  return -1;
}

int get_free_status_entry() {
  // returns an mfd
  int i;
  for (i=0; i<MAX_FILES; i++) {
    if (status[i].int_inode == NULL) return i;
  }
  return -1;
}
@

a) In Aufgabe 13 haben Sie die Funktion [[create_null_file()]] implementiert, mit der Sie eine neue Datei mit angegebener Größe und angegebenem Dateinamen erzeugen können. Erstellen Sie eine Kopie dieser Funktion namens [[create_empty_file()]], welche weniger leistet: Sie erzeugt einfach eine leere Datei, muss also keine Datenblöcke reservieren und in [[i_zone[i]]] für alle [[i]] Nullen eintragen. Wir brauchen diese Funktion in der nächsten Übung für [[mx_write]].

b) Schreiben Sie eine Funktion [[mx_open()]], welche im Wesentlichen wie der System-Call-Wrapper [[open()]] arbeitet:

\begin{itemize}

\item Es wird der erste freie MFD verwendet (0..15). Die Nummer sei [[n]].

<<kernel declarations>>=
int mx_open (const char *path, int oflag);
int creat_empty_file (const char *path, int mode);  // later
@

<<our minix code>>=
int count_open_files = 0;  // number of open files
int count_int_inodes = 0;  // number of internal inodes in use


int mx_open (const char *path, int oflag) {
  debug_printf ("mx_open: entered\n");
  int ext_ino = pathname_to_ino (path);
  debug_printf ("DEBUG: ext_ino = %d\n", ext_ino);
  debug_printf ("mx_open: after pathname_to_ino()\n");
  if (ext_ino == -1) {
    // file not found
    if (oflag & O_CREAT != 0) {
      printf ("DEBUG: mx_open calls creat_empty_file\n");
      ext_ino = creat_empty_file (path, 0644);
    }
    else
      return (-1);  // file not found, and no O_CREAT
  }
    
  int int_ino;  // number of internal inode for this file
@

\item Zunächst werden die MFDs durchsucht:
  \begin{itemize}
  \item Fall 1: Wenn die Datei bereits mit dem MFD [[i]] geöffnet ist, wird [[status[n].int_inode]] auf [[status[i].int_inode]] gesetzt und im internen Inode [[refcount]] um 1 erhöht. (Der interne Inode wird also mehrfach genutzt.)
  
<<our minix code>>=
short file_already_open = false;
int mfd = get_free_status_entry();

int_ino = -1; 
int i;
if (count_open_files == 0) {
  int_ino = 0;  // first file to be opened
} else {
  for (i = 0; i < MAX_INT_INODES; i++) {
    if (inodes[i].ino == ext_ino) {
      file_already_open = true;
      int_ino = i;
      break;
    }
  }
  // reached end of the loop: file is not open
  if (int_ino == -1) int_ino = get_free_inodes_entry();
}

if (int_ino == -1) {
  // error: no free internal inode available
  return -1;
}

struct int_minix2_inode *inode = &(inodes[int_ino]);

// data for file descriptor
status[mfd].int_inode = inode;
status[mfd].pos       = 0;
status[mfd].mode      = oflag;  // FIX ME: check?
if (oflag == O_APPEND) {} ;

if (file_already_open) {
  <<[[mx_open]] case: file already open>>
} else {
  <<[[mx_open]] case: file not open>>
}
@

<<[[mx_open]] case: file already open>>=
inode->refcount++;   // file is opened once more
@
  
  \item Fall 2: War die Datei noch nicht geöffnet, wird das Wurzelverzeichnis durchsucht -- wenn der angegebene Dateiname gefunden wird, wird der zugehörige Inode in den zum MFD gehörenden internen Inode kopiert. (Interne Inodes sollten darum am Anfang exakt wie normale Inodes aufgebaut sein, die Zusatzfelder folgen erst dahinter.) Im internen Inode werden [[clean]] auf 1 und [[refcount]] (zunächst) auf 0 gesetzt. Speichern Sie im internen Inode auch die Nummer des ``echten'' Inodes im Dateisystem.

For reading the inode, we cast the internal inode pointer (of type
[[struct int_minix2_inode*]]) to an external inode pointer (of type 
[[struct minix2_inode*]]).

<<[[mx_open]] case: file not open>>=
// get inode from disk

// copy diskinode[ext_ino] to int_inode[int_ino]
read_inode (ext_ino, (struct minix2_inode*) inode);
inode->ino = ext_ino; // number of external inode
inode->refcount = 1;  // one user
inode->clean = 1;     // as on disk
@



  
  \end{itemize}

\item In [[status[n].pos]] wird ein geeigneter Wert (0 oder [[i_size]]) eingetragen.

\item Im internen Inode wird [[refcount]] erhöht.

\item [[status[n].mode]] nimmt den Öffnen-Modus auf. (So ist es möglich, dieselbe Datei z. B. 1x zum Lesen und 1x zum Schreiben zu öffnen -- dabei wird nur einziger interner Inode verwendet, Modus und aktuelle Lese-/Schreibposition werden aber getrennt gespeichert.)

\item Danach gibt die Funktion den Wert [[n]] zurück -- Ende.

\item Wenn das Öffnen fehlschlägt, gibt die Funktion -1 zurück. [[errno]] wird nicht gesetzt.

<<our minix code>>=
  count_open_files++;
  if (!file_already_open) count_int_inodes++;
  return mfd;
}
@

\end{itemize}


c) Ergänzen Sie eine Funktion [[mx_close()]], die das Gegenstück zu [[mx_open()]] ist, also geöffnete Dateien wieder schließt. Beachten Sie dabei, dass eine Datei mehrfach geöffnet sein kann. Der [[refcount]] wird beim Schließen dekrementiert -- wenn er den Wert 0 erreicht, soll der zugehörige interne Inode freigegeben werden. Ist [[clean]] = 0, wird vorher der ``externe Anteil'' des internen Inodes in das Dateisystem zurückgeschrieben.

We don't have to mark the inode as unused---setting its [[refcount]] to 0 does the job since that property is what we use to find a free one.

<<kernel declarations>>=
int mx_close (int mfd);
@

<<our minix code>>=
int mx_close (int mfd) {
  // printf ("DEBUG: mx_close (%d) called\n", mfd);
  struct filestat *st;
  struct int_minix2_inode *inode;
  
  if (mfd<0 || mfd>=MAX_FILES) return -1;   // wrong mfd number
  
  st = &status[mfd];
  inode = st->int_inode;
  // printf ("DEBUG: &inode = %x\n", inode);
  if (inode == NULL) return -1;             // no open file
  
  // close file
  st->int_inode = NULL;
  inode->refcount--;
  
  // usage count down to 0? Then sync inode
  if (inode->refcount == 0) {
    if (inode->clean == 0) {
      int ext_ino = inode->ino;
      write_inode (ext_ino, (struct minix2_inode*) inode);
    }    
    count_int_inodes--;
  }
  
  count_open_files--;  
  return 0;
}
@

d) Implementieren Sie eine Funktion [[mx_sync(int mfd)]], welche Änderungen am internen Inode zum MFD [[mfd]] sofort zurück schreibt und danach im internen Inode [[clean]] auf 1 setzt.

<<our minix code>>=
int mx_sync (int mfd) {
  struct filestat *st;
  struct int_minix2_inode *inode;

  if (mfd<0 || mfd>=MAX_FILES) return -1;   // wrong mfd number
  
  st = &status[mfd];
  inode = st->int_inode;
  if (inode == NULL) return -1;             // no open file
  
  if (inode->clean == 0) {
    int ext_ino = inode->ino;
    write_inode (ext_ino, (struct minix2_inode*) inode);
    inode->clean = 1;   // now it is clean
  }
}
@

e) Implementieren Sie die Funktion [[mx_lseek()]], welche dieselben Parameter wie [[lseek()]] akzeptiert. Anstelle des File Descriptors wird ein Minix File Descriptor (MFD) verwendet. Wenn der angegebene MFD gültig ist, wird die zugehörige Dateiposition geeignet gesetzt. Für erste Tests reicht es, die Variante mit absoluter Positionierung ([[whence]] = [[SEEK_SET]]) zu implementieren.

We first define the seek options:

<<kernel declarations>>=
#define	SEEK_SET	0	/* absolute offset */
#define	SEEK_CUR	1	/* relative offset */
#define	SEEK_END	2	/* EOF plus offset */
@

<<our minix code>>=
int mx_lseek (int mfd, int offset, int whence) {
  // printf ("DEBUG: mx_lseek, mfd = %d, offset = %d, whence = %d\n", mfd, offset, whence);
  struct filestat *st;
  struct int_minix2_inode *inode;

  if (mfd<0 || mfd>=MAX_FILES) return -1;   // wrong mfd number
  
  st = &status[mfd];
  inode = st->int_inode;
  if (inode == NULL) return -1;             // no open file

  if (whence<0 || whence>2) return -1;      // wrong lseek option
  
  if (st->mode == O_APPEND) return st->pos; // ignore lseek when in APPEND mode
  
  switch (whence) {
    case SEEK_SET: st->pos = offset; break;
    case SEEK_CUR: st->pos += offset; break;
    case SEEK_END: st->pos = inode->i_size + offset;
  };
  
  return st->pos;
}
@

f) Schreiben Sie eine Funktion [[mx_read()]], welche dieselben Parameter wie [[read()]] akzeptiert. Anstelle des File Descriptors wird wieder ein MFD verwendet. Diese Funktion ist komplex:

\begin{itemize}
\item Wenn die Datei nur zum Schreiben oder im Append-Modus geöffnet ist oder der angegebene MFD nicht gültig ist, gibt die Funktion direkt den Wert -1 zurück.

We put the lookup of a block number in a separate function [[fileblocktozone()]].

<<kernel declarations>>=
int mx_read (int mfd, void *buf, int nbyte);
int fileblocktozone (int blockno, struct int_minix2_inode *inode);
@


<<our minix code>>=
<<mx read>>
@


<<mx read>>=
int mx_read (int mfd, void *buf, int nbyte) {
  debug_printf ("DEBUG: mx_read: %d bytes\n", nbyte);
  struct filestat *st;
  struct int_minix2_inode *inode;

  if (mfd<0 || mfd>=MAX_FILES) return -1;   // wrong mfd number
  
  st = &status[mfd];
  inode = st->int_inode;
  if (inode == NULL) return -1;             // no open file

  if (st->mode == O_WRONLY || st->mode == O_APPEND)
    return -1;                              // cannot read from write-only file
@

\item Ansonsten muss sie die aktuelle Dateiposition berücksichtigen und zunächst bestimmen, welche (logischen) Blöcke der Datei gelesen werden müssen,

<<mx read>>=
  int startbyte = st->pos;
  if (startbyte >= inode->i_size) return 0;  // nothing to read
  int endbyte = st->pos + nbyte - 1;
  if (endbyte >= inode->i_size) {
    nbyte -= (endbyte - inode->i_size + 1);
    endbyte = inode->i_size - 1;
  }
@

Knowing which bytes we need, we can easily calculate the blocks:

<<mx read>>=
  int startblock = startbyte / BLOCK_SIZE;
  int endblock   = endbyte / BLOCK_SIZE;
  int curblock = startblock;
@

\item dann aus dem Inode die zugehörigen Blocknummern extrahieren und mit [[readblock()]] die Blöcke vom Dateisystem lesen

We need to loop over all the blocks and check for special cases.

<<mx read>>=
  uchar block[BLOCK_SIZE];
  int offset, length;
  int read_bytes = 0;
  int zone;
  while (nbyte > 0) {
    // where is the block?
    // printf ("read_logical_block (%d); ", curblock);   // debug
    zone = fileblocktozone (curblock, inode);  // SOMETHING WRONG IN THERE?
    if (zone == -1) {
      printf ("ERROR: double indirection not implemented. Use smaller files :)\n");
      return -1;
    };

    // printf ("readblock (%d)\n", zone);

    readblock (zone, (uchar*) block);
    if (curblock == startblock) {
      offset = startbyte % BLOCK_SIZE;
      length = min (nbyte, BLOCK_SIZE - offset);
    } else {
      offset = 0;
      length = min (nbyte, BLOCK_SIZE);
    }
    memcpy_debug (buf, block+offset, length);
    
    nbyte -= length;
    buf   += length;
    read_bytes += length;
    curblock++;
    st->pos += length;
  }
  return read_bytes;
}
@

The Minix V2 filesystems uses 4 byte long Integers as zone addresses,
so one indirection block (or zone) has space for
[[BLOCK_SIZE / 4]] such addresses. We'll define this number as
a constant:

<<our minix headers>>=
#define BLOCKADDRESSES_PER_BLOCK BLOCK_SIZE / 4
@

<<our minix code>>=
int fileblocktozone (int blockno, struct int_minix2_inode *inode) {
  int zone;
  int indirect_zone;
  int *zone_ptr;
  uchar indirect_block[BLOCK_SIZE];
  if (blockno < 7) {
    // the first 7 zone numbers (0..6) are in the inode:
    zone = inode->i_zone[blockno];
    debug_printf ("\nDIRECT: %d\n", zone);
  } else if (blockno >= 7 && blockno < 7+BLOCKADDRESSES_PER_BLOCK) {
    // inode holds the address of an indirection block
    // 7..
    indirect_zone = inode->i_zone[7];
    if (indirect_zone == 0) {
      // no indirection block found
      return -2;
    }
    debug_printf ("\nINDIRECTIONS IN: %d, ", indirect_zone);
    readblock (indirect_zone, (uchar *) indirect_block);
    zone_ptr = (int *) indirect_block;
    zone_ptr += (blockno - 7);    
    zone = *zone_ptr;
    debug_printf ("INDIRECT: %d\n", zone);
  } else {
    // double indirection, not implemented
    zone = -1;
  }
  return zone;
}
@



\item und schließlich die relevanten Teile in den angegebenen Puffer kopieren.

\item Schließlich muss noch die Dateiposition angepasst werden, wobei die Funktion berücksichtigen muss, dass evtl. beim Lesen das Dateiende erreicht wurde -- in dem Fall ist die Dateiposition [[i_size]].

\item Der Rückgabewert ist die Anzahl der tatsächlich gelesenen Zeichen.
\end{itemize}


The [[mx_write]] function works similar to [[mx_read]], but it must also read blocks which are only partly modified so that writing the block does not erase the parts which are not to modified. The structure is the same as in [[mx_read]], we start with some checks:

<<mx write>>=
int mx_write (int mfd, void *buf, int nbyte) {
  // debug_printf ("DEBUG: mx_write: %d bytes\n", nbyte);
  struct filestat *st;
  struct int_minix2_inode *inode;

  if (mfd<0 || mfd>=MAX_FILES) return -1;   // wrong mfd number
  
  st = &status[mfd];
  inode = st->int_inode;
  if (inode == NULL) return -1;             // no open file

  if (st->mode == O_RDONLY)
    return -1;                              // cannot write to read-only file
@

The calculation of start and end positions (and blocks) is the same as well:

<<mx write>>=
  int startbyte = st->pos;
  // if (startbyte >= inode->i_size) return 0;  // nothing to read
  int endbyte = st->pos + nbyte - 1;

  /*
  if (endbyte >= inode->i_size) {
    nbyte -= (endbyte - inode->i_size + 1);
    endbyte = inode->i_size - 1;
  }
  */
  
  int startblock = startbyte / BLOCK_SIZE;
  int endblock   = endbyte / BLOCK_SIZE;
  int curblock = startblock;
@

And the code for actually writing the blocks is just a little different from that
of [[mx_read]]:

<<mx write>>=
  uchar block[BLOCK_SIZE];
  int offset, length;
  int written_bytes = 0;
  int zone;
  while (nbyte > 0) {
    // where is the block?
    // printf ("writeblock (%d); ", curblock);   // debug
    zone = fileblocktozone (curblock, inode);
    // printf ("DEBUG: mx_write, fileblocktozone (%d) = %d\n", curblock, zone);
    if (zone == -2 || zone == 0) {
      // block does not yet exist
      zone = create_new_zone (curblock, inode);
    };

    if (zone == -1) {
      printf ("ERROR: double indirection not implemented. Use smaller files :)\n");
      return -1;
    };
    
    if (curblock == startblock) {
      offset = startbyte % BLOCK_SIZE;
      length = min (nbyte, BLOCK_SIZE - offset);
      // printf ("DEBUG: WRITE, FIRST BLOCK, curblock = %d, offset = %d, length = %d\n", curblock, offset, length);
    } else {
      offset = 0;
      length = min (nbyte, BLOCK_SIZE);
    }

    if (offset != 0 || length != BLOCK_SIZE) {
      // writing a partial block -- read first!
      readblock (zone, (uchar*) block);
    }
    memcpy (block+offset, buf, length);
    writeblock (zone, (uchar*) block);
    
    nbyte -= length;
    buf   += length;
    written_bytes += length;
    curblock++;
    st->pos += length;
    
    if (st->pos > inode->i_size)
      inode->i_size = st->pos;
  }
  
  write_inode (inode->ino, (struct minix2_inode*) inode);
  
  
  
  // printf ("inode 3\n"); read_inode (3, inode); show_inode(inode);
  // printf ("inode 4\n"); read_inode (4, inode); show_inode(inode);
  
  return written_bytes;
}
@

<<our minix code>>=
int create_new_zone (int blockno, struct int_minix2_inode *inode) {
  // printf ("DEBUG: create_new_zone (%d)\n", blockno);
  int zone = request_block ();  // new data block
  if (zone == -1) {
    debug_printf ("cannot reserve data block; disk full\n");
  }
  int indirect_zone;
  int *zone_ptr;
  uchar indirect_block[BLOCK_SIZE] = { 0 };
  if (blockno < 7) {
    // the first 7 zone numbers (0..6) are in the inode:
    inode->i_zone[blockno] = zone;
    debug_printf ("\nADD DIRECT: %d\n", zone);
  } else if (blockno >= 7 && blockno < 7+BLOCKADDRESSES_PER_BLOCK) {
    // inode holds the address of an indirection block
    // 7..
    indirect_zone = inode->i_zone[7];

    // if there is no indirection block yet, create it
    if (indirect_zone == 0) {
      // no indirection block found
      indirect_zone = request_block ();  // data block for indirections
      if (indirect_zone == -1) {
        debug_printf ("cannot reserve indirection block; disk full\n");
        clear_zmap_bit (zone);   // undo reservation of data block
        return -1;
      }
      inode->i_zone[7] = indirect_zone;
    }
    debug_printf ("\nINDIRECTIONS IN: %d, ", indirect_zone);
    readblock (indirect_zone, (uchar *) indirect_block);
    zone_ptr = (int *) indirect_block;
    zone_ptr += (blockno - 7);
    *zone_ptr = zone;   // write information about new data block
    // printf ("DEBUG: writeblock, indirect_zone = %d\n", indirect_zone);
    writeblock (indirect_zone, (uchar *) indirect_block);
    debug_printf ("ADD INDIRECT: %d\n", zone);
  } else {
    // double indirection, not implemented
    zone = -1;
  }
  return zone;
}
@

What's still missing is a way to create a new (empty) file. This 

<<mx creat>>=
int creat_empty_file (const char *path, int mode) { // later
  char abspath[256];
  if (*path != '/')
    relpath_to_abspath (path, (char*)abspath);
  else
    strncpy (abspath, path, 256);

  int i;
  int inodenr = request_inode ();
  struct minix2_inode inode = { 0 };
  for (i = 0; i<10; i++) inode.i_zone[i] = 0;
  inode.i_size = 0;
  inode.i_atime = inode.i_ctime = inode.i_mtime = 9999;
  inode.i_uid = inode.i_gid = 1000;
  inode.i_nlinks = 0;
  inode.i_mode = S_IFREG | mode;
  write_inode (inodenr, &inode);
  // Verzeichniseintrag anlegen
  write_link (inodenr, abspath);
  return inodenr;
}
@


<<our minix code>>=
<<mx creat>>
<<mx write>>
@



\subsubsection{Working Directory, Relative Paths}

We want processes to have a ``current working directory'', so we add an 
entry to the thread control block structure:

<<more TCB entries>>=
char cwd[256];
@

To query and set this value, we will need two system calls
[[getcwd]] and [[chdir]]:

Now [[getcwd]] just copies a string, while [[chdir]] needs to check
whether the argument is a valid directory:

<<kernel declarations>>=
char *getcwd (char *buf, int size);
boolean file_exists (const char *path);
boolean file_is_directory (const char *path);
int chdir (const char *path);
@

<<kernel functions>>=
char *getcwd (char *buf, int size) {
  strncpy (buf, thread_table[current_task].cwd, size);
  return buf;
}

boolean file_exists (const char *path) {
  int ino = pathname_to_ino (path);
  if (ino == -1) return false;
  return true;
}

boolean file_is_directory (const char *path) {
  int ino = pathname_to_ino (path);

  // exists?
  if (ino == -1)
    return false;

  // is directory?
  struct minix2_inode inode;
  read_inode (ino, &inode);
  if ((inode.i_mode & S_IFDIR) == 0)
    return false;
    
  return true;
}

int chdir (const char *path) {
  char abspath[256];
  // check relative/absolute path
  if (*path != '/')
    relpath_to_abspath (path, abspath);
  else
    strncpy (abspath, path, 256);
    
  if (file_is_directory (abspath)) {
    strncpy (thread_table[current_task].cwd, abspath, 256);
    return 0;
  } else {
    return -1;  // error
  }
}
@

As usual, we define and register system call functions:

<<syscall functions>>=
void syscall_getcwd (struct regs *r) {
  // ebx: buffer for directory
  // ecx: maximum length of path
  r->eax = (uint)getcwd ((char*)r->ebx, r->ecx);
}

void syscall_chdir (struct regs *r) {
  // ebx: new directory
  r->eax = chdir ((char*)r->ebx);
}
@

<<initialize syscalls>>=
insert_syscall (__NR_getcwd, syscall_getcwd);
insert_syscall (__NR_chdir, syscall_chdir);
@


\subsubsection{Linking and Unlinking}

Unix systems have no [[delete]] or [[erase]] system calls for
files---instead there is an [[unlink]] system call which removes
a directory entry (it deletes the link from a filename to an inode
in that directory). Only if the last name was deleted,
[[unlink]] will also delete the file, which means freeing all data
blocks and the inode.

The opposite operation is creating a hardlink: This creates a new
name (a new link from a filename to an inode in some directory).

Both operations modify an inode's link count: That is where the
filesystem keeps track of how many names were given to a file.

We will start with the [[link]] operation since it is simpler.

<<kernel declarations>>=
int mx_link(const char *path1, const char *path2);
@

<<our minix code>>=
int mx_link(const char *path1, const char *path2) {
  char abspath1[256];
  char abspath2[256];

  // path1: make absolute path if necessary:
  if (*path1 != '/')
    relpath_to_abspath (path1, abspath1);
  else
    strncpy (abspath1, path1, 256);
    
  // check path1 exists
  if (!file_exists(abspath1)) {
    return -1;   // path1 does not exist
  }
  
  // check path1 is not a directory
  if (file_is_directory(abspath1)) {
    printf ("ln: warning: %s is a directory. This option will be removed.\n");
  }
  
  // path2: make absolute path if necessary:
  if (*path2 != '/')
    relpath_to_abspath (path2, abspath2);
  else
    strncpy (abspath2, path2, 256);
  
  // check path2 does NOT exist
  if (file_exists(abspath2)) {
    return -1;   // path2 already exists; no forced linking
  }
  
  // everything ok now :)
  int ino = pathname_to_ino (abspath1);
  write_link (ino, abspath2);
  return 0;
}
@

Here is the code for the system call:

<<syscall functions>>=
void syscall_link (struct regs *r) {
  // ebx: original name
  // ecx: new name
  r->eax = (uint)mx_link ((char*)r->ebx, (char*)r->ecx);
}
@

<<initialize syscalls>>=
insert_syscall (__NR_link, syscall_link);
@


Unlinking is similar as long as at least one filename (one link)
remains:

<<kernel declarations>>=
int mx_unlink (const char *path);
@

<<our minix code>>=
int mx_unlink (const char *path) {
  char abspath[256]; char dir[256]; char base[30];
  char ind_block[BLOCK_SIZE];
  struct minix_dir_entry dentry;
  int inodenr, dir_inodenr;
  int i;
  boolean found;

  // make absolute path if necessary:
  if (*path != '/')
    relpath_to_abspath (path, abspath);
  else
    strncpy (abspath, path, 256);

  // check path1 exists
  if (!file_exists(abspath)) {
    printf ("rm: file does not exist\n");
    return -1;   // error: path does not exist
  }
  
  inodenr = pathname_to_ino (path);
  
  printf ("DEBUG: inodenr is %d\n", inodenr);
  
  struct minix2_inode inode;
  read_inode (inodenr, &inode);

  // split path into dir and base
  splitpath (abspath, dir, base);
  
  printf ("DEBUG: abspath = %s, dir = %s, base = %s, ", abspath, dir, base);
  
  dir_inodenr = pathname_to_ino (dir);
  
  printf ("dir_inodenr is %d\n", dir_inodenr);

  // delete entry in directory
  found = false;
  for (i=0; i<32; i++) {
    read_dir_entry (dir_inodenr, i, &dentry);
    if ( dentry.inode==inodenr && strcmp(dentry.name, base) ) {
      dentry.inode = 0;
      memset (dentry.name, 0, 30);
      found = true;
      write_dir_entry (dir_inodenr, i, &dentry);
      break;  // search finished
    }
  }
  if (found==false) return -1;  // error: not found in directory
  
  
  inode.i_nlinks--;   // one name less
  
  if (inode.i_nlinks == 0) {
    <<free this inode>>
  }
  
  write_inode (inodenr, &inode);

  return 0;
}
@

Finally we must take care of the case when the last link has been
removed---then we have an inode with a reference count of 0, and
that means, the file is truly to be deleted: We need to mark its
data blocks as free (including an indirection block, if it exists)
and also mark the inode as free.

<<free this inode>>=
// free direct blocks
for (i=0; i<7; i++) {
  clear_zmap_bit (inode.i_zone[i] - 33);  // mark data block as free
  inode.i_zone[i] = 0;
}

// free indirect blocks
if (inode.i_zone[7] != 0) {
  // indirection block exists
  readblock (inode.i_zone[7], ind_block);
  unsigned int *zoneno;
  zoneno = (unsigned int*)ind_block;      // cast to uint*
  while (*zoneno != 0) {
    clear_zmap_bit (*zoneno - 33);        // mark data block as free
    zoneno++;
  }
  clear_zmap_bit (inode.i_zone[7] - 33);  // mark indir. block as free
  inode.i_zone[7] = 0;
}

// free inode
printf ("Freeing inode %d\n", inodenr);
clear_imap_bit (inodenr);
@

The system calls:

<<syscall functions>>=
void syscall_unlink (struct regs *r) {
  // ebx: pathname
  r->eax = (uint)mx_unlink ((char*)r->ebx);
}
@

<<initialize syscalls>>=
insert_syscall (__NR_unlink, syscall_unlink);
@



Unix systems also know a second type of link, the symbolic or soft
link (short: symlink). While this name reminds of the (hard) links for which we have just
provided the implementation, and even the same Unix tool ([[ln]]) handles
both hard and soft links, these two links have nothing in common.

A symbolic link is a special file which contains a path name as data.
When you disable the treatment of symbolic links on a Unix system
and try to read such a file, all you get is the stored path name: Figure
\ref{fig:symlink-as-file} shows how \UlixI{} displayed the content of a 
symbolic link before symlinks were implemented: [[ulix.symlink]] was
created by executing

{\small
\begin{verbatim}
ln -s ulix.h ulix.symlink
\end{verbatim}
}

\noindent
on a Linux system which had loop-mounted the Minix filesystem: As you can
see from the letter [[l]] at the start of the file entry, \UlixI{} already
recognized the file type but did not know better than to output the
contents of the file's first data block.

\begin{figure}[h]
\centering
\includegraphics[width=13cm]{pics/symlink-as-file-invert.png}
\caption{\UlixI{} version 0.08 displays the contents of a symbolic link---in that version symbolic links were not yet implemented. (The image was inverted for better readability.)}
\label{fig:symlink-as-file}
\end{figure}


As you can see, creating a symlink is easy: We just write the link target
into a data block and mark the file as symlink:

<<kernel declarations>>=
int mx_symlink (char *path1, char *path2);
@

<<our minix code>>=
int mx_symlink (char *path1, char *path2) {
  char abspath[256];
  if (*path2 != '/')
    relpath_to_abspath (path2, (char*)abspath);
  else
    strncpy (abspath, path2, 256);
    
  int fd = mx_open (abspath, O_WRONLY | O_CREAT);
  if (fd==-1) return -1;   // error: cannot create file
  mx_write (fd, path1, strlen(path1));
  mx_close (fd);
@

(Note that we do \emph{not} write a terminating [[\0]] character: The
link target need not be terminated, the length of the filename is simply
the symlink's file size.)

We're not finished yet---now we have a regular file with the link target in
the first data block. We need to turn it into a symlink:

<<our minix code>>=
  int inode_nr = pathname_to_ino (abspath);
  struct minix2_inode inode;
  read_inode (inode_nr, &inode);
  inode.i_mode = S_IFLNK | 0777;
  write_inode (inode_nr, &inode);
  return 0;  // OK.
}
@

We've set the symlink's access rights to 0777 ([[rwxrwxrwx]]) which is
the default on Linux machines. The rights do not matter much anyway since
reading, writing, or executing the linked file requires the target to
grant the needed access permissions.

Here's the corresponding system call:

<<syscall functions>>=
void syscall_symlink (struct regs *r) {
  // ebx: target file name
  // ecx: symbolic link name
  r->eax = (uint)mx_symlink ((char*)r->ebx, (char*)r->ecx);
}
@

<<initialize syscalls>>=
insert_syscall (__NR_symlink, syscall_symlink);
@


What's left for us is to modify the [[mx_open]] function, since it shall
not open the link file itself but instead follow the symlink and open
the referenced file.

<<mx open: follow symlink>>=
// TO DO
@

IDEA: let [[mx_open]] open the symlink (as a file), read the target
name, call [[mx_close]] (from inside [[mx_open]]!), then recursively
do [[return mx_open(target,...)]] with the target name.



\subsubsection{Making and Unmaking Directories}

What's left is code for creating and deleting directories. Similar to
symlinks, directories are just a special type of file, and we already
know how to modify existing directories.

Deleting a directory means to free the data blocks that had been used
by it and to remove its entry in the super-directory (the directory 
which is one step close to the filesystem root and contains it)---this
task is already handled by the [[mx_unlink]] function, so we need no
further code in the kernel. Actually, we could provide an [[mx_rmdir]]
function which is simpler than [[mx_unlink]] since directories must 
not be hard-linked: if we remove a directory, we always remove its
inode.

For making a directory, we could do this as the logical three-step-procedure
that is involded:

\begin{itemize}
\item create the (empty) directory,
\item within the new directory, create a hard link [[.]] to itself,
\item and also create a hard link [[..]]---either to the super-directory
or to [[/]] in case of the root directory [[/]]. But the kernel will
never create a root directory (that's handled by the user mode tool 
[[mkfs.minix]])
\end{itemize}

Also, all new directories look identical except for the two hard links 
[[.]] and [[..]], so we will keep our task simple by defining what the
contents of a new directory look like (data-bock-wise) and how to
update the inode numbers in the [[.]] and [[..]] entries.

The ``.''' character (dot) has the ASCII value 46, or 0x2E in hexadecimal
code. A hexdump of the data area of a Minix filesystem shows the following
contents for an empty directory:

{\small
\begin{verbatim}
$ hexdump -C /tmp/minixdata.img
[...]
00013000  08 00 2e 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013020  01 00 2e 2e 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013030  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
[...]
\end{verbatim}
}

This shows a directory on the top level with inode number 8. The first two lines
contain the directory entry for [[.]] (pointing to itself: [[08 00]]) and the
directory entry for [[..]] (pointing to the root directory which has inode number
1 ([[01 00]]).

The size of such an entry is 64:

{\small
\begin{verbatim}
$ ls -ld /mnt/minix/empty
drwxr-xr-x 2 esser esser 64 Jul 17 16:13 /mnt/minix/empty
\end{verbatim}
}

<<empty directory declaration>>=
char empty_directory[64] = 
  "\0\0.\0\0\0\0\0"   "\0\0\0\0\0\0\0\0"  // first entry, "."
  "\0\0\0\0\0\0\0\0"  "\0\0\0\0\0\0\0\0"
  "\0\0..\0\0\0\0"    "\0\0\0\0\0\0\0\0"  // second entry, ".."
  "\0\0\0\0\0\0\0\0"  "\0\0\0\0\0\0\0\0";
@

The inode numbers go into positions 0--1 and 32--33 of this string.

Thus, the code for creating a directory is as follows:

<<kernel declarations>>=
int mx_mkdir(const char *path, int mode);
@

<<our ulix code>>=
<<empty directory declaration>>

int mx_mkdir(const char *path, int mode) {
}
@



\section{Disk I/O}
\label{sec:disk-i-o}

\subsection{Serial Hard Disk}

Since talking to a floppy disk controller (FDC) or an ATA hard disk
controller is quite complicated, we simplify our life by emulating
a disk. This requires that we 

\begin{itemize}
\item run \UlixI{} in a virtual machine which
supports two serial ports and that we 
\item add an external program which
connects to the (virtual) second serial port, accepting
commands and sending data back and forth.
\end{itemize}

It takes a little more than that, though, since we want to emulate
the ``normal'' behavior of a disk controller. In real life,
transfers use DMA (direct memory access). At the lowest level,
the disk driver creates a [[DMA_READ]] or [[DMA_WRITE]] message
and sends it to the controller. By itself, neither of these is a
blocking action, since the disk controller will handle the
transfer of data from the hard disk to memory (reading) or from
memory to the disk (writing) independently of the CPU which
continues executing. However, the process which initiated the
transfer must be blocked anyway, since reading from the disk will
take a while (and writing might not be safe if it continued and
possibly changed the data which are currently written). After
completion the disk controller creates an interrupt, the
corresponding interrupt handler starts and puts the process back
into the ready queue.

The actual DMA transfers work with physical memory addresses, so
code using DMA must always know where data is or will be stored in
physical memory.

Our serial hard disk works differently, it uses [[in]] and [[out]]
commands to read or write single bytes through the serial port,
and it can use virtual memory.
In a simple implementation of this method the process would never
block, it would just take a while to send or receive the data,
and the scheduler would switch back and forth between this process
and others.

In order to emulate ``proper'' disk controller behavior we take
the following steps:

\begin{itemize}
\item Each time that a process starts a disk read/write operation,
we create a special buffer for this transfer (which knows what 
data to send in what direction) and put it in a disk queue; we
then block the queue. We limit the queue size so that no more
than 100 processes may create an entry at the same time (the 101st
process would fail and exit).

\item The timer interrupt regularly activates the timer handler,
and besides updating the ticks variable [[system_ticks]] and
checking if the scheduler needs to be called, we also let it
check whether there is an active buffer in the disk queue. If so,
it sends or receives a few bytes via the serial port.

\item Note that the sending of data via the serial port can be
demanded at once, while receiving depends on the other side
(our external process). When the other side sends a byte, it
causes an interrupt for the serial port, and inside the \UlixI{}
interrupt handler we fill a different buffer with that byte.
So when ``reading'' in the timer handler, we don't actually
talk to the serial port, but instead just copy data from one
buffer to another.

\item We do not allow a read and a write operation at the same
time, since this would overcomplicate matters. Instead at each
moment, we either read a whole sector, write one, or do not
access the serial disk at all.

\item We add extra functions for non-blocking data transfer,
because when we let the kernel (not processes) access the disk,
we have nothing that we can block. Since this is the easier
type of transfer, we start with it.

\item If the kernel wants to read/write while there are buffer
entries belonging to processes, it will have to wait until
those are serviced. This could be optimized by changing the
protocol between \UlixI{} and the external process (basically
suspending process-caused transfers in order to favor a
kernel-caused one).
\end{itemize}


We start with defining the buffer (which we create as a ring buffer):

<<kernel declarations>>=
#define SECSIZE 1024

struct serial_disk_buffer_entry {
  int pid;                        // process ID; -1 if kernel
  short status;                   // New, Transfer, Finished, see BUF_STAT_*
  short direction;                // 100 = read, 101 = write
  uint secno;                     // sector number
  uint address;                   // memory address (in the process' address space)
  unsigned char sector[SECSIZE];  // 1024 bytes
};

#define BUF_STAT_NEW      0
#define BUF_STAT_TRANSFER 1
#define BUF_STAT_FINISHED 2
#define BUF_READ          100
#define BUF_WRITE         101

struct serial_disk_buffer_entry serial_disk_buffer[100];

int serial_disk_buffer_start = 0;   // initialize start and end of buffer usage
int serial_disk_buffer_end   = 0;   // interval in use is [start,end[, 
                                    // [0,0[ is empty
@

This way we can always check whether the buffer is empty by testing if
[[serial_disk_buffer_start]] equals [[serial_disk_buffer_end]].

Next we provide functions with which we can manage and query the
buffer. The first one enters a new entry in the buffer:

<<kernel functions>>=
int serial_disk_enter (int pid, short direction, uint secno, uint address) {
  // TODO: lock
  
  // check if buffer is full
  if ( (serial_disk_buffer_end+1) % 100 == serial_disk_buffer_start )
    return -1;   // fail
  
  struct serial_disk_buffer_entry *entry;
  entry = &serial_disk_buffer[serial_disk_buffer_end];
  entry->status = BUF_STAT_NEW;
  entry->pid = pid;
  entry->direction = direction;
  entry->secno = secno;
  entry->address = address;
  
  short tmp = serial_disk_buffer_end;
  serial_disk_buffer_end = (serial_disk_buffer_end+1) % 100;
  // TODO: unlock
  
  return tmp;   // tell the caller what entry number we used
}
@

The next function just removes the first entry of the (non-empty) buffer
if it is marked as finished; it then just moves the start
variable ahead:

<<kernel functions>>=
void serial_disk_remove_top () {
  if ( (serial_disk_buffer_start != serial_disk_buffer_end) &&
       (serial_disk_buffer[serial_disk_buffer_start].status == BUF_STAT_FINISHED) 
     ) {
    serial_disk_buffer_start++;
    serial_disk_buffer_start %= 100;
  }
  return;
}
@

Now it is time to provide the non-blocking functions for reading and writing.
We combine them in one function which does the appropriate thing, based on
the buffer entry's [[direction]] field. The function takes no arguments since
it finds all the necessary information in the buffer entry.

<<kernel declarations>>=
volatile int serial_disk_reader = 0;   // are we currently reading?
@

<<kernel functions>>=
void serial_disk_send_sector_number (uint secno) {
  uart2putc ((unsigned char)(secno%256));  // lowest byte
  secno /= 256;
  uart2putc ((unsigned char)(secno%256));  // 2nd lowest byte
  secno /= 256;
  uart2putc ((unsigned char)(secno%256));  // 3rd lowest byte
  secno /= 256;
  uart2putc ((unsigned char)(secno%256));  // highest byte
  return;
}

int serial_disk_non_blocking_rw () {
  if (serial_disk_buffer_start == serial_disk_buffer_end)
    return -1;   // buffer is empty
  
  struct serial_disk_buffer_entry *entry;
  entry = &serial_disk_buffer[serial_disk_buffer_start];
  
  if (entry->direction == BUF_WRITE) {
    // write
    uart2putc (CMD_PUT);
    serial_disk_send_sector_number (entry->secno);
    unsigned char *addressptr;
    addressptr = (char*) (entry->address);
    int i;
    for (i=0; i<1024; i++) {
      uart2putc (*addressptr);
      addressptr++;
    };
    
    entry->status = BUF_STAT_FINISHED;
    serial_disk_buffer_start++;
    serial_disk_buffer_start %= 100;
  } else if (entry->direction == BUF_READ) {
    // read
    uart2putc (CMD_GET);
    serial_disk_send_sector_number (entry->secno);
    serial_disk_reader = 1;  // we're in read mode,
       // this value gets changed in the IRQ handler
    
    // wait for data and show it... BEFORE CHANGING buffer_start
    // printf ("waiting... ");
    while (serial_disk_reader == 1) asm ("hlt");
    // printf (" done waiting.\n");
        
    entry->status = BUF_STAT_FINISHED;
    // DEBUG, // printf ("%s\n", entry->sector);
    serial_disk_buffer_start++;
    serial_disk_buffer_start %= 100;
    // copy buffer to target memory location
    memcpy ((char*)(entry->address), (char*)&(entry->sector), SECSIZE);
  }
}
@

Next we combine our functions to provide blocking read and write
functions for the kernel:

<<kernel declarations>>=
int kernel_read_sector (int secno, char* buf);
int kernel_write_sector (int secno, char* buf);
@

<<kernel functions>>=
int kernel_read_sector (int secno, char* buf) {
  // printf ("DEBUG FS: kernel read sector %d\n", secno);
  serial_disk_enter (-1, BUF_READ, secno, (uint)buf);
  serial_disk_non_blocking_rw ();
}

int kernel_write_sector (int secno, char* buf) {
  // printf ("DEBUG FS: kernel write sector %d\n", secno);
  serial_disk_enter (-1, BUF_WRITE, secno, (uint)buf);
  serial_disk_non_blocking_rw ();
}
@

We start with defining a few commands:

<<serial-hd/serial-hd-controller.h>>=
// Commands for the serial hard disk controller}
#define CMD_STAT   1   // status query
#define CMD_GET    2   // GET a sector (1024 bytes)
#define CMD_PUT    3   // PUT a sector (1024 bytes)
#define CMD_NUMSEC 4   // query: how many sectors?
#define CMD_TERM   99  // terminate controller
@

which will be used both in the \UlixI{} code as well as
in the external controller program.

<<kernel declarations>>=
<<serial-hd/serial-hd-controller.h>>
@


We need to initialize the serial disk by asking its
controller how many sectors it has:

<<kernel functions>>=
void serial_disk_init () {
  uart2putc (CMD_STAT);

}
@





\subsubsection{The external controller process}

This is a simple program:

<<serial-hd/serial-hd-controller.c>>=
#include <fcntl.h>        // open()
#include <sys/types.h>    // socket()
#include <sys/socket.h>   // socket()
#include <netinet/in.h>   // socket()
#include <unistd.h>       // close()
#include <string.h>       // bzero()
#include <stdio.h> 
#include <unistd.h>       // lseek: SEEK_SET

#include "serial-hd-controller.h"

int socks;                // socket descriptor for ULIX connection
int fd = -1;              // file descriptor
int numsec = -1;          // number of sectors (1024 bytes) in disk image

#define SECSIZE 1024

unsigned char sector[SECSIZE];

void readsocket (unsigned char* buf, short len) {
  // We use this instead of recv(), since recv() does not always
  // read the expected number of bytes.
  int total = 0;
  while (total < len) {
    total += recv (socks, buf+total, len-total, 0);
  };
  return;
};

void openfile () {
  fd = open ("minix1.img", O_RDWR);
  numsec = 2880;
  return;
};

void readsect (int i) {
  int res;
  // get sector from disk image
  lseek (fd, i*SECSIZE, SEEK_SET);
  res = read (fd, &sector, SECSIZE);
  // send it to ULIX
  send(socks, &sector, SECSIZE, 0);
};

void writesect (int i) {
  int total = 0;
  int sent;
  // char *ptr = (char*)&sector;
  readsocket ((unsigned char*) &sector, SECSIZE);
  // write it to disk image
  lseek (fd, i*SECSIZE, SEEK_SET);
  write (fd, &sector, SECSIZE);
};

void closefile () {
  close (fd);
  fd = -1; numsec = -1;
  return;
}

int main(void) {
  openfile ();   // open disk image

  /* connect to TCP port 4444 (localhost) */
  socks = socket(AF_INET, SOCK_STREAM, 0);
  struct sockaddr_in serveraddr;
  bzero(&serveraddr, sizeof(serveraddr));
  inet_pton(AF_INET, "127.0.0.1", &(serveraddr.sin_addr));
  serveraddr.sin_family = AF_INET;
  serveraddr.sin_port = htons(4444);

  /* Create connection */
  connect(socks, (struct sockaddr*) &serveraddr, sizeof(serveraddr));

  unsigned char cmd_type;
  int sectornumber;

  setbuf (stdout, 0);

  while (1) {
    readsocket (&cmd_type, 1);
    switch (cmd_type) {
      case CMD_STAT:
        printf ("ULIX asked for status\n");
        break;
      case CMD_GET:
        readsocket ((unsigned char*)&sectornumber, 4);
        printf ("ULIX asked get %d\n", sectornumber);
        readsect (sectornumber);
        break;
      case CMD_PUT:
        readsocket ((unsigned char*)&sectornumber, 4);
        printf ("ULIX asked put %d\n", sectornumber);
        writesect (sectornumber);
        break;
      case CMD_TERM:
        printf ("ULIX terminated connection. Quitting.\n");
        goto ende;
      default:
        printf ("ERROR in Command from ULIX\n");
    };      
  } 

  ende:
  /* Close connection */
  close (socks);
  closefile ();
  return;
}
@

In order to connect the external process to [[qemu]] (running \UlixI{}), we
start [[qemu]] as follows:

<<qemu invocation>>=
qemu -m 64 -fda ulixboot.img -d cpu_reset -s -serial mon:stdio \
-serial tcp::4444,server
@

Note that there are two [[-serial]] arguments; the first one connects
COM1 with the terminal from which [[qemu]] was started; the second one
connects COM2 with a TCP server on port 4444. That's the one our external
program is going to connect to.




\subsection{The Floppy Controller}

We define a [[floppy_queue]] which will contain processes waiting
for a floppy access operation to finish:

<<kernel global variables>>=
blocked_queue floppy_queue;   // processes which wait for the floppy
@

and we have to initialize this queue:

<<initialize system>>=
floppy_queue.next = floppy_queue.prev = 0;
@

Processes that access a floppy disk drive will wait on this queue,
and the interrupt handler will wake up these processes when the
operation was completed.

For example, when reading from an open file, [[read]] will call
[[fdc_read_sector]] which in turn calls [[fdc_command]]. 

The last function potentially calls [[fdc_reset]], and it will
call further functions all of which call [[fdc_wait_interrupt]].

[[wait_fdc_interrupt]] actually puts the process to sleep via
[[fdc_sleep]] until an interrupt occurs.

For accessing the floppy disk controller we use code from
Tudor Hulubei's Thix Operating System \cite{Hulubei:1995:Thix} which
is GPL-2-licensed.

<<floppy declarations>>=
#define ENXIO           6               /* Device not configured */
#define EBUSY           16              /* Device / Resource busy */
#define EINVAL          22              /* Invalid argument */
#define ESPIPE          29              /* Illegal seek */

#define PANIC printf

#define min(a,b) ((a) <= (b) ? (a) : (b))
#define max(a,b) ((a) >= (b) ? (a) : (b))

#define HZ 100
/* CHECK THIS VALUE! */


/**** from gnu/types.h ****/
typedef unsigned short __dev_t;
typedef long int __off_t;	/* Type of file sizes and offsets.  */


/**** from ioctl.h ****/
#define IOCTL_GETBLKSZ  0x00005480   /* Get device block size.  */
#define IOCTL_GETDEVSZ  0x00005481   /* Get device size (in no. of blocks).  */

/**** from buffer.h ****/
typedef struct {
  unsigned block         : 24,
           busy          : 1,
           in_demand     : 1,
           delayed_write : 1,
           valid         : 1,
           dedicated     : 1;

  __dev_t device;
  unsigned short size;

  unsigned char *address;

  unsigned short hprev;
  unsigned short hnext;

  unsigned short lprev;
  unsigned short lnext;

  unsigned short next;
  unsigned short __fill;
} buffer_t;

#define buf_address(buf_no)     buf_vect[buf_no].address


buffer_t *buf_vect;    /* from buffer.c */


/**** from include/thix/blkdrv.h ****/
typedef struct tag_br {
/*  int kid;    */              /* Kernel ID of the process.  */
    int blksz;                  /* File system block size.  */
    int block;                  /* First block. -1 means unused request.  */
    int nblocks;                /* Number of blocks.  */
    int buf_no;                 /* A list of buffers to receive data.  */
    struct tag_br *next;        /* Next request in the request list.  */
} blk_request;


/**** from dma.h ****/
#define DMA_CHANNELS            0x08

#define DMA0_STATUS             0x08
#define DMA0_INIT               0x0A
#define DMA0_MODE               0x0B
#define DMA0_FLIPFLOP           0x0C

#define DMA1_STATUS             0xD0
#define DMA1_INIT               0xD4
#define DMA1_MODE               0xD6
#define DMA1_FLIPFLOP           0xD8

#define DMA_READ_MODE           0x44
#define DMA_WRITE_MODE          0x48
#define DMA_VERIFY_MODE         0x40

/**** from floppy.h ****/

typedef int semaphore;   /* REMOVE THIS LATER */
typedef struct {         /* REMOVE THIS LATER */
  int in_use;                 /* In use flag.  */
  int mp;                     /* Index in mpt[].  */
  semaphore sync_mutex;       /* Semaphore used at sync time.  */
} minor_info;

#define ERR_BADREQ      error[0]

static char *error[] =
{
    "bad request",
};

#define WAIT_DEVICE_IO          54

#define FLOPPY_OUTPUT                   0x3f2

#define FLOPPY_CONTROLLER_ENABLE        0x04
#define FLOPPY_DMAINT_ENABLE            0x08

#define FLOPPY_STATUS                   0x3f4

#define FLOPPY_CONTROLLER_BUSY          0x10
#define FLOPPY_DMA_MODE                 0x20
#define FLOPPY_DIRECTION                0x40
#define FLOPPY_MASTER                   0x80
#define FLOPPY_NEW_BYTE                 (FLOPPY_MASTER         |   \
                                         FLOPPY_DIRECTION      |   \
                                         FLOPPY_CONTROLLER_BUSY)

#define FLOPPY_COMMAND                  0x3f5

#define FLOPPY_READ                     0xe6
#define FLOPPY_WRITE                    0xc5
#define FLOPPY_FORMAT                   0x4d
#define FLOPPY_RECALIBRATE              0x07
#define FLOPPY_SEEK                     0x0f
#define FLOPPY_SENSE                    0x08
#define FLOPPY_SPECIFY                  0x03

#define FLOPPY_RATE                     0x3f7
#define FLOPPY_INPUT                    0x3f7

#define FLOPPY_CHANGE_LINE              0x80
#define FLOPPY_CHANNEL                  0x02
#define FLOPPY_DTL                      0xFF

#define FLOPPY_SPEC2                    0x06

#define MAX_FLOPPY_RESULTS              0x07
#define MAX_FLOPPY_ERRORS               0x08

#define FLOPPY_TYPES                    0x03

#define TEST_BITS                       0xf8
#define SEEK_OK                         0x20
#define TRANSFER_OK                     0x00
#define WRITE_PROTECTED                 0x02

#define INVALID_TRACK                   -1

#define FDC_BLKSZ                       512

#define MAX_FDCS                        2


/*
 * fdc_buf is hard coded because the DMA needs it between 64k boundaries.
 * See vm_init() in mm.c for details.
 */

static char *fdc_buf = (char *)0x9a800;

static int  fdc_getresults(void);
static void fdc_out(unsigned char data);
static void fdc_surprise(void);

typedef struct {
  int total_sectors;
  int tracks;
  int sectors;
  int sectorsize;
  int trackstep;
  int rate;
  int gap;
  int spec1;
} struct_fdd_type;

typedef struct {
  int present;
  int calibrated;
  int motor;
  int current_track;
  int type;
} struct_fdd;

static int fdc_cmd;
static int fdc_drive;
static int fdc_track;
static int fdc_head;
static int fdc_sector;
static int fdc_nsects;
@

We use two mutexes to protect access to the floppy controller:

<<floppy declarations>>=
static semaphore fdc_oc_mutex = 1;
static semaphore fdc_rw_mutex = 1;
lock fdc_oc_lock;  // ULIX lock!
lock fdc_rw_lock;  // ULIX lock!

static volatile int fdc_ticks                  = 0;
static volatile int fdc_timeout                = 0;
static volatile int fdc_need_reset             = 0;
static volatile int fdc_waits_interrupt        = 0;
static volatile int fdc_ticks_till_motor_stops = 0;

// Es gibt auch 3.84 MB grosse Floppies, das Format ist wie
// bei den 2.88-ern, aber mit 48 statt 36 Sektoren, siehe
// http://www.infodrom.north.de/~joey/Linux/Tips+Tricks/floppy288.html


static char *fdd_drive_name[6] = {
  "not installed",
  "360K (not supported)",
  "1.2M",
  "720K (not supported)",
  "1.44M",
  "2.88M"
};

// muss fuer 2.88M evtl. noch die drive rate anpassen??

static struct_fdd_type fdd_type[FLOPPY_TYPES] = {
  { 80*15*2, 80, 15, 2, 0, 0, 0x1B, 0xDF },           /* 1.2M   */
  { 80*18*2, 80, 18, 2, 0, 0, 0x1B, 0xCF },           /* 1.44M  */
  { 80*36*2, 80, 36, 2, 0, 0, 0x1B, 0xAF },           /* 2.88M  */
};

static struct_fdd_type *current_fdd_type;

static struct_fdd fdd[2] = {
  { 0, 0, 0, INVALID_TRACK, 0 },
  { 0, 0, 0, INVALID_TRACK, 0 }
};

static struct_fdd *current_fdd;

static unsigned char fdc_results[MAX_FLOPPY_RESULTS];
static unsigned char current_OUTPUT;

static minor_info fdc_minor_info[2] = {
  { 0, 0, 1 },
  { 0, 0, 1 },
};


/*  RE-ENABLE THIS LATER?
static block_driver fdc_driver = {
  "floppy disk",
  fdc_open,
  fdc_close,
  fdc_read,
  fdc_write,
  NULL,
  fdc_ioctl,
  NULL,
  fdc_lseek,
  fdc_timer,
  FDC_MAJOR,
  FDC_IRQ,
  BLK_DRV,
  2,
  fdc_minor_info,
};
*/
@



We need [[fdc_sleep]] and [[fdc_wakeup]], so here's simple code for non-process-mode.

<<kernel declarations>>=
short int fdc_is_busy = false;
@

<<kernel functions>>=
void fdc_sleep () {
  if ((current_task > 1) && scheduler_is_active) {
    // block process
    /// asm ("sti");
    /// while (fdc_is_busy == true) debug_printf("-");   // wait for other FDC operation
    /// asm ("cli");
    fdc_is_busy = true;
    thread_table[current_task].state = TSTATE_WAITFLP;
    remove_from_ready_queue (current_task);
    add_to_blocked_queue (current_task, &floppy_queue);
      
    // try: active waiting
    /*
    ENABLE_SCHEDULER;
    asm("sti");
    while ( thread_table[current_task].state == TSTATE_WAITFLP ) ;
    */
    
    // calling yield (via syscall 66)
    debug_printf ("fdc_sleep going to call yield()\n");
    asm ("sti");
    asm {
      mov eax, 66;
      int 0x80;     // here it crashes??
    }
  }
  fdc_is_busy = false;
  return;
};
@

We expect floppy operations to complete in the same order in which they were
started, so for [[fdc_wakeup]] we just wake the first process in the queue.

ACTUALLY WE WAKE ALL OF THEM -- WHY?

<<kernel functions>>=
void fdc_wakeup () {
  thread_id start_pid = floppy_queue.next;
  if (start_pid != 0) {
    // only if there are queue entries...
    thread_id search_pid = start_pid;
    do {
      // TODO: WARUM TESTE ICH HIER AUF cur_vt?
      // if (thread_table[search_pid].terminal == cur_vt) {
      if (true) {
        thread_table[search_pid].state = TSTATE_READY;
        deblock (search_pid, &floppy_queue);
        break;
      } else {
        search_pid = thread_table[search_pid].next;
      }
    } while (search_pid != start_pid && search_pid != 0);
  }
  return;
}
@

The [[fdc_timer]] gets called from the timer handler, so we need to 
declare it here:

<<kernel declarations>>=
void fdc_timer(void);
@

We add it to the timer tasks as defined on page \pageref{chunk:timer-handler}:

<<timer tasks>>=
fdc_timer ();
@

The following functions [[outb_delay]] and [[inb_delay]] do the same as [[outbyte]] and
[[inbyte]], but they execute an extra [[outb]] to an unused port (0xE0) in order to
create a short delay. It does not matter which value is sent to the port, so they just
send [[al]] (but could use any other value):

<<floppy code>>=
/**** FROM proc/i386.h *********/
static /* inline */ void outb_delay(unsigned short __port, unsigned char __value) {
  __asm__ __volatile__("outb %0,%1; \
                        outb %%al,$0xE0"      :
                       /* no output */        :
                       "a" (__value),
                       "dN" (__port)           
                       /* "eax","edx" */ );
}

static /* inline */ unsigned char inb_delay(unsigned short __port) {
  unsigned char data;

  __asm__ __volatile__("inb %1,%0; \
                        outb %%al,$0xE0"      :
                       "=a" (data)            :
                       "dN" (__port)           
                       /* "eax","edx" */ );
  return data;
}


/**** FROM arch/pc/cmos.c *********/

unsigned char
read_cmos(unsigned char address) {
  outb_delay(0x70, address);
  return inb_delay(0x71);
}



/**** FROM dma.c *********/

unsigned char dma_page_reg   [8] = { 0x87,0x83,0x81,0x82,0x00,0x8B,0x89,0x8A };
unsigned char dma_address_reg[8] = { 0x00,0x02,0x04,0x06,0xC0,0xC4,0xC8,0xCC };
unsigned char dma_count_reg  [8] = { 0x01,0x03,0x05,0x07,0xC2,0xC6,0xCA,0xCE };


void enable_dma_channel(int channel) {
  if (channel < 4)
    outb_delay(DMA0_INIT, channel);
  else
    outb_delay(DMA1_INIT, channel & 3);
}

void disable_dma_channel(int channel) {
  if (channel < 4)
    outb_delay(DMA0_INIT, channel | 4);
  else
    outb_delay(DMA1_INIT, (channel & 3) | 4);
}

void set_dma_channel_mode(int channel, int mode) {
  if (channel < 4)
    outb_delay(DMA0_MODE, mode | channel);
  else
    outb_delay(DMA1_MODE, mode | (channel & 3));
}


void clear_dma_channel_flipflop(int channel) {
  outb_delay((channel < 4) ? DMA0_FLIPFLOP : DMA1_FLIPFLOP, 0);
}

void set_dma_channel_count(int channel, long count) {
  count--;

  if (channel < 4) {
    outb_delay(dma_count_reg[channel], (unsigned char)count);
    outb_delay(dma_count_reg[channel], (unsigned char)(count >> 8));
  } else {
    outb_delay(dma_count_reg[channel], (unsigned char)(count >> 1));
    outb_delay(dma_count_reg[channel], (unsigned char)(count >> 9));
  }
}

void set_dma_channel_address(int channel, unsigned char *address) {
  if (channel < 4) {
    outb_delay(dma_address_reg[channel], (unsigned char)(unsigned)address);
    outb_delay(dma_address_reg[channel], (unsigned char)((unsigned)address >>8));
  } else {
    outb_delay(dma_address_reg[channel], (unsigned char)((unsigned)address >>1));
    outb_delay(dma_address_reg[channel], (unsigned char)((unsigned)address >>9));
  }
}

void set_dma_channel_page(int channel, int page) {
  outb_delay(dma_page_reg[channel], (channel < 4) ? page : page & 0xFE);
}



/**** FROM floppy.c ******/

/*
 * Initialize the DMA floppy channel.
 */

static void dma_init(char *address, int count) {
  disable_dma_channel(FLOPPY_CHANNEL);
  clear_dma_channel_flipflop(FLOPPY_CHANNEL);
  set_dma_channel_mode(FLOPPY_CHANNEL,
    (fdc_cmd == FLOPPY_READ) ? DMA_READ_MODE : DMA_WRITE_MODE);
  set_dma_channel_count(FLOPPY_CHANNEL, count);
  set_dma_channel_address(FLOPPY_CHANNEL, address);
  set_dma_channel_page(FLOPPY_CHANNEL, (unsigned)address >> 16);
  enable_dma_channel(FLOPPY_CHANNEL);
}
@

The actual interrupt handler for the floppy drives is rather simple: it first
checks whether interrupts were expected at all, and if so, it wakes a waiting
process.

<<floppy code>>=
void fdc_interrupt(struct regs* r) {
  fdc_timeout = 0;
  debug_printf ("FDC: interrupt\n");
  if (!fdc_waits_interrupt)
    fdc_need_reset = 1;  // unexepected floppy interrupt, reset controller
  fdc_waits_interrupt = 0;
  fdc_wakeup();
}
@

The functions [[fdc_start_motor]] and [[fdc_stop_motor]] turn the floppy drive motor on and off:

<<floppy code>>=
static void fdc_start_motor(void) {
  int i;

  if (current_fdd->motor) return;
  current_OUTPUT = FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE |
                   fdc_drive | (16 << fdc_drive);
  outb_delay(FLOPPY_OUTPUT, current_OUTPUT);
  current_fdd->motor = 1;
  fdd[!fdc_drive].motor = 0;
  for (i = 0; i < 500000; i++);
}

static void fdc_stop_motor(void) {
  outb_delay(FLOPPY_OUTPUT,
             current_OUTPUT = FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE |
             fdc_drive);

  fdd[0].motor = fdd[1].motor = 0;
}
@



<<floppy code>>=
/*
 * The floppy timer.  Called in order to stop the floppy motor if
 * there has been no floppy access in the past two seconds.
 */

void fdc_timer(void) {
  if (fdc_waits_interrupt && ++fdc_ticks > HZ * 2) {
    fdc_waits_interrupt = 0;
    fdc_timeout = 1;
    fdc_wakeup();
  } else if ((fdd[0].motor | fdd[1].motor) &&
             // fdc_rw_mutex && 
             ~(fdc_rw_lock->l) &&
             !--fdc_ticks_till_motor_stops) {
    fdc_stop_motor();
  }
}


/*
 * Wait for an interrupt.  Force a reset on timeout.
 */

static int wait_fdc_interrupt(void) {
  fdc_ticks = 0;
  fdc_waits_interrupt = 1;
  fdc_sleep();

  if (fdc_timeout) {
    fdc_need_reset = 1;
    printf("FDC: drive %d timeout\n", fdc_drive);
  }

  return fdc_timeout;
}


/*
 * Read the results from the floppy controller.
 */

static int fdc_getresults(void) {
  int i, results;
  unsigned char status;

  if (fdc_need_reset) { printf ("exit\n"); return 0; } ;

  for (results = i = 0; i < 30000; i++) {
    status = inb_delay(FLOPPY_STATUS) & FLOPPY_NEW_BYTE;
    if (status == FLOPPY_MASTER) return 1;
    if (status != FLOPPY_NEW_BYTE) continue;
    if (results == MAX_FLOPPY_RESULTS) break;
    fdc_results[results++] = inb_delay(FLOPPY_COMMAND);
  }

  printf("FDC: reply error\n");
  fdc_need_reset = 1;
  return 0;
}


/*
 * Send a byte to the floppy controller.
 */

static void fdc_out(unsigned char data) {
  int i;
  unsigned char status;

  for (i = 0; i < 10000; i++) {
    status = inb_delay(FLOPPY_STATUS) & (FLOPPY_MASTER | FLOPPY_DIRECTION);
    if (status != FLOPPY_MASTER) continue;
    outb_delay(FLOPPY_COMMAND, data);
    return;
  }

  printf("FDC: can't send byte %w to controller\n", data);
  fdc_need_reset = 1;
}


static void fdc_mode(void) {
  fdc_out(FLOPPY_SPECIFY);
  fdc_out(current_fdd_type->spec1);
  fdc_out(FLOPPY_SPEC2);
  outb_delay(FLOPPY_RATE, current_fdd_type->rate & ~0x40);
}


static void fdc_reset(void) {
  int i;

  //! DEBUG(1, "FDC: reseting...\n");

  // debug_printf ("DEBUG: cli, in fdc_reset\n");
  __asm__ __volatile__("cli");  // disable();
  outb_delay(FLOPPY_OUTPUT, FLOPPY_DMAINT_ENABLE);

  for(i = 0; i < 10000; i++) __asm__("nop");

  outb_delay(FLOPPY_OUTPUT,
             current_OUTPUT = FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE);

  fdc_need_reset = 0;

  fdd[0].calibrated = fdd[1].calibrated = 0;
  fdd[0].motor      = fdd[1].motor      = 0;

  if (wait_fdc_interrupt())
    printf("FDC: can't reset controller (timeout)\n");

  fdc_out(FLOPPY_SENSE);

  if (!fdc_getresults())
    printf("FDC: can't reset controller\n");
}


static int fdc_recalibrate(void) {
  if (fdc_need_reset) return 0;

  //! DEBUG(1, "FDC: recalibrating drive %d...\n", fdc_drive);

  // debug_printf ("DEBUG: cli, in fdc_recalibrate\n");
  __asm__ __volatile__("cli");  // disable();
  fdc_start_motor();
  fdc_out(FLOPPY_RECALIBRATE);
  fdc_out(fdc_drive);

  if (fdc_need_reset)
    return 0;

  if (wait_fdc_interrupt())
    return 0;

  fdc_out(FLOPPY_SENSE);

  if (!fdc_getresults())
    goto bad_recalibration;

  if ((fdc_results[0] & TEST_BITS) != SEEK_OK || fdc_results[1])
    goto bad_recalibration;

  current_fdd->current_track = INVALID_TRACK;
  return current_fdd->calibrated = 1;

  bad_recalibration:

  printf("FDC: can't recalibrate\n");
  fdc_need_reset = 1;
  return 0;
}


static int fdc_seek(void) {
  if (fdc_need_reset) return 0;

  if (!current_fdd->calibrated)
    if (!fdc_recalibrate())
      return 0;

  if (fdc_track == current_fdd->current_track) return 1;

  // debug_printf ("DEBUG: cli, in fdc_seek\n");
  __asm__ __volatile__("cli");  // disable();

  if (!current_fdd->motor) return 0;

  fdc_out(FLOPPY_SEEK);
  fdc_out(fdc_head << 2 | fdc_drive);
  fdc_out(fdc_track);
  
  if (fdc_need_reset) return 0;

  if (wait_fdc_interrupt()) return 0;

  current_fdd->current_track = fdc_track;
  fdc_out(FLOPPY_SENSE);

  if (!fdc_getresults()) return 0;

  if ((fdc_results[0] & TEST_BITS) != SEEK_OK ||
      fdc_results[1] != fdc_track * (current_fdd_type->trackstep + 1))
    return 0;

  // printf ("fdc_seek returns 1\n");
  return 1;
}


/*
 * Perform the actual transfer.
 */

static int fdc_transfer(void) {
  int sectors;

  // debug_printf ("DEBUG: cli, in fdc_transfer\n");
  __asm__ __volatile__("cli");  // disable();

  if (fdc_need_reset || !current_fdd->motor || !current_fdd->calibrated)
    return 0;

  // printf ("fdc_transfer: calling dma_init... ");
  dma_init(fdc_buf +
           ((fdc_head * current_fdd_type->sectors + fdc_sector - 1) << 9),
           fdc_nsects * (1 << (current_fdd_type->sectorsize + 7)));
  // printf ("done\n");

  fdc_mode();
  fdc_out(fdc_cmd);
  fdc_out(fdc_head << 2 | fdc_drive);
  fdc_out(fdc_track);
  fdc_out(fdc_head);
  fdc_out(fdc_sector);
  fdc_out(current_fdd_type->sectorsize);      /* 2 = 512 bytes/sector.  */
  fdc_out(current_fdd_type->sectors);         /* End of track.  */
  fdc_out(current_fdd_type->gap);             /* Gap length.  */
  fdc_out(FLOPPY_DTL);                        /* Data length.  */

  // printf ("fdc_transfer: alls fdc_out's done\n");

  if (fdc_need_reset) return 0;

  if (wait_fdc_interrupt()) return 0;

  // printf ("fdc_transfer: calling fdc_getresults... ");
  if (!fdc_getresults()) return 0;
  // printf ("done\n");

  if (fdc_cmd == FLOPPY_WRITE && fdc_results[1] & WRITE_PROTECTED) {
    fdc_out(FLOPPY_SENSE);
    // printf ("fdc_transfer: calling fdc_getresults (#2)... ");
    fdc_getresults();
    // printf ("done\n");
    return -1;
  }

  if ((fdc_results[0] & TEST_BITS) != TRANSFER_OK ||
      fdc_results[1] || fdc_results[2])
    goto bad_transfer;

  sectors = (fdc_results[3] - fdc_track) * (current_fdd_type->sectors << 1) +
            (fdc_results[4] - fdc_head) * current_fdd_type->sectors +
            fdc_results[5] - fdc_sector;

  if (sectors == fdc_nsects) return 1;

  bad_transfer:

  current_fdd->calibrated = 0;
  return 0;
}


static int fdc_command(int cmd, int drive, int track, int sector, int nsects) {
  int err;

  fdc_cmd    = cmd;
  fdc_drive  = drive;
  fdc_track  = track;
  fdc_head   = sector / current_fdd_type->sectors;
  fdc_sector = sector % current_fdd_type->sectors + 1;
  fdc_nsects = nsects;

  fdc_ticks_till_motor_stops = 3 * HZ;

  for (err = 0; err < MAX_FLOPPY_ERRORS; err++) {
    if (fdc_need_reset)
      fdc_reset();

    fdc_start_motor();

    if (!fdc_seek()) {
      debug_printf("FDC: seek error on drive %d\n", fdc_drive);
	  continue;
	}

	switch (fdc_transfer()) {
      case -1: printf("FDC: disk in drive %d is write protected\n", fdc_drive);
               return 0;
      case  0: continue;
      case  1: return 1;
	}
  }
  return 0;
}


int fdc_open(int minor, int flags) {
  //! DEBUG(9, "(%d/%d)\n", FDC_MAJOR, minor);

  if (minor < 0 || minor >= MAX_FDCS || !fdd[minor].present) {
    //! DEBUG(9, "no such device\n");
    return -ENXIO;
  }

  //! down(&fdc_oc_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_oc_lock);

  if (!fdc_minor_info[minor].in_use) {
    fdd[minor].calibrated    = 0;
    fdd[minor].current_track = INVALID_TRACK;
    fdd[minor].motor         = 0;
    fdc_minor_info[minor].in_use = 1;
  }

  //! up(&fdc_oc_mutex);
  UNLOCK (fdc_oc_lock);

  return 0;
}


int fdc_close(int minor) {
  //! DEBUG(9, "(%d/%d)\n", FDC_MAJOR, minor);

  //! down(&fdc_oc_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_oc_lock);

  /* It should never enter on the 'true' branch of this 'if'.
     Maybe this should be removed.  */

  if (!fdc_minor_info[minor].in_use) {
    printf("FDC: trying to close unused device %d\n", minor);
    //! up(&fdc_oc_mutex);
    UNLOCK (fdc_oc_lock);
    return -EBUSY;
  }

  fdc_minor_info[minor].in_use = 0;

  //! up(&fdc_oc_mutex);
  UNLOCK (fdc_oc_lock);
  
  return 0;
}


int fdc_read(int minor, blk_request *br) {
  int spt;                            /* Sectors per track.  */
  int spb;                            /* Sectors per file system block.  */
  int i, buf_no;
  unsigned address = 0, index = 0;
  int device = minor, ctrack, csector;
  int block, cblock, nblocks, cnblocks;
  int good_sectors, total_good_sectors = 0;

  //! down(&fdc_rw_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_rw_lock);

  current_fdd      = &fdd[device];
  current_fdd_type = &fdd_type[current_fdd->type];

  spb     = br->blksz / FDC_BLKSZ;
  block   = br->block   * spb;
  nblocks = br->nblocks * spb;


  /* Check the request.  */
  if (block   <  0 || block   >= current_fdd_type->total_sectors ||
      nblocks <= 0 || nblocks >  current_fdd_type->total_sectors ||
      block + nblocks         >  current_fdd_type->total_sectors)
    PANIC("bad request (cmd=r dev=%d blk=%d nblk=%d buf=%d)\n",
          device, br->block, br->nblocks, br->buf_no);

  spt = current_fdd_type->sectors << 1;
  buf_no = br->buf_no;

  //! DEBUG(9, "(cmd=r dev=%d blk=%d nblk=%d buf=%d)\n",
  //!       device, br->block, br->nblocks, br->buf_no);

  for (cblock = block; nblocks; cblock += cnblocks, nblocks -= cnblocks) {
    ctrack   = cblock / spt;
    csector  = cblock % spt;
    cnblocks = min(nblocks, spt - csector);

    if (fdc_command(FLOPPY_READ, device, ctrack, csector, cnblocks))
      good_sectors = cnblocks;
	else
      for (good_sectors = i = 0; i < cnblocks; good_sectors++, i++) {
        printf("FDC: reading one sector at a time (%d/%z/%z)...\n",
               device, ctrack, csector + i);
        if (fdc_command(FLOPPY_READ, device, ctrack, csector+i,1) == 0)
          break;
      }

    for (i = 0; i < cnblocks; index++, i++) {
      if (i < good_sectors) {
        if (index == 0)
          address = (unsigned)buf_address(buf_no);
        memcpy_debug((void *)(address + (index << 9)),
               &fdc_buf[(csector + i) << 9], FDC_BLKSZ);
        buf_vect[buf_no].valid = 1;
      } else
        buf_vect[buf_no].valid = 0;

      if (index == spb - 1) {
        buf_no = buf_vect[buf_no].next;
        index = -1;
      }
    }

    total_good_sectors += good_sectors;
    if (good_sectors != cnblocks) break;
  }

  //! up(&fdc_rw_mutex);
  UNLOCK (fdc_rw_lock);

  return total_good_sectors * FDC_BLKSZ;
}


int fdc_read_sector(int device, int block, char* buffer) {
  // READ A 512 BYTE SECTOR  (DISC SECTOR SIZE = 512)
  // 1.4MB: 80 tracks, 18 sectors, sectorsize=2. 80x18x2=2880
  int spt;                            /* Sectors per track.  */
  int i, buf_no;
  unsigned address = 0, index = 0;
  int ctrack, csector;
  int cnblocks;
  int good_sectors, total_good_sectors = 0;

  //! down(&fdc_rw_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_rw_lock);

  current_fdd      = &fdd[device];
  current_fdd_type = &fdd_type[current_fdd->type];

  spt = current_fdd_type->sectors << 1;  // 36 ??

  ctrack   = block / spt;
  csector  = block % spt;
  cnblocks = 1;

  if (fdc_command(FLOPPY_READ, device, ctrack, csector, cnblocks))
    good_sectors = cnblocks;
  else
    good_sectors = 0;

  if (good_sectors == 1) {
    debug_printf ("DEBUG: fdc_read_sector: accessing FDC buffer\n");
    memcpy_debug((void *)buffer,
           &fdc_buf[csector << 9]+0xd0000000, FDC_BLKSZ);
  }

  //! up(&fdc_rw_mutex);
  UNLOCK (fdc_rw_lock);

  return good_sectors * FDC_BLKSZ;
}

int fdc_write_sector(int device, int block, char* buffer) {
  // READ A 512 BYTE SECTOR  (DISC SECTOR SIZE = 512)
  // 1.4MB: 80 tracks, 18 sectors, sectorsize=2. 80x18x2=2880
  int spt;                            /* Sectors per track.  */
  int i, buf_no;
  unsigned address = 0, index = 0;
  int ctrack, csector;
  int cnblocks;
  int good_sectors, total_good_sectors = 0;

  //! down(&fdc_rw_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_rw_lock);

  current_fdd      = &fdd[device];
  current_fdd_type = &fdd_type[current_fdd->type];

  spt = current_fdd_type->sectors << 1;  // 36 ??

  ctrack   = block / spt;
  csector  = block % spt;
  cnblocks = 1;

  memcpy_debug( &fdc_buf[csector << 9]+0xd0000000,
          (void *)buffer, FDC_BLKSZ);

  if (fdc_command(FLOPPY_WRITE, device, ctrack, csector, cnblocks))
    good_sectors = cnblocks;
  else
    good_sectors = 0;


  //! up(&fdc_rw_mutex);
  UNLOCK (fdc_rw_lock);

  return good_sectors * FDC_BLKSZ;
}


int fdc_write(int minor, blk_request *br) {
  int spt;                            /* Sectors per track.  */
  int spb;                            /* Sectors per file system block.  */
  int i, buf_no;
  unsigned address = 0, index = 0;
  int device = minor, ctrack, csector;
  int block, cblock, nblocks, cnblocks;
  int good_sectors, total_good_sectors = 0;

  //! down(&fdc_rw_mutex, WAIT_DEVICE_BUSY);
  LOCK (fdc_rw_lock);

  current_fdd      = &fdd[device];
  current_fdd_type = &fdd_type[current_fdd->type];

  spb     = br->blksz / FDC_BLKSZ;
  block   = br->block   * spb;
  nblocks = br->nblocks * spb;


  /* Check the request.  */

  if (block   <  0 || block   >= current_fdd_type->total_sectors ||
      nblocks <= 0 || nblocks >  current_fdd_type->total_sectors ||
      block + nblocks         >  current_fdd_type->total_sectors)
	PANIC("%s (cmd=w dev=%d blk=%d nblk=%d buf=%d)\n",
          ERR_BADREQ, device, br->block, br->nblocks, br->buf_no);

  spt = current_fdd_type->sectors << 1;
  buf_no = br->buf_no;

  //! DEBUG(9, "(cmd=w dev=%d blk=%d nblk=%d buf=%d)\n",
  //!       device, br->block, br->nblocks, br->buf_no);

  for (cblock = block; nblocks; cblock += cnblocks, nblocks -= cnblocks) {
    ctrack   = cblock / spt;
    csector  = cblock % spt;
    cnblocks = min(nblocks, spt - csector);

    for (i = 0; i < cnblocks; index++, i++) {
      if (index == 0) address = (unsigned)buf_address(buf_no);
      memcpy_debug(&fdc_buf[(csector + i) << 9],
             (void *)(address + (index << 9)), FDC_BLKSZ);

      if (index == spb - 1) {
        buf_no = buf_vect[buf_no].next;
        index = -1;
      }
    }

    if (fdc_command(FLOPPY_WRITE, device, ctrack, csector, cnblocks))
      good_sectors = cnblocks;
    else
      for (good_sectors = i = 0; i < cnblocks; good_sectors++, i++) {
        printf("FDC: writing one sector at a time (%d/%z/%z)...\n",
               device, ctrack, csector + i);
        if (fdc_command(FLOPPY_WRITE, device, ctrack,csector+i,1) == 0)
          break;
      }

    if (good_sectors != cnblocks) break;
    total_good_sectors += good_sectors;
  }

  //! up(&fdc_rw_mutex);
  UNLOCK (fdc_rw_lock);

  return total_good_sectors * FDC_BLKSZ;
}

int fdc_ioctl(int minor, int cmd, void *argp) {
  switch (cmd) {
    case IOCTL_GETBLKSZ:          /* Get device block size.  */
      *(int *)argp = FDC_BLKSZ;
      break;

    case IOCTL_GETDEVSZ:          /* Get device size (in no of blocks).  */
      *(int *)argp =  fdd_type[fdd[minor].type].total_sectors;
      break;

    default:
      return -EINVAL;
  }

  return 0;
}

/*
WOFUER BRAUCH ICH DAS?
int fdc_lseek(int minor, __off_t offset) {
  if (minor < fdc_driver.minors)
    return offset;

  return -ESPIPE;
}
*/


int fdc_map_type (int t) {
  // we support types 2 (1.2 MB), 4 (1.44 MB), and 5 (2.88 MB)
  switch (t) {
    case 2: return 0;
    case 4: return 1;
    case 5: return 3;
    default: return -1;
  }
}

/*
 * Initialize the driver data structures.  Detect the number of floppies
 * and their type from the CMOS.  Also register the driver.
 */

int fdc_init(void) {
  // initialize locks
  fdc_oc_lock = get_new_lock ();
  fdc_rw_lock = get_new_lock ();
  debug_printf ("DEBUG: &fdc_oc_lock->l = %x\n", &fdc_oc_lock->l);
  debug_printf ("DEBUG: &fdc_rw_lock->l = %x\n", &fdc_rw_lock->l);

  int type, fdd_type_byte = read_cmos(0x10);

  type = fdd_type_byte >> 4;

  if ((fdd[0].present = (type == 2 || type == 4 || type == 5 )))
    // fdd[0].type = (type != 2);
    fdd[0].type = fdc_map_type (type);

  printf("FDC: fda is %s, ", fdd_drive_name[type]);

  type = fdd_type_byte & 0x0F;

  if ((fdd[1].present = (type == 2 || type == 4 || type == 5 )))
    // fdd[1].type = (type != 2);
    fdd[1].type = fdc_map_type (type);

  printf("fdb is %s\n", fdd_drive_name[type]);

  irq_install_handler(6, fdc_interrupt);
  outportb (0x3F7,  0); // FDC Reset
  outportb (0x3F2, 12); // Enable DMA, disable Reset

  
  // TEST FDC
  char fbuf[512];
  fdc_read_sector(0, 39, (char*)&fbuf); fbuf[60]='\0'; 
  // printf ("sector %d: %s ...\n", 39, &fbuf);
  // fdc_read_sector(0, 40, (char*)&fbuf); fbuf[60]='\0'; 
  // printf ("sector %d: %s ...\n", 40, &fbuf);
  
  // memcpy(&fbuf, "HALLO LEUTE - WIE GEHT ES?", 27);
  // fdc_write_sector(0, 40, (char*)&fbuf);
  

  // TESTS
  
  // simplefs_ls();
  /*
  char xbuf[51];
  int fd = simplefs_open ("makefs.c");
  int counter;
  for (;;) {
    counter = simplefs_read (fd, (char*)&xbuf, 50);
    xbuf[counter] = '\0';
    printf ("%s", xbuf);
    if (counter==0) break;
  };
  printf ("\n");
  */
  asm ("sti");
  
  return 0; // register_driver((generic_driver *)&fdc_driver);
}
@


<<kernel declarations>>=
<<floppy declarations>>
@

<<kernel functions>>=
<<floppy code>>
@


\subsection{Provisorische System Calls fuer FDC-Zugriff}

Die folgenden Funktionen lesen von fdb (floppy 1), ulixdata.img.

<<kernel functions>>=
void syscall_read_sector (struct regs *r) {
  // printf ("  sector: %d\n" ,r->ebx);
  fdc_read_sector(1, r->ebx, (char*)r->ecx);
};

void syscall_write_sector (struct regs *r) {
  fdc_write_sector(1, r->ebx, (char*)r->ecx);
};

void syscall_open (struct regs *r) {
  // r->eax = simplefs_open ((char*) r->ebx);
  debug_printf ("syscall_open called\n");
  r->eax = mx_open ((char*) r->ebx, r->ecx);
  return;
};

void syscall_close (struct regs *r) {
  int gfd = r->ebx;
  debug_printf ("syscall_close (fd = %d) called\n", gfd);
  // simplefs_close (gfd);
  mx_close (gfd);
};

void syscall_read (struct regs *r) {
  // ebx: fd
  // ecx: *buf
  // edx: nbytes
  int gfd = r->ebx;
  char* buf = (char*) r->ecx;
  int nbytes = r->edx;
  // r->eax = simplefs_read (gfd, buf, nbytes);
  r->eax = mx_read (gfd, buf, nbytes);
  // debug_printf ("syscall_read finished\n");
};

void syscall_write (struct regs *r) {
  // ebx: fd
  // ecx: *buf
  // edx: nbytes
  int gfd = r->ebx;
  char* buf = (char*) r->ecx;
  int nbytes = r->edx;
  // r->eax = simplefs_write (gfd, buf, nbytes);
  r->eax = mx_write (gfd, buf, nbytes);
  debug_printf ("syscall_write finished\n");
};

void syscall_lseek (struct regs *r) {
  // ebx: fd
  // ecx: offset
  // edx: whence
  r->eax = mx_lseek (r->ebx, r->ecx, r->edx);
};

void syscall_ls (struct regs *r) {
  // ebx: path
  char *path = (char*) r->ebx;
  int inode = pathname_to_ino (path);
  if (inode == -1)
    printf ("ls: %s: no such directory\n", path);
  else {
    printf ("directory %s is in inode %d\n", path, inode);
    list_dir (inode);   // Minix!
  }
  return;
};

@

<<kernel declarations>>=
#define SEEK_SET        0       /* set file offset, absolute */
#define SEEK_CUR        1       /* set file offset, relative */
#define SEEK_END        2       /* set file offset, EOF+offset */
@

<<initialize syscalls>>=
insert_syscall (0x7001, syscall_read_sector);
insert_syscall (0x7002, syscall_write_sector);

insert_syscall (__NR_open,  syscall_open);
insert_syscall (__NR_close, syscall_close);
insert_syscall (__NR_read,  syscall_read);
insert_syscall (__NR_write, syscall_write);
insert_syscall (__NR_lseek, syscall_lseek);
@

<<ulix system calls>>=
#define __NR_ls 0x5102
@

<<initialize syscalls>>=
insert_syscall (__NR_ls, syscall_ls);
@


Simple file system (32 files, no directories, no attributes):

<<kernel declarations>>=
#define EBADF 16
typedef unsigned short uint16;
typedef struct {
  char name[12];  // filename
  uint16 size;    // file size in bytes
  uint16 sector;  // start sector
} simplefs_fat_entry;
simplefs_fat_entry simplefs_fat[32];   // 32 files max.

typedef struct {
  short int used;       // are we using this entry?
  char name[12];        // filename
  uint16 size;          // file size in bytes
  uint16 sector;        // start sector
  unsigned int pos;     // seek position
} simplefs_openfiles_entry;
simplefs_openfiles_entry simplefs_openfiles[32];  // 32 open files
  
void simplefs_ls ();
int simplefs_open (char* filename);
int simplefs_close (int fd);
int simplefs_read (int fd, char* buf, int nbytes);
int simplefs_write (int fd, char* buf, int nbytes);
int simplefs_lseek(int fd, int offset, int whence);
@

<<initialize kernel global variables>>=
memset (simplefs_openfiles, 0, sizeof(simplefs_openfiles));
@

<<kernel functions>>=
void simplefs_ls () {
  fdc_read_sector (1, 0, (char*)simplefs_fat);
  int i;
  for (i=0; i<32; i++) {
    if (simplefs_fat[i].sector != 0)
    printf ("%-12s %7d %4d\n", 
      simplefs_fat[i].name,
      simplefs_fat[i].size,
      simplefs_fat[i].sector);
  };
  return;
};

int simplefs_get_fd () {
  int i;
  for (i=0; i<32; i++) {
    if (simplefs_openfiles[i].used == 0) {
      // found a free one
      simplefs_openfiles[i].used = 1;
      return i;
    };
  };
  // found no free FD
  return -1;
};

int simplefs_open (char* filename) {
  int i, fd;
  fdc_read_sector (1, 0, (char*)simplefs_fat);
  for (i=0; i<32; i++) {
    if (simplefs_fat[i].sector != 0) {
      if (strcmp(simplefs_fat[i].name, filename)) {
        // printf ("file found\n");
        goto found;
      }
    }
  }
  // not found:
  return -1;
  
  found:
  fd = simplefs_get_fd();
  if (fd == -1) {
    // no free FD
    printf ("open: no free fd\n");
    return -1;
  };
  memcpy (simplefs_openfiles[fd].name, simplefs_fat[i].name, 12);
  simplefs_openfiles[fd].size = simplefs_fat[i].size;
  simplefs_openfiles[fd].sector = simplefs_fat[i].sector;
  simplefs_openfiles[fd].pos = 0;  // init 0
  return fd;
};

int simplefs_close (int fd) {
  // set everything to 0
  // printf ("simplefs_close(%d) called\n", fd);
  memset (&simplefs_openfiles[fd], 0, sizeof(simplefs_openfiles_entry));
  return 0;
}
@

Whenever we read, write, or seek in a file, we first check
whether the file is open:

<<simplefs check file open>>=
if (simplefs_openfiles[fd].sector == 0) {
  // file not open
  return -EBADF;
};
@

<<kernel functions>>=
int simplefs_read (int fd, char* buf, int nbytes) {
  char sector[512];
  <<simplefs check file open>>
  int pos = simplefs_openfiles[fd].pos;
  
  if (pos+nbytes > simplefs_openfiles[fd].size) {
    // reaching EOF
    nbytes = simplefs_openfiles[fd].size - pos;
  }
  
  int relpos = pos%512;   // where in the buffer do we start?
  int sec = simplefs_openfiles[fd].sector + pos/512;
  int bufpos = 0;
  int count = 0;
  while (nbytes > 0) {
    fdc_read_sector (1, sec, (char*)sector);
    int b = min(512-relpos,nbytes);
    // next line: casting (char*) so that pointer arithmetic works...
    memcpy (buf+bufpos, ((char*)&sector)+relpos, b);
    
    sec++;  // next sector
    nbytes -= b;
    bufpos += b;
    count += b;
    relpos = 0;
  };
  simplefs_openfiles[fd].pos += count;
  return count;
}

int simplefs_write (int fd, char* buf, int nbytes) {
  char sector[512];
  <<simplefs check file open>>
  int pos = simplefs_openfiles[fd].pos;
  
  if (pos+nbytes > simplefs_openfiles[fd].size) {
    // reaching EOF
    nbytes = simplefs_openfiles[fd].size - pos;
  }

  int relpos = pos%512;   // where in the buffer do we start?
  int sec = simplefs_openfiles[fd].sector + pos/512;
  int bufpos = 0;
  int count = 0;
  while (nbytes > 0) {
    // each sector that we modify must first be read...
    fdc_read_sector (1, sec, (char*)sector);
    int b = min(512-relpos,nbytes);
    // next line: casting (char*) so that pointer arithmetic works...
    memcpy (((char*)&sector)+relpos, buf+bufpos, b);
    fdc_write_sector (1, sec, (char*)sector);
    
    sec++;  // next sector
    nbytes -= b;
    bufpos += b;
    count += b;
    relpos = 0;
  };
  simplefs_openfiles[fd].pos += count;
  return count;
}

int simplefs_lseek(int fd, int offset, int whence) {
  <<simplefs check file open>>
  if (offset<0) return -1;   // negative offset
  switch (whence) {
    case SEEK_SET: simplefs_openfiles[fd].pos = offset; break;
    case SEEK_CUR: simplefs_openfiles[fd].pos += offset; break;
    case SEEK_END: simplefs_openfiles[fd].pos = 
                   simplefs_openfiles[fd].size+offset; break;
    default:       return -1;  // wrong whence value
  }
  return simplefs_openfiles[fd].pos;
}
@


\section{A Simple Buffer Cache}

Early versions of \UlixI{} caused all [[readblock]] and [[writeblock]]
operations to directly access the floppy drive. This made even simple
things such as displaying the contents of the root directory very slow,
since many blocks were read over and over again.

Here we show how to dramatically speed up disk access (to blocks which
have already been read) by buffering them in memory.

For our simple system it does not take much: We provide a buffer than
can store 512 blocks. A kernel lock [[buffer_lock]] protects against
parallel accesses.

<<kernel global variables>>=
#define BUFFER_CACHE_SIZE 512

struct buffer_entry {
  char buf[BLOCK_SIZE];
  int dev;      // from what device?              (-1 if free)
  int blockno;  // block number of buffered block (-1 if free)
  byte count;   // how often was it read?
};

struct buffer_entry buffer_cache[BUFFER_CACHE_SIZE];
// struct buffer_entry *buffer_cache;

lock buffer_lock;
@

Here's how we initialize the buffer cache at system start:

% < < initialize kernel global variables > >=
<<initialize system>>=
// buffer_cache = kmalloc (BUFFER_CACHE_SIZE * (BLOCK_SIZE+12));
// memset (buffer_cache, 0,BUFFER_CACHE_SIZE * (BLOCK_SIZE+12)); 
memset (buffer_cache, 0, sizeof(buffer_cache));
debug_printf ("nulled buffer cache; size: %d\n", sizeof(buffer_cache));
for (int i = 0; i<BUFFER_CACHE_SIZE; i++) {
  buffer_cache[i].blockno = 
  buffer_cache[i].dev     = -1;
}

buffer_lock = get_new_lock ();
@

Next we need code for entering data into and extracting it from the
buffer cache; we write two functions

<<kernel declarations>>=
int buffer_write (int dev, int blockno, char *block);
int buffer_read  (int dev, int blockno, char *block);
boolean buffer_contains (int dev, int blockno);
@

These are basically defined similar to [[readblock]] and [[writeblock]],
but we provide a device id [[dev]] as an extra parameter so that we
can use the cache for different devices.

Reading is the simpler function, so we start with that:

<<kernel functions>>=
int buffer_read (int dev, int blockno, char *block) {
  // don't use the buffer before the scheduler is up
  if (!scheduler_is_active) return -1;  // -1 signals: must be read from disk
  
  LOCK (buffer_lock);
  
  debug_printf ("DEBUG: buffer_read (%d,%d,%x) entered\n", dev, blockno, block);

  // check if buffer cache holds the requested block
  int pos = -1;  // position in the cache
  for (int i=0; i<BUFFER_CACHE_SIZE; i++) {
    if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
      // found it!
      pos = i;
      debug_printf ("DEBUG: in buffer_read, found entry pos = %d\n", pos);
      break;
    }
  }
  
  if (pos == -1) {
    UNLOCK (buffer_lock);
    return -1;  // not found
  }
    
  // we found it: copy the contents, update the counter
  memcpy (block, buffer_cache[pos].buf, BLOCK_SIZE);
  if ((int)buffer_cache[pos].count < 254)
    buffer_cache[pos].count++;

  UNLOCK (buffer_lock);
  return 0;    // success
}
@

Writing to the buffer is a little more complicated---if there is no entry 
for the block we want to write. Otherwise it's pretty much the same:

<<kernel functions>>=
int buffer_write (int dev, int blockno, char *block) {
  // don't use the buffer before the scheduler is up
  if (!scheduler_is_active) return 0;

  LOCK (buffer_lock);
  
  debug_printf ("DEBUG: buffer_write (%d,%d,%x) entered\n", dev, blockno, block);

  // check if buffer cache already holds the requested block
  int pos = -1;  // position in the cache
  for (int i=0; i<BUFFER_CACHE_SIZE; i++) {
    if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
      // found it!
      pos = i;
      break;
    }
  }
  
  if (pos == -1) {
    // not found, create it
    <<buffer cache: find or create free entry; sets [[pos]]>>
  }
  
  // copy the contents, update the counter
  debug_printf ("DEBUG: in buffer_write, pos = %d, memcpy (%x,%x,%x)\n", pos, buffer_cache[pos].buf, block, BLOCK_SIZE);
  if ((pos>=0) && (pos<BUFFER_CACHE_SIZE)) {
    memcpy (buffer_cache[pos].buf, block, BLOCK_SIZE);
    if ((int)buffer_cache[pos].count < 254)
      buffer_cache[pos].count++;
  } else {
    debug_printf ("ERROR in buffer_write; index pos = %d out of range\n", pos);
  }
  
  UNLOCK (buffer_lock);
  
  return 0;    // success
}
@

The obvious difference is that writing to the buffer cache always succeeds
because we either update an existing entry or create a new entry. Creating
a new one is not a problem as long as there remain free entries:

<<buffer cache: find or create free entry; sets [[pos]]>>=
pos = -1;  // new search
for (int i=0; i<BUFFER_CACHE_SIZE; i++) {
  // printf ("searching free one; i = %d, buffer_cache[i].dev = %d\n", i, buffer_cache[i].dev);
  if (buffer_cache[i].dev == -1) {
    // this one is free
    pos = i;
    debug_printf ("DEBUG: in buffer_write, found free entry pos = %d\n", pos);
    break;
  }
}

if (pos == -1) {
  // we found no free entry
  <<buffer cache: free an entry; sets [[pos]]>>
}

// memset (0, buffer_cache[pos], sizeof (struct buffer_entry));
buffer_cache[pos].dev = dev;
buffer_cache[pos].blockno = blockno;
buffer_cache[pos].count = 0;
@

This code makes prepares the buffer cache entry by setting its
[[dev]] and [[blockno]] members. The [[memset]] command above would
also zero out the buffer's contents, but this is not needed since
it will be overwritten immediately.

Finally we need to say how to find an entry when all entries are in
use. This asks for a replacement strategy and we'll implement a
simple ``least often used'' strategy.

<<buffer cache: free an entry; sets [[pos]]>>=
printf ("DEBUG: buffer_write: need to free an entry\n");
pos = 0;  // new search
int least_used_val = buffer_cache[0].count;

for (int i=0; i<BUFFER_CACHE_SIZE; i++) {
  if (buffer_cache[i].count < least_used_val) {
    // this entry was accessed less often
    least_used_val = buffer_cache[i].count;
    pos = i;  // update candidate
  }
}
@

We also add a function [[buffer_contains]] which lets us query whether
a specific block is currently buffered:

<<kernel functions>>=
boolean buffer_contains (int dev, int blockno) {
  // don't use the buffer before the scheduler is up
  if (!scheduler_is_active) return false;
  
  debug_printf ("DEBUG: buffer_contains (%d,%d) entered\n", dev, blockno);

  // check if buffer cache holds this block
  int pos = -1;  // position in the cache
  for (int i=0; i<BUFFER_CACHE_SIZE; i++) {
    if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
      // found it!
      pos = i;
      break;
    }
  }
  
  // return (pos != -1);
  if (pos == -1)
    return false;
  else
    return true;
}
@



\chapter{Signals}
\label{chap:ulix:signals}%

Signals are a classical Unix mechanism which allows a simple kind of
messaging: processes can send signals to other processes which makes them
either terminate or call a registered signal handler. In many ways these
signals are very similar to interrupts, but while an interrupt handler
can only be set up in kernel mode (and serves for the whole system),
signal handlers can be setup in user mode and belong to just one process.

The similarity between signals and interrupts goes even further: Interrupts
exist in two varieties, synchronous (e.\,g. interrupts caused by accesssing
a bad memory address or trying to execute an unknown CPU instruction) and 
asynchronous (e.\,g. raised by a device, such as the timer or a floppy or
hard disk controller), and the same holds for signals: a synchronous signal
is caused by the process itself (again access to a bad memory address is an
example---in that case it causes an interrupt first and the interrupt handler
sends a corresponding signal to the process), but most signals are
asynchronous (sent by a different process).

Some functionality is available in both worlds (interrupts and signals),
take for example a timer: the computer's timer chip generates regular timer
interrupts which are asynchronous events and invoke the kernel's timer
interrupt handler. Besides other things, this handler checks whether one of
the processes has registered a (process-private) timer---and if so,
generates an alarm signal. When the process is scheduled the next time,
instead of continuing its normal execution it enters its alarm signal
handler and treats the asynchronous signal.

An example for synchronous events in both worlds is bad memory access.
When a process tries to access a virtual address which is not available
(because the page tables do not map it to some physical address), a
page fault is generated, so the CPU jumps into the page fault (interrupt)
handler. That one checks the reason (the only acceptable reason being
that the page was paged out to disk). If that is not the case, the 
process must be terminated. To achieve this goal, the page fault handler
sends the process a SIGSEGV (``segmentation violation'') signal. 
When the process is scheduled again,
it will normally abort, though it may have registered a SIGSEGV signal
handler to deal with such a situation.

For the memory example, consider the following program [[segfault.c]]:

<<segfault.c>>=
int main () {
  char *adr = (char *)0;
  char c = *adr;
  putchar (c);
}
@

and its execution via the debugger [[gdb]]:

{\small
\begin{verbatim}
$ gcc -g segfault.c 
$ gdb a.out 
GNU gdb (Ubuntu/Linaro 7.4-2012.04-0ubuntu2.1) 7.4-2012.04
(gdb) run
Starting program: /tmp/a.out 

Program received signal SIGSEGV, Segmentation fault.
0x0000000000400508 in main () at segfault.c:3
3	  char c = *adr;
\end{verbatim}
}


\section{Use Cases for Signals}

What are signals good for? In this section we show you three examples which
demonstrate the power of signals.

......




\section{Signals in Classical Unix Systems}

In classical Unix systems, processes can use the [[kill]] system call to
deliver a signal to an arbitrary process (as long as both have the same
owner or the signal-sending process belongs to [[root]]), or the [[raise]]
system call to send a signal to itself.

Every Unix system knows a few standard signals, with signal numbers 
typically ranging from 0 to 31. While some signals have standard signal
numbers (such as 9 and 15 for [[SIGKILL]] and [[SIGTERM]]), the POSIX
standard does not require signals to use standard values; it only asks
for signal names to be defined\footnote{see \url{http://pubs.opengroup.org/onlinepubs/009695399/basedefs/signal.h.html}}:

\begin{description}
\item[SIGABRT]
	

A
	

Process abort signal.

\item[SIGALRM]
	

T
	

Alarm clock.

\item[SIGBUS]
	

A
	

Access to an undefined portion of a memory object.

\item[SIGCHLD]
	

I
	

Child process terminated, stopped,

[XSI] [Option Start]  
	

 
	

or continued. [Option End]

\item[SIGCONT]
	

C
	

Continue executing, if stopped.

\item[SIGFPE]
	

A
	

Erroneous arithmetic operation.

\item[SIGHUP]
	

T
	

Hangup.

\item[SIGILL]
	

A
	

Illegal instruction.

\item[SIGINT]
	

T
	

Terminal interrupt signal.

\item[SIGKILL]
	

T
	

Kill (cannot be caught or ignored).

\item[SIGPIPE]
	

T
	

Write on a pipe with no one to read it.

\item[SIGQUIT]
	

A
	

Terminal quit signal.

\item[SIGSEGV]
	

A
	

Invalid memory reference.

\item[SIGSTOP]
	

S
	

Stop executing (cannot be caught or ignored).

\item[SIGTERM]
	

T
	

Termination signal.

\item[SIGTSTP]
	

S
	

Terminal stop signal.

\item[SIGTTIN]
	

S
	

Background process attempting read.

\item[SIGTTOU]
	

S
	

Background process attempting write.

\item[SIGUSR1]
	

T
	

User-defined signal 1.

\item[SIGUSR2]
	

T
	

User-defined signal 2.

\item[SIGPOLL]
	

T
	

Pollable event.

\item[SIGPROF]
	

T
	

Profiling timer expired.

\item[SIGSYS]
	

A
	

Bad system call.

\item[SIGTRAP]
	

A
	

Trace/breakpoint trap. [Option End]

\item[SIGURG]
	

I
	

High bandwidth data is available at a socket.

\item[SIGVTALRM]
	

T
	

Virtual timer expired.

\item[SIGXCPU]
	

A
	

CPU time limit exceeded.

\item[SIGXFSZ]
	

A
	

File size limit exceeded. 
\end{description}

Table \ref{tab:signals} shows how these signal names are mapped to signal numbers
on some standard systems.

\begin{table}
\centering
\begin{tabular}{l|r|r|r|r|r}
\textbf{Signal} & \textbf{Linux} & \textbf{OS X} & 
\textbf{Minix} & \textbf{FreeBSD} & \textbf{Solaris} \\
\hline
SIGABRT   &  6 &  6 &  6 &  6 &  6 \\
SIGALRM   & 14 & 14 & 14 & 14 & 14 \\
SIGBUS    &  7 & 10 &  7 & 10 & 10 \\
SIGCHLD   & 17 & 20 & 17 & 20 & 18 \\
SIGCONT   & 18 & 19 & n/a, 18 & 19 & 25 \\
SIGFPE    &  8 &  8 &  8 &  8 &  8 \\
SIGHUP    &  1 &  1 &  1 &  1 &  1 \\
SIGILL    &  4 &  4 &  4 &  4 &  4 \\
SIGINT    &  2 &  2 &  2 &  2 &  2 \\
SIGKILL   &  9 &  9 &  9 &  9 &  9 \\
SIGPIPE   & 13 & 13 & 13 & 13 & 13 \\
SIGQUIT   &  3 &  3 &  3 &  3 &  3 \\
SIGSEGV   & 11 & 11 & 11 & 11 & 11 \\
SIGSTOP   & 19 & 17 & n/a, 19 & 17 & 23 \\
SIGTERM   & 15 & 15 & 15 & 15 & 15 \\
SIGTSTP   & 20 & 18 & n/a, 20 & 18 & 24 \\
SIGTTIN   & 21 & 21 & n/a, 22 & 21 & 26 \\
SIGTTOU   & 22 & 22 & n/a, 23 & 22 & 27 \\
SIGUSR1   & 10 & 30 & 10 & 30 & 16 \\
SIGUSR2   & 12 & 31 & 12 & 31 & 17 \\
SIGPOLL *)& 29 & 23 & -- & 23 & 22 \\
SIGPROF   & 27 & 27 & 25 & 27 & 29 \\
SIGSYS    & 31 & 12 & -- & 12 & 12 \\
SIGTRAP   &  5 &  5 &  5 &  5 &  5 \\
SIGURG    & 23 & 16 & -- & 16 & 21 \\
SIGVTALRM & 26 & 26 & 24 & 26 & 28 \\
SIGXCPU   & 24 & 24 & -- & 24 & 30 \\
SIGXFSZ   & 25 & 25 & -- & 25 & 31 \\
%\hline
%SIGSTKFLT & 16 & -- & -- & -- & -- \\
%SIGWINCH  & 28 & 28 & 21 & 28 & 20 \\
%SIGPWR    & 30 & -- & -- & -- & 19 \\
%SIGEMT    & -- &  7 & 16 &  7 &  7 \\
%SIGINFO   & -- & 29 & -- & 29 & -- \\
%SIGKMESS  & -- & -- & 29 & -- & -- \\
%SIGKSIG   & -- & -- & 30 & -- & -- \\
%SIGNDELAY & -- & -- & 31 & -- & -- \\
%SIGTHR    & -- & -- & -- & 32 & -- \\
%SIGCANCEL & -- & -- & -- & -- & 36 \\
%SIGFREEZE & -- & -- & -- & -- & 34 \\
%SIGLOST   & -- & -- & -- & -- & 37 \\
%SIGLWP    & -- & -- & -- & -- & 33 \\
%SIGTHAW   & -- & -- & -- & -- & 35 \\
%SIGWAITING& -- & -- & -- & -- & 32 \\
%SIGXRES   & -- & -- & -- & -- & 38 \\
\end{tabular}
  \caption{Standard signals on five Unix systems.}
  \label{tab:signals}
  
\vspace{3mm}
{\small
*) Linux, Mac OS, and FreeBSD call the SIGPOLL signal SIGIO.
}

\end{table}

Sources: 
\begin{itemize}
\item [[kill -l]] on Linux (kernel 3.0.0) and OS X
(Darwin kernel 10.8.0), 
\item Minix [[signal.h]] header file; n/a (not available) means: these
system calls have not been implemented in Minix, but the numbers were
assigned because the POSIX standard demands it.
(\url{http://faculty.qu.edu.qa/rriley/cmpt507/minix/signal_8h-source.html})
\item FreeBSD: \url{http://www.unix.com/man-page/FreeBSD/3/signal/}
\item OpenSolaris 2009.06, \url{http://www.unix.com/man-page/opensolaris/3head/signal.h/}
\end{itemize}


Over these five operating systems, only the signals SIGHUP (1), SIGINT (2),
SIGQUIT (3), SIGILL (4), SIGTRAP (5), SIGABRT (6), SIGFPE (8), SIGKILL (9),
SIGSEGV (11), SIGPIPE (13), SIGARLM (14), and SIGTERM (15) have common
numbers.


Literature: \url{https://www2.opengroup.org/ogsys/catalog/t101}, 
Single UNIX Specification, Version 4, 2013 Edition



\section{Implementation of Signals in \UlixI{}}

In order to implement signals in \UlixI{}, we need to add two sets of
functionality:

\begin{itemize}
\item methods which let a process register signal handlers (via a [[signal]] 
system call) and decide which signals to block (via a [[sigprocmask]] system
call),
\item methods to deliver signals to processes and have the process react
accordingly: for delivering, we need to implement the [[kill]] system call,
and making the process execute (and return from) the signal handler requires
changes to the scheduling code.
\end{itemize}

We will allow each process to define signal handlers for 32 signals (0--31),
so we need space for 32 addresses, and we need to store $2 \times 32$ bits
in each process for pending signals and blocked signals: A signal handler
is storead as its address,

<<kernel typedefs>>=
typedef void (*sighandler_t)(int);
@

and 32 bits fit precisely in an [[unsigned long]] integer, so we can add
two variables [[sig_pending]] and [[sig_blocked]] for storing those bits:

<<more TCB entries>>=
  sighandler_t sighandlers[32];
  unsigned long sig_pending;
  unsigned long sig_blocked;
@

For every signal number [[i]] and each state of a process there are several
possibilities:

\begin{itemize}
\item The signal is blocked; in that case the [[i]]-th bit in [[sig_blocked]] 
is 1, and the value in [[sighandlers[i]]] is irrelevant, because the signal will
cause the [[i]]-th bit of [[sig_pending]] to be set.
\item The signal is not blocked and the default action shall take place;
in that case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[SIG_DFL]].
\item The signal is not blocked, but the process ignores this signal; in that 
case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[SIG_IGN]].
\item The signal is not blocked and a signal handler [[handler()]] has been
installed; in that case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[handler]].
\end{itemize}

We use the [[SIG_DFL]] and [[SIG_IGN]] values from a Linux system
(on a 32 bit Linux system their definitions can be found in
\path!/usr/include/asm-generic/signal-defs.h!):

<<kernel declarations>>=
#define SIG_DFL ((sighandler_t)0)     /* default signal handling */
#define SIG_IGN ((sighandler_t)1)     /* ignore signal */
#define SIG_ERR ((sighandler_t)-1)    /* error code */
@

This assumes that 0 and 1 can never be the addresses of a signal handler
function.

We will not implement queues for signals; if the same process recieves
the same signal more than once before the scheduler activates it the next
time, then the extra signals will get lost. Thus, our internal [[kill]]
function is rather simple:

<<kernel functions>>=
void kill (int pid, int signo) {
  TCB *tcb;
  tcb = &thread_table[pid];
  
  if (!tcb->used) { 
    printf ("ERROR in kill: process %d does not exist\n", pid);
    return;    // process does not exist
  }
  
  switch (signo) {
    case SIGSTOP: 
      tcb->state = TSTATE_STOPPED;
      remove_from_ready_queue (pid);
      if (pid == current_task) {
        asm {
          mov eax, 66;         // yield, jump to scheduler
          int 0x80;
        }
      }
      break;
    case SIGKILL:  
      tcb->used = false;
      remove_from_ready_queue (pid);
      if (pid == current_task) {
        asm {
          mov eax, 66;         // yield, jump to scheduler
          int 0x80;
        }
      }
      break;
  };
  
  int blocked = tcb->sig_blocked & (1<<signo);
  if (!blocked && signo>=0 && signo<32) {
    tcb->sig_pending |= (1<<signo);
  }
  return;
}
@

<<kernel declarations>>=
void kill (int pid, int signo);
@

Note that we do no checking in this function, [[kill]] can be called by
the kernel itself (which may send any signal to any process), but it
cannot be called directly by a process. Sending by a process requires using
a system call, and the system call handler will check whether the process
is allowed to send the signal to the target process before calling [[kill]].

It is also classical for a process to send a signal to itself; that is
what the [[raise]] function does. We will not implement it specifically
inside the kernel, but in the user mode library: [[raise(sig)]] is the
same as [[kill(getpid(),sig)]].

Here's the code for the system call handler:

<<initialize syscalls>>=
insert_syscall (__NR_kill, syscall_kill);
@

<<syscall functions>>=
void syscall_kill (struct regs *r) {
  // ebx: pid of child to send a s signal
  // ecx: signal number
  int ok, retval;
  int target_pid = r->ebx;
  int signo      = r->ecx;
  
  ok = true;
  
  // check if target process exists
  if (!thread_table[target_pid].used) {
    // target process does not exist
    retval = -1; goto end;
  }

  // check if signal is in range 0..31
  if (signo < 0 || signo > 31) {
    retval = -1; goto end;
  }
  
  <<check if current process may send a signal>>
  if (ok) {
    kill (target_pid, signo);
    retval = 0;
  } else
    retval = -1;
  
  end:
  r->eax = retval;

  <<run scheduler if this was a raise operation>>
  return;
};
@

We only allow sending a signal if either the sender's owner has user ID 0 or 
if sender and recipient have the same owner:

<<check if current process may send a signal>>=
// TO DO!
// 
// 
ok = true;
@

If sender and receiver are the same process, we have a [[raise]] operation,
and in that case we will jump into the scheduler: we do not want the current
process to continue execution since it might have sent a [[SIGKILL]] signal
to itself.

<<run scheduler if this was a raise operation>>=
if (current_task == target_pid) {
  // calling yield (via syscall 66)
  asm {
    mov eax, 66;
    int 0x80;
  };
}
@


How can a process declare a signal handler? It just defines a function
of type [[sighandler_t]] and makes a [[signal]] syscall. The internal
function for entering a system call is the following:

<<kernel declarations>>=
sighandler_t signal (int sig, sighandler_t func);

#define SIGKILL  9
#define SIGSTOP 19
@

<<kernel functions>>=
sighandler_t signal (int sig, sighandler_t func) {
  sighandler_t old_func;
  if (sig>=0 && sig<32 && sig!=SIGKILL && sig!=SIGSTOP) {
    old_func = thread_table[current_task].sighandlers[sig];
    thread_table[current_task].sighandlers[sig] = func;
  } else {
    old_func = SIG_ERR;   // wrong signal number
  }
  return old_func;
}
@

As usual, we need to provide a system call so that a process can access
this function.

<<syscall functions>>=
void syscall_signal (struct regs *r) {
  // ebx: signal number
  // ecx: address of signal handler
  int signo         = r->ebx;
  sighandler_t func = (sighandler_t)r->ecx;

  signal (signo, func);
  r->eax = (uint)func;
  return;
};
@

<<initialize syscalls>>=
insert_syscall (__NR_signal, syscall_signal);
@



\section{Alarms}

[[alarm]] and [[setitimer]] cause the kernel to send a [[SIGALRM]]
signal to the process when a specified timer has run out.




\chapter{Booting}
\label{chap:ulix:boot}%



\chapter{Segmentation}
\label{chap:ulix:segmentation}%

We will not give a detailed description of segmentation in this
book. Just note that it is a requirement on Intel systems to
enable it.

Volume 3 of the Intel (R) 64 and IA-32 Architectures Software 
Developer's Manual \cite[p. 3-1]{intel-part3} states:

\begin{quote}
``When operating in protected mode, some form of segmentation must be used. There is no mode bit to disable segmentation.''
\end{quote}

$\longrightarrow$ Sample assembler code for setting up segmentation can be found
in the same document on p. 419 (p. 9-23).


\codesection{Implementation of Segmentation in \Ulix{}}

The following code is necessary to initialize segmentation
on an Intel CPU. 

It is taken from Bran's Kernel Development Tutorial
(Brandon Friesen,
\url{http://www.osdever.net/tutorials/view/brans-kernel-development-tutorial}).

We'll add the [[segmentation declarations]] and [[segmentation code]] to
the obvious files:

<<kernel declarations>>=
<<segmentation declarations>>
@

<<kernel functions>>=
<<segmentation code>>
@

\red
<<segmentation declarations>>=
/* Defines a GDT entry */
struct gdt_entry
{
    unsigned short limit_low;
    unsigned short base_low;
    unsigned char base_middle;
    unsigned char access;
    unsigned char granularity;
    unsigned char base_high;
} __attribute__((packed));

struct gdt_ptr
{
    unsigned short limit;
    uint base;
} __attribute__((packed));

/* Our GDT, with 3 entries, and finally our special GDT pointer */
struct gdt_entry gdt[6];
struct gdt_ptr gp;

/* This is in start.asm. We use this to properly reload
*  the new segment registers */
extern void gdt_flush();
@

<<segmentation code>>=
/* Setup a descriptor in the Global Descriptor Table */
void gdt_set_gate(int num, unsigned long base, unsigned long limit,
                  unsigned char access, unsigned char gran)
{
    /* Setup the descriptor base address */
    gdt[num].base_low = (base & 0xFFFF);
    gdt[num].base_middle = (base >> 16) & 0xFF;
    gdt[num].base_high = (base >> 24) & 0xFF;

    /* Setup the descriptor limits */
    gdt[num].limit_low = (limit & 0xFFFF);
    gdt[num].granularity = ((limit >> 16) & 0x0F);

    /* Finally, set up the granularity and access flags */
    gdt[num].granularity |= (gran & 0xF0);
    gdt[num].access = access;
}

/* Should be called by main. This will setup the special GDT
*  pointer, set up the first 3 entries in our GDT, and then
*  finally call gdt_flush() in our assembler file in order
*  to tell the processor where the new GDT is and update the
*  new segment registers */

void gdt_install()
{
    /* Setup the GDT pointer and limit */
    /* We'll have 6 GDT entries; only three are defined now */
    gp.limit = (sizeof(struct gdt_entry) * 6) - 1;
    gp.base = (int) &gdt;

    /* Our NULL descriptor */
    gdt_set_gate(0, 0, 0, 0, 0);

    /* The second entry is our Code Segment. The base address
    *  is 0, the limit is 4GBytes, it uses 4KByte granularity,
    *  uses 32-bit opcodes, and is a Code Segment descriptor.
    *  Please check the table above in the tutorial in order
    *  to see exactly what each value means */
    gdt_set_gate(1, 0, 0xFFFFFFFF, 0x9A, 0xCF);

    /* The third entry is our Data Segment. It's EXACTLY the
    *  same as our code segment, but the descriptor type in
    *  this entry's access byte says it's a Data Segment */
    gdt_set_gate(2, 0, 0xFFFFFFFF, 0x92, 0xCF);
    
    <<install GDTs for User Mode>>  /* explained later */
    
    /* Flush out the old GDT and install the new changes! */
    gdt_flush();
    
    <<flush TSS>>  /* explained later */
}
/* bkerndev - Bran's Kernel Development Tutorial
*  By:   Brandon F. (friesenb@gmail.com)
*  Desc: Interrupt Descriptor Table management
*
*  Notes: No warranty expressed or implied. Use at own risk. */
@
\black



<<segmentation assembler code>>=

@


\chapter{Small Standard Library}

Some standard functions which are normally included with an
operating system must be provided by us; here's a list of
functions that are often used. This library will also be part
of the kernel functions:

<<kernel functions>>=
<<small standard library>>
@


\section{Strings}

We will start with two string functions:

\red

<<ulix.h function prototypes>>=
size_t strlen(const char *str);
int strcmp (const char *str1, const char *str2);
int strncmp (const char *str1, const char *str2, uint n);
int atoi (char* s);
@

<<small standard library>>=
size_t strlen(const char *str)
{
    size_t retval;
    for(retval = 0; *str != '\0'; str++) retval++;
    return retval;
}

int strcmp (const char *str1, const char *str2) {
  int endoftest = false;
  int pos = 0;
  int result;
  while (! endoftest) {
    if ( str1[pos] != str2[pos] ) {
      result = false; 
      endoftest = true;
    };
    if ( (str1[pos] == (char)0) && (str2[pos] == (char)0) ) {
      result = true;
      endoftest = true;
    };
    pos++;
  };
  return result;
}

// This one is broken:
/*
int strncmp (const char *str1, const char *str2, uint n) {
  int endoftest = false;
  int pos = 0;
  int result;
  while (! endoftest) {
    if ( str1[pos] != str2[pos] ) {
      result = false; 
      endoftest = true;
    };
    if ( ((str1[pos] == (char)0) && (str2[pos] == (char)0)) || (pos==n) ) {
      result = true;
      endoftest = true;
    };
    pos++;
  };
  return result;
}
*/

int strncmp (const char *s1, const char *s2, uint n) {
  // source: http://en.wikibooks.org/wiki/C_Programming/Strings
  unsigned char uc1, uc2;
  /* Nothing to compare?  Return zero.  */
  if (n == 0)
    return 0;
  /* Loop, comparing bytes.  */
  while (n-- > 0 && *s1 == *s2) {
    /* If we've run out of bytes or hit a null, return zero
       since we already know *s1 == *s2.  */
    if (n == 0 || *s1 == '\0')
      return 0;
    s1++;
    s2++;
  }
  uc1 = (*(unsigned char *) s1);
  uc2 = (*(unsigned char *) s2);
  return ((uc1 < uc2) ? -1 : (uc1 > uc2));
}


int atoi (char* s) {
  int res = 0;
  while ( ('0' <= *s) && (*s <= '9') ) {
    res = res*10 + (*s-'0');
    s++;
  }
  return res;
};
@
\black


\section{printf and sprintf}

We use a small implementation of [[printf]] and [[sprintf]] that is
licensed unter the LGPL and available from
\url{http://www.menie.org/georges/embedded/}---there is no need to
reinvent the wheel. We modified the code so that [[printf]] can also
handle the `o' format character for octal numbers. (Thankfully the
function already knew how to print numbers to any base; we just copied
the code for `x' and changed the base 16 to 8.)

<<kernel declarations>>=
extern int printf(const char *format, ...);
extern int sprintf(const char *format, ...);
@

The code is unchanged, but we have turned the leading comments into normal text
to make them better readable.\\

\noindent \verb#/*# \\
Copyright 2001, 2002 Georges Menie (www.menie.org)\\

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU Lesser General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\\
\verb#*/#\\

\noindent \verb#/*# \\
	[[putchar]] is the only external dependency for this file,
	if you have a working [[putchar]], just remove the following
	define. If the function should be called something else,
	replace [[outbyte(c)]] by your own function call.\\
\verb#*/#\\

<<printf.c>>=
#define putchar(c) kputch(c)
extern void outportb (unsigned short _port, unsigned char _data);
#define bochs_putch(c) outportb(0xe9, c)

static void printchar(char **str, int c) {
  extern int putchar(int c);
  extern int uartputc(int c);
  
  if ((int)str == -1) {
    // debug output: goes to qemu serial console and bochs console
    if (c == 0x100) {  //  backspace
      uartputc('\b'); uartputc(' '); uartputc('\b');
    } else uartputc(c);
    bochs_putch (c);
  } else {
    if (str) {
      **str = c;
      ++(*str);
    }
    else (void)putchar(c);
  }
}

#define PAD_RIGHT 1
#define PAD_ZERO 2

static int prints(char **out, const char *string, int width, int pad)
{
	register int pc = 0, padchar = ' ';

	if (width > 0) {
		register int len = 0;
		register const char *ptr;
		for (ptr = string; *ptr; ++ptr) ++len;
		if (len >= width) width = 0;
		else width -= len;
		if (pad & PAD_ZERO) padchar = '0';
	}
	if (!(pad & PAD_RIGHT)) {
		for ( ; width > 0; --width) {
			printchar (out, padchar);
			++pc;
		}
	}
	for ( ; *string ; ++string) {
		printchar (out, *string);
		++pc;
	}
	for ( ; width > 0; --width) {
		printchar (out, padchar);
		++pc;
	}

	return pc;
}

/* the following should be enough for 32 bit int */
#define PRINT_BUF_LEN 12

static int printi(char **out, int i, int b, int sg, int width, int pad, int letbase)
{
	char print_buf[PRINT_BUF_LEN];
	register char *s;
	register int t, neg = 0, pc = 0;
	register unsigned int u = i;

	if (i == 0) {
		print_buf[0] = '0';
		print_buf[1] = '\0';
		return prints (out, print_buf, width, pad);
	}

	if (sg && b == 10 && i < 0) {
		neg = 1;
		u = -i;
	}

	s = print_buf + PRINT_BUF_LEN-1;
	*s = '\0';

	while (u) {
		t = u % b;
		if( t >= 10 )
			t += letbase - '0' - 10;
		*--s = t + '0';
		u /= b;
	}

	if (neg) {
		if( width && (pad & PAD_ZERO) ) {
			printchar (out, '-');
			++pc;
			--width;
		}
		else {
			*--s = '-';
		}
	}

	return pc + prints (out, s, width, pad);
}

static int print(char **out, int *varg)
{
	register int width, pad;
	register int pc = 0;
	register char *format = (char *)(*varg++);
	char scr[2];

	for (; *format != 0; ++format) {
		if (*format == '%') {
			++format;
			width = pad = 0;
			if (*format == '\0') break;
			if (*format == '%') goto out;
			if (*format == '-') {
				++format;
				pad = PAD_RIGHT;
			}
			while (*format == '0') {
				++format;
				pad |= PAD_ZERO;
			}
			for ( ; *format >= '0' && *format <= '9'; ++format) {
				width *= 10;
				width += *format - '0';
			}
			if( *format == 's' ) {
				register char *s = *((char **)varg++);
				pc += prints (out, s?s:"(null)", width, pad);
				continue;
			}
			if( *format == 'd' ) {
				pc += printi (out, *varg++, 10, 1, width, pad, 'a');
				continue;
			}
			if( *format == 'o' ) {
				pc += printi (out, *varg++,  8, 0, width, pad, 'a');
				continue;
			}
			if( *format == 'x' ) {
				pc += printi (out, *varg++, 16, 0, width, pad, 'a');
				continue;
			}
			if( *format == 'X' ) {
				pc += printi (out, *varg++, 16, 0, width, pad, 'A');
				continue;
			}
			if( *format == 'u' ) {
				pc += printi (out, *varg++, 10, 0, width, pad, 'a');
				continue;
			}
			if( *format == 'c' ) {
				/* char are converted to int then pushed on the stack */
				scr[0] = *varg++;
				scr[1] = '\0';
				pc += prints (out, scr, width, pad);
				continue;
			}
		}
		else {
		out:
			printchar (out, *format);
			++pc;
		}
	}
	if ( (int)out != -1 && out ) **out = '\0';
	return pc;
}

/* assuming sizeof(void *) == sizeof(int) */

int printf(const char *format, ...)
{
	register int *varg = (int *)(&format);
	return print(0, varg);
}

int debug_printf(const char *format, ...)
{
	register int *varg = (int *)(&format);
	return print((char**)-1, varg);
}

int sprintf(char *out, const char *format, ...)
{
	register int *varg = (int *)(&format);
	return print(&out, varg);
}
@



\section{Serial Port}

The following code is borrowed from the xv6 operating
system (REFERENCE), especially from source files uart.c and console.c.

<<kernel declarations>>=
// I/O Addresses of the two programmable interrupt controllers
#define IO_PIC1         0x20    // Master (IRQs 0-7)
#define IO_PIC2         0xA0    // Slave (IRQs 8-15)

#define COM1    0x3f8
#define COM2    0x2f8
static int uart;    // is there a uart?
static int uart2;   // and a second uart?
#define IRQ_SLAVE       2       // IRQ at which slave connects to master
#define IRQ_COM1        4
#define IRQ_COM2        3


// Current IRQ mask.
// Initial IRQ mask has interrupt 2 enabled (for slave 8259A).
static unsigned short irqmask = 0xFFFF & ~(1<<IRQ_SLAVE);

void microdelay (int us);
@

<<kernel functions>>=
void microdelay (int us) {
};

// SLIP changes
// static void picsetmask(unsigned short mask) {
void picsetmask(unsigned short mask) {
  irqmask = mask;
  outportb(IO_PIC1+1, mask);
  outportb(IO_PIC2+1, mask >> 8);
};

void uartinit(void) {
  char *p;

  // Turn off the FIFO
  outportb(COM1+2, 0);
 
  // 9600 baud, 8 data bits, 1 stop bit, parity off.
  outportb(COM1+3, 0x80);    // Unlock divisor
  outportb(COM1+0, 115200/9600);
  outportb(COM1+1, 0);
  outportb(COM1+3, 0x03);    // Lock divisor, 8 data bits.
  outportb(COM1+4, 0);
  outportb(COM1+1, 0x01);    // Enable receive interrupts.

  // If status is 0xFF, no serial port.
  if(inportb(COM1+5) == 0xFF)
    return;
  uart = 1;

  // Acknowledge pre-existing interrupt conditions;
  // enable interrupts.
  inportb(COM1+2);
  inportb(COM1+0);
  // picenable(IRQ_COM1);
  picsetmask(irqmask & ~(1<<IRQ_COM1));
  // ioapicenable(IRQ_COM1, 0);

  // Announce that we're here.
  for(p="xv6...\n"; *p; p++)
    uartputc(*p);
}
@

We start the serial port when booting:

<<setup serial port>>=
uartinit ();
printf ("Serial port active\n");
@


To simplify disk access, we provide something we call a serial hard disk.
Using the second serial port (of a virtual machine) we allow \UlixI{} to
connect to an external process which imitates a hard disk controller.
\UlixI{} can send simple commands to that process and in return will be
served with data (1024 byte sectors) out of a file.

<<kernel declarations>>=
void uart2putc (int);
@

<<kernel functions>>=
void uart2putc (int c) {
  int i;
  if(!uart2)
    return;
  for(i = 0; i < 128 && !(inportb(COM2+5) & 0x20); i++)
    microdelay(10);
  outportb(COM2+0, c);
}

void uart2init(void) {
  // Turn off the FIFO
  outportb(COM2+2, 0);
 
  // 9600 baud, 8 data bits, 1 stop bit, parity off.
  outportb(COM2+3, 0x80);    // Unlock divisor
  outportb(COM2+0, 115200/9600);
  outportb(COM2+1, 0);
  outportb(COM2+3, 0x03);    // Lock divisor, 8 data bits.
  outportb(COM2+4, 0);
  outportb(COM2+1, 0x01);    // Enable receive interrupts.

  // If status is 0xFF, no serial port.
  if(inportb(COM2+5) == 0xFF)
    return;
  uart2 = 1;

  // Acknowledge pre-existing interrupt conditions;
  // enable interrupts.
  inportb(COM2+2);
  inportb(COM2+0);
  picsetmask(irqmask & ~(1<<IRQ_COM2));

  // send CMD_STAT
  // uart2putc(1);
}
@

<<setup serial hard disk>>=
uart2init ();
printf ("Serial port 2 active\n");
@

We also need an interrupt handler for the second serial port; after
all, the hard disk will answer requests, so there are data coming
in on COM2.

<<kernel declarations>>=
char serial_hard_disk_buffer[1024];
int serial_hard_disk_pos = 0;

<<kernel functions>>=
static int uart2getc (void) { 
  if(!uart2)
    return -1;
  if(!(inportb(COM2+5) & 0x01))
    return -1;
  return inportb(COM2+0);
}

void serial_hard_disk_handler (struct regs *r) {
  
  // ack interrupt
  char c = uart2getc ();

  if (1==0) {
    if ((c>32)&&(c<128)) putch (c);
    else putch ('+');
  }
  serial_hard_disk_buffer[serial_hard_disk_pos++] = c; 
  
  if (serial_hard_disk_pos == 1024) {
    // serial_hard_disk_buffer[1024] = 0;
    // printf ("\nRECEIVED A SECTOR FROM THE SERIAL DISK\n");
    // printf ("BUFFER: >>%s<<\n", serial_hard_disk_buffer);
    serial_hard_disk_pos = 0;
    
    // copy buffer to proper serial hard disk buffer
    memcpy ( &(serial_disk_buffer[serial_disk_buffer_start].sector), 
             &serial_hard_disk_buffer, 1024 );
    serial_disk_reader = 0;  // reading a sector is finished
  }
}
@

And we enter this interrupt handler in the handler list...

% // SLIP MOD

<<setup serial hard disk>>=
//  irq_install_handler (IRQ_COM2, serial_hard_disk_handler);

// SLIP MOD use own isr routine
irq_install_handler (IRQ_COM1, serial_hard_disk_handler);
extern void slip_isr();
irq_install_handler (IRQ_COM2, slip_isr);
@


This is for reading ...

<<reading stuff>>=

@


\section{Screen}

Next we look at ways to write to the screen:

<<kernel declarations>>=
int csr_x, csr_y;   // Cursor position
@

\red
<<small standard library>>=
/* These define our textpointer, our background and foreground
*  colors (attributes), and x and y cursor coordinates */
unsigned short *textmemptr;
int attrib = 0x0F;
int revattrib = 0x1F;
int csr_x = 0; int csr_y = 0;

/* Scrolls the screen */
void scroll(void)
{
  unsigned blank, temp;
  term_buffer* term;
  short int target_vt;
  if (scheduler_is_active) {
    target_vt = thread_table[current_task].terminal;
    term = &vt[target_vt];
  } else {
    target_vt = KERNEL_VT;   // kernel: default write to 0
  }

    /* A blank is defined as a space... we need to give it
    *  backcolor too */
    blank = 0x20 | (attrib << 8);

    /* Row 24 is the end, this means we need to scroll up */
    if (cur_vt == target_vt && csr_y >= 24)
    {
        /* Move the current text chunk that makes up the screen
        *  back in the buffer by a line */
        temp = csr_y - 24 + 1;
        memcpy (textmemptr, textmemptr + temp * 80, (24 - temp) * 80 * 2);

        /* Finally, we set the chunk of memory that occupies
        *  the last line of text to our 'blank' character */
        memsetw (textmemptr + (24 - temp) * 80, blank, 80);
        csr_y = 24 - 1;
    }

    if (scheduler_is_active && term->y >= 24)
    {
        /* Move the current text chunk that makes up the screen
        *  back in the buffer by a line */
        temp = term->y - 24 + 1;
        memcpy ((unsigned short*)term->mem, (unsigned short*)term->mem + temp * 80, (24 - temp) * 80 * 2);

        /* Finally, we set the chunk of memory that occupies
        *  the last line of text to our 'blank' character */
        memsetw ((unsigned short*)term->mem + (24 - temp) * 80, blank, 80);
        term->y = 24 - 1;
    }
}
@

<<kernel declarations>>=
void move_csr(void);
@

<<small standard library>>=
/* Updates the hardware cursor: the little blinking line
*  on the screen under the last character pressed! */
void move_csr(void)
{
    unsigned temp;

    /* The equation for finding the index in a linear
    *  chunk of memory can be represented by:
    *  Index = [(y * width) + x] */
    temp = csr_y * 80 + csr_x;

    /* This sends a command to indicies 14 and 15 in the
    *  CRT Control Register of the VGA controller. These
    *  are the high and low bytes of the index that show
    *  where the hardware cursor is to be 'blinking'. To
    *  learn more, you should look up some VGA specific
    *  programming documents. A great start to graphics:
    *  http://www.brackeen.com/home/vga */
    outportb(0x3D4, 14);
    outportb(0x3D5, temp >> 8);
    outportb(0x3D4, 15);
    outportb(0x3D5, temp);
}

/* Clears the screen */
void cls()
{
    unsigned blank, blankrev;
    int i;

    /* Again, we need the 'short' that will be used to
    *  represent a space with color */
    blank = 0x20 | (attrib << 8);
    blankrev = 0x20 | (revattrib << 8);

    /* Sets the entire screen to spaces in our current
    *  color */
    for(i = 0; i < 24; i++)
        memsetw (textmemptr + i * 80, blank, 80);

    memsetw (textmemptr + i * 80, blankrev, 80);

    /* Update out virtual cursor, and then move the
    *  hardware cursor */
    csr_x = 0;
    csr_y = 0;
    move_csr();
}


/* Puts a character on the serial console
   code from xv6 operating system, uart.c */
   
void uartputc (int c) {
  int i;
  if(!uart)
    return;
  for(i = 0; i < 128 && !(inportb(COM1+5) & 0x20); i++)
    microdelay(10);
  outportb(COM1+0, c);
}


// mehr zu VGA-Hardware
// http://www.opensource.apple.com/source/xnu/xnu-792.13.8/osfmk/console/i386/text_console.c

/*  not needed...
#define VGA_C_START         0x0a
#define VGA_IDX_REG         0x3d4
#define VGA_IO_REG          0x3d5
#define VGA_CURSOR_CS       0x1F
#define VGA_CURSOR_ON       0x20

static char vga_cursor_start = 0;

static void enable_cursor () {
  vga_cursor_start = inportb(VGA_IO_REG) & VGA_CURSOR_CS;
  outportb(VGA_IDX_REG, VGA_C_START);
  outportb(VGA_IO_REG, vga_cursor_start | VGA_CURSOR_ON);
}
*/


/* Puts a single character on the screen */
void kputch(unsigned char c) {
  // check if we're writing to current terminal
  term_buffer* term;
  short int target_vt;
  if (scheduler_is_active) {
    target_vt = thread_table[current_task].terminal;
    term = &vt[target_vt];
  } else {
    target_vt = KERNEL_VT;   // kernel: default write to 0
  }
    
    unsigned short *where;
    unsigned att = attrib << 8;

    /* Handle a backspace, by moving the cursor back one space */
    if(c == 0x08)
    {
        if (cur_vt == target_vt) {
          if (csr_x != 0) csr_x--;
        }
        if (scheduler_is_active) {
          if (term->x != 0) term->x--;
        }
    }
    /* Handles a tab by incrementing the cursor's x, but only
    *  to a point that will make it divisible by 8 */
    else if(c == 0x09)
    {
        if (cur_vt == target_vt) {
          csr_x = (csr_x + 8) & ~(8 - 1);
        }
        if (scheduler_is_active) {
          term->x = (term->x + 8) & ~(8 - 1);
        }
    }
    /* Handles a 'Carriage Return', which simply brings the
    *  cursor back to the margin */
    else if(c == '\r')
    {
        if (cur_vt == target_vt) {
          csr_x = 0;
        }
        if (scheduler_is_active) {
          term->x = 0;
        }
    }
    /* We handle our newlines the way DOS and the BIOS do: we
    *  treat it as if a 'CR' was also there, so we bring the
    *  cursor to the margin and we increment the 'y' value */
    else if(c == '\n')
    {
        if (cur_vt == target_vt) {
          csr_x = 0;    csr_y++;
        }
        if (scheduler_is_active) {
          term->x = 0;  term->y++;
        }
    }
    /* Any character greater than and including a space, is a
    *  printable character. The equation for finding the index
    *  in a linear chunk of memory can be represented by:
    *  Index = [(y * width) + x] */
    else if(c >= ' ')
    {
        if (cur_vt == target_vt) {
          where = textmemptr + (csr_y * 80 + csr_x);
          *where = c | att;	/* Character AND attributes: color */
          csr_x++;
        }
        if (scheduler_is_active) {
          where = (unsigned short*)term->mem + (term->y * 80 + term->x);
          *where = c | att;
          term->x++;
        }
    }

    /* If the cursor has reached the edge of the screen's width, we
    *  insert a new line in there */
    if(csr_x >= 80)
    {
        if (cur_vt == target_vt) {
          csr_x = 0;    csr_y++;
        }
        if (scheduler_is_active) {
          term->x = 0;  term->y++;
        }
    }

    /* Scroll the screen if needed, and finally move the cursor */
    scroll();
    if (cur_vt == target_vt) {
      move_csr();
    };
    
    
    /* also write on serial console
       code taken from xv6 operating system, console.c
    */
    if (c == 0x100) {  //  backspace
      uartputc('\b'); uartputc(' '); uartputc('\b');
    } else uartputc(c);
    
    
    /* also write on BOCHS terminal */
    bochs_putch (c);
}



inline void putnl () {
  // write newline character on console
  
  // die ist von mir ;)
  kputch ('\n');
}





/* Uses the above routine to output a string... */
void kputs(char *text)
{
    int i;

    for (i = 0; i < strlen(text); i++)
    {
        kputch(text[i]);
    }
}
@


<<kernel declarations>>=
uint VIDEORAM = 0xB8000;
void bochs_puts(char *text);
void set_statusline (char *text);
void _set_statusline (char *text, int offset);
void set_statusline_hex (uint i);
@

\black
<<small standard library>>=
void _set_statusline (char *text, int offset) {
  int i = 0;
  uint videoaddress = VIDEORAM + 80*24*2+2*offset;  // last line of video
  while ((text[i] != 0) && (i<80)) {
    // POKEPH (videoaddress, text[i]);
    // directly write to videoaddress
    // in the beginning this will be 0xB8000, later: 0xD00B8000
    *((char*)videoaddress) = text[i];
    i++;
    videoaddress+=2;
  }
};

void set_statusline (char *text) {
  _set_statusline (text, 0);
};

void set_statusline_hex (uint i) {
  char buf[19];
  sprintf ((char*)&buf, "0x%08x    ", i);
  set_statusline ((char*)&buf);
};

void bochs_puts(char *text)
// analog to kputs(), this one uses the bochs console.
{
    int i;

    for (i = 0; i < strlen(text); i++)
    {
        bochs_putch(text[i]);
    }
}
@

<<ulix.h function prototypes>>=
void printint (int i);
@

<<small standard library>>=
/* printint ist von mir (hge), und die ist grotten schlecht ;)) */
void printint (int i) {
  char s[8];
  int rest;
  rest = i / 1000000; i = i % 1000000; s[0] = rest + '0';
  rest = i /  100000; i = i %  100000; s[1] = rest + '0';
  rest = i /   10000; i = i %   10000; s[2] = rest + '0';
  rest = i /    1000; i = i %    1000; s[3] = rest + '0';
  rest = i /     100; i = i %     100; s[4] = rest + '0';
  rest = i /      10; i = i %      10; s[5] = rest + '0';
  rest = i;                            s[6] = rest + '0';
  s[7] = (char)0;
  kputs ((char*)&s);
};
@

<<ulix.h function prototypes>>=
void printbits (uint i);
@

<<small standard library>>=
void printbits (uint i) {
  int bit = 31;
  char bits[33];
  bits[32]=0;
  for (; bit>=0; bit--) {
    bits[bit] = (char)(i%2 + (int)('0'));
    i=i/2;
  };
  kputs ((char*)&bits);
};
@

<<ulix.h function prototypes>>=
void printhex (uint i);
@

<<small standard library>>=
void printhex (uint i) {
  int digit = 7;
  char digits[11];
  digits[0]='0';
  digits[1]='x';
  char c;
  digits[10]=0;
  for (; digit>=0; digit--) {
    c = i%16;
    if (c < 10) {
      c = c+(int)'0';     // digits 0..9
    } else {
      c = c-10+(int)'A';  // digits A..F
    };
    digits[digit+2] = (char)c;
    i=i/16;
  };
  kputs ((char*)&digits);
};
@

<<ulix.h function prototypes>>=
void bochs_printhex (uint i);
void bochs_printint (int i);
@

<<small standard library>>=
void bochs_printhex (uint i) {
  int digit = 7;
  char digits[11];
  digits[0]='0';
  digits[1]='x';
  char c;
  digits[10]=0;
  for (; digit>=0; digit--) {
    c = i%16;
    if (c < 10) {
      c = c+(int)'0';     // digits 0..9
    } else {
      c = c-10+(int)'A';  // digits A..F
    };
    digits[digit+2] = (char)c;
    i=i/16;
  };
  bochs_puts ((char*)&digits);
};

void bochs_printint (int i) {
  char s[8];
  int rest;
  rest = i / 1000000; i = i % 1000000; s[0] = rest + '0';
  rest = i /  100000; i = i %  100000; s[1] = rest + '0';
  rest = i /   10000; i = i %   10000; s[2] = rest + '0';
  rest = i /    1000; i = i %    1000; s[3] = rest + '0';
  rest = i /     100; i = i %     100; s[4] = rest + '0';
  rest = i /      10; i = i %      10; s[5] = rest + '0';
  rest = i;                            s[6] = rest + '0';
  s[7] = (char)0;
  bochs_puts ((char*)&s);
};

@

<<ulix.h function prototypes>>=
void printhex_statusline (uint i);
@

<<small standard library>>=
void printhex_statusline (uint i) {
  int digit = 7;
  char digits[11];
  digits[0]='0';
  digits[1]='x';
  char c;
  digits[10]=0;
  for (; digit>=0; digit--) {
    c = i%16;
    if (c < 10) {
      c = c+(int)'0';     // digits 0..9
    } else {
      c = c-10+(int)'A';  // digits A..F
    };
    digits[digit+2] = (char)c;
    i=i/16;
  };
  set_statusline ((char*)&digits);
};
@

<<ulix.h function prototypes>>=
void printhexbyte (unsigned char i);
@

<<small standard library>>=
void printhexbyte (unsigned char i) {
  int digit = 1;
  unsigned char digits[3];
  unsigned char c;
  digits[2]=0;
  for (; digit>=0; digit--) {
    c = i%16;
    if (c < 10) {
      c = c+(int)'0';     // digits 0..9
    } else {
      c = c-10+(int)'A';  // digits A..F
    };
    digits[digit] = (char)c;
    i=i/16;
  };
  kputs ((char*)&digits);
};
@

<<ulix.h function prototypes>>=
void bochs_printhexbyte (unsigned char i); /* defined later ... */
@

<<small standard library>>=
void bochs_printhexbyte (unsigned char i) {
  int digit = 1;
  unsigned char digits[3];
  unsigned char c;
  digits[2]=0;
  for (; digit>=0; digit--) {
    c = i%16;
    if (c < 10) {
      c = c+(int)'0';     // digits 0..9
    } else {
      c = c-10+(int)'A';  // digits A..F
    };
    digits[digit] = (char)c;
    i=i/16;
  };
  bochs_puts ((char*)&digits);
};
@

<<ulix.h function prototypes>>=
void printbitsandhex (uint i);
@

<<small standard library>>=
void printbitsandhex (uint i) {
  printbits (i);
  kputch (' ');
  printhex (i);
  return;
};
@

<<ulix.h function prototypes>>=
void hexdump (uint start, uint end);
@

<<small standard library>>=
void hexdump (uint start, uint end) {
  char z;
  for (uint i=start; i < end; i+=16) {
    printhex (i);  // address
    kputs ("  ");
    // hex values
    for (int j=i; j<i+16; j++) {
      printhexbyte ((unsigned char)PEEK(j)); kputch (' ');
      if (j==i+7) kputch (' ');
    };
    kputch (' ');
    // char values
    for (int j=i; j<i+16; j++) {
      z = PEEK(j);
      if ((z>32)&&(z<127)) {
        kputch (PEEK(j));
      } else {
        kputch ('.');
      };
    };
    
    kputch ('\n');
  };
};
@

<<ulix.h function prototypes>>=
void bochs_hexdump (uint start, uint end);
@

<<small standard library>>=
void bochs_hexdump (uint start, uint end) {
  char z;
  for (int i=start; i < end; i+=16) {
    bochs_printhex (i);  // address
    bochs_puts ("  ");
    // hex values
    for (int j=i; j<i+16; j++) {
      bochs_printhexbyte ((unsigned char)PEEK(j)); bochs_putch (' ');
      if (j==i+7) bochs_putch (' ');
    };
    bochs_putch (' ');
    // char values
    for (int j=i; j<i+16; j++) {
      z = PEEK(j);
      if ((z>32)&&(z<127)) {
        bochs_putch (PEEK(j));
      } else {
        bochs_putch ('.');
      };
    };

    bochs_puts ("   ");
    bochs_printhex (i-start);  // offset
        
    bochs_putch ('\n');
  };
};

@

\red
<<small standard library>>=
/* Sets the forecolor and backcolor that we will use */
void settextcolor(unsigned char forecolor, unsigned char backcolor)
{
    /* Top 4 bytes are the background, bottom 4 bytes
    *  are the foreground color */
    attrib = (backcolor << 4) | (forecolor & 0x0F);
}

/* Sets our text-mode VGA pointer, then clears the screen for us */
void init_video(void)
{
    textmemptr = (unsigned short *)VIDEORAM;
    cls();
}
@

Here's something to fill the status line with useful stuff

<<small standard library>>=
void update_statusline () {
  char status_string[81];
  sprintf ((char*)&status_string, "%s \xb3 Free frames: %d \xb3 Free RAM: 0x%x  ", UNAME, free_frames, free_frames*PAGE_SIZE);

  set_statusline ((char*)&status_string);
};
@

\black



\chapter{Debugging Help}

\section{The Kernel Mode Shell}

In cases when user mode does not work or when we need to look at
kernel structures that are not accessible from user mode, we can
launch a simple kernel mode shell that provides a few commands.


<<ulix.h function prototypes>>=
void kgetch (char* c);
@

<<kernel declarations>>=
void kreadline (char *s, int maxlength);
@


<<kernel mode shell>>=
void command_stat() {
  printf ("MAX_ADDRESS:      %d \n", MAX_ADDRESS);
  printf ("PAGE_SIZE:        %d \n", PAGE_SIZE);
  printf ("NUMBER_OF_FRAMES: %d \n", NUMBER_OF_FRAMES);
};

uint page_desc_2_frame_address (page_desc pd);
page_desc* fill_page_desc (page_desc *pd, uint present,
                           uint writeable, uint user_accessible,
                           uint dirty, uint frame_addr);

#define KMAP(pd,frame) fill_page_desc (pd, true, true, false, false, frame)
#define UMAP(pd,frame) fill_page_desc (pd, true, true, true,  false, frame)

void command_test() {
  kputs ("current_pd as INT:              "); printbitsandhex (*(uint*)(current_pd)); kputs("\n");
  kputs ("current_pd->ptds[0].frame_addr.:"); printbitsandhex (current_pd->ptds[0].frame_addr<<12); kputs("\n");  
  kputs ("current_pt as INT:              "); printbitsandhex (*(uint*)(current_pt)); kputs("\n");
  kputs ("address of current_pd:          "); printhex ((uint)current_pd); kputs("\n");
  kputs ("address of current_pt:          "); printhex ((uint)current_pt); kputs("\n");

  kputs ("size of current_pd:             "); printhex (sizeof(*current_pd)); kputs("\n");
  kputs ("size of current_pt:             "); printhex (sizeof(*current_pt)); kputs("\n");
  
  kputs ("address of frame table:         "); printhex ((uint)ftable); putnl();
  kputs ("hexdump ftable\n");
  hexdump ((uint)&place_for_ftable, ((uint)&place_for_ftable) + 1);
};
  


extern unsigned int stack_first_address, stack_last_address;
void command_mem() {
  kputs ("kernel_pd as INT:               "); printbitsandhex (*(int*)(&kernel_pd)); kputs("\n");
  kputs ("kernel_pd.ptds[0].frame_addr:   "); printbitsandhex (kernel_pd.ptds[0].frame_addr<<12); kputs("\n");  
  kputs ("kernel_pd.ptds[768].frame_addr: "); printbitsandhex (kernel_pd.ptds[768].frame_addr<<12); kputs("\n");  
  kputs ("kernel_pd.ptds[831].frame_addr: "); printbitsandhex (kernel_pd.ptds[831].frame_addr<<12); kputs("\n");  
  kputs ("kernel_pd.ptds[832].frame_addr: "); printbitsandhex (kernel_pd.ptds[832].frame_addr<<12); kputs("\n");  
  kputs ("kernel_pd.ptds[833].frame_addr: "); printbitsandhex (kernel_pd.ptds[833].frame_addr<<12); kputs("\n");  
  kputs ("kernel_pt as INT:               "); printbitsandhex (*(int*)(&kernel_pt)); kputs("\n");
  kputs ("address of kernel_pd:           "); printhex ((uint)&kernel_pd); kputs("\n");
  kputs ("address of kernel_pt:           "); printhex ((uint)&kernel_pt); kputs("\n");
  kputs ("stack_first_address:            "); printhex ((uint)&stack_first_address); kputs("\n");
  kputs ("stack_last_address:             "); printhex ((uint)&stack_last_address); kputs("\n");
  kputs ("free_frames:                    "); printint (free_frames); kputch ('\n');
  
  uint esp;
  __asm__ __volatile__("mov %%esp, %0": "=r"(esp));
  kputs ("ESP:                            "); printhex(esp); kputs ("\n");

  
};

void command_time() {
  short int hour, min, sec;
    hour = (system_time/60/60)%24;
    min = (system_time/60)%60;
    sec = system_time%60;
    printf ("The time is %02d:%02d:%02d.\n", hour, min, sec);
};

void command_uname() {
  printf ("%s; Build: %s \n", UNAME, BUILDDATE);
};

void command_pfault() {
  uint adr = 0x108000;
  printf("Causing a Page fault: accessing address 0x%08x \n", adr);
  uint *pointer = (uint*)(adr);
  uint pagefault = *pointer;
  printbits(pagefault); kputch('\n');
  kputs("adr/4096: "); printhex(adr/4096); putnl();
  adr = pageno_to_frameno (adr/4096);
  kputs("pageno_to_frameno (adr/4096): "); printhex(adr); putnl();
  
}

void command_div0() {
  // Test for exception
  int zero = 0; int i = 10 / zero;
  kputch(i);
}

void command_hexdump() {
  // hexdump (0x00100000,0x00100060); kputch('\n');
  hexdump (0xC0100000,0xC0100060); kputch('\n');
  hexdump (0xD0100000,0xD0100060);
};

void command_check() {
  kputs ("Performing integrity checks\n");
  
  kputs ("Serching for strange pointers in page table\n");
  page_directory* pd;
  // page_table_desc* ptd;
  pd = current_pd;
  // page_table* pt;
  
  kputs ("current_pd: "); printhex ((uint)pd); putnl();
  
  // *ptd = pd->ptds[0];
  // kputs ("frame_addr of 1st c_pd entry: "); printhex (ptd->frame_addr << 12); putnl();
  
  for ( int i=0; i<770; i++) {
    kputs ("address of pd->ptds["); printint (i); kputs("]: "); 
    printhex ((uint)&(pd->ptds[i])); 
    kputs (" --> ");
    printhex (pd->ptds[i].frame_addr << 12);
    putnl();
    if (i==2) i=767;
  }
};

void command_malloc () {
  printf ("Allocating 4 M with kmalloc()\n");
  uint* p;
  p = kmalloc (4*1024*1024);
  printf ("Address of p: %x \n", p);
  printf ("Testing access to p\n");
  for (uint i = 0; i< 1024*1024; i+=1) {
    if (i%4 == 0) set_statusline_hex(i);
    p[i] = 0xAABBCCDD;
    if (p[i] != 0xAABBCCDD) printf ("Error\n");
  };

  printf ("Allocating another 16 K with kmalloc()\n");
  uint* q;
  q = kmalloc (16*1024);
  printf ("Address of q: %x \n", q);

  printf ("Allocating another 16 K with kmalloc()\n");
  uint* r;
  r = kmalloc (16*1024);
  printf ("Address of r: %x \n", q);

  hexdump ((uint)p-16, (uint)(p+12)-16);
  hexdump ((uint)q-16, (uint)(q+12)-16);
  
  printf ("Testing kfree with p, q:\n");
  kfree (p); kfree(q);
  // printf ("Testing kfree with non-malloced data:\n");
  // int j; kfree (&j);
};

void print_process_list () {  
  int i;
  printf (" PID PPID ESP      EIP      EBP      Stack    AS  State Exi Cmdline\n");
  for (i=0;i<MAX_THREADS; i++) {
    if (thread_table[i].used) {
      printf ("%4d %4d %08x %08x %08x %08x %2d  %-5s %3d %s\n",
        thread_table[i].tid,
        thread_table[i].ppid,
        thread_table[i].regs.esp,
        thread_table[i].regs.eip,
        thread_table[i].regs.ebp,
        thread_table[i].kstack,
        thread_table[i].addr_space,
        state_names[thread_table[i].state],
        thread_table[i].exitcode,
        thread_table[i].cmdline);
    }
  }
  return;
}

void command_longhelp () {
  printf ("exit         stop system (actually: relaunch shell...)\n"
          "test\n"
          "pfault, div0 test faults\n"
          "mem          show memory (frames, pages) info\n"
          "stat\n"
          "uname        show Ulix version\n"
          "hexdump      show hexdump of some memory area\n"
          "clear        clear the screen\n"
          "gf, gp, gp1k get a frame, a page, 1000 pages\n"
          "rp           release page\n"
          "bdump\n"
          "check\n"
          "malloc       test kernel malloc\n"
          "time         show time\n"
          "cloneas <n>  clone address space (argument: size)\n"
          "listas\n"
          "testas\n"
          "ps           process list\n"
          "init         start user mode (come back with Shift-Esc)\n"
          "exec         start program from disk (come back with Shift-Esc)\n"
          "testdisk     test Serial Disk Interface\n"
          "enable       (re-)enable scheduler (helpful?)\n"
          "ls           list contents of floppy fdb\n"
  );
          
}
#define SHELL_COMMANDS "help, exit, test, pfault, div0, mem, stat, uname, hexdump, clear, gf, gp, rp, gp1k, bdump, check, malloc, time, cloneas x, listas, testas, init, exec, testdisk, enable, longhelp, ls, ps"

void run_command (char* s) {
  if ( strcmp (s, "mem2") ) {
    command_mem();
  } else if ( strcmp (s, "stat") ) {
    command_stat();
  } else if ( strcmp (s, "uname") ) {
    command_uname();
  } else if ( strcmp (s, "help") ) {
    printf ("Commands: %s \n", SHELL_COMMANDS);
  } else if ( strcmp (s, "test") ) {
    command_test();
  } else if ( strcmp (s, "init") ) {
    printf ("Entering user mode, starting init process\n");
    create_init_process();
  } else if ( strcmp (s, "pfault") ) {
    command_pfault();
  } else if ( strcmp (s, "div0") ) {
    command_div0();
  } else if ( strcmp (s, "hexdump") ) {
    command_hexdump();
  } else if ( strcmp (s, "check") ) {
    command_check();
  } else if ( strcmp (s, "clear") ) {
    cls();
  } else if ( strcmp (s, "usermode") ) {
    run_first_process();
  } else if ( strcmp (s, "mem") ) {
    print_page_table();
  } else if ( strcmp (s, "ps") ) {
    print_process_list();
  } else if ( strcmp (s, "mem2") ) {
    command_mem();
  } else if ( strcmp (s, "malloc") ) {
    command_malloc();
  } else if ( strcmp (s, "longhelp") ) {
    command_longhelp();
  } else if ( strcmp (s, "enable") ) {
    ENABLE_SCHEDULER;
  } else if ( strncmp (s, "cloneas", 7) == 0 ) {
    // clone address space
    int arg;
    arg = atoi (s+8);
    if (arg==0) return; // skip command
    printf ("cloneas %d\n", arg);
    int i = create_new_address_space(arg);
    activate_address_space (i);
    printf ("Address space %d activated\n", i);
   
  } else if ( strcmp (s, "testas") ) {
    int i = create_new_address_space(1);  // create AS #1
    activate_address_space (i);
    i = create_new_address_space(1);  // create AS #2
    activate_address_space (i);
    goto done;
    create_new_address_space(1);  // create AS #3
    goto done;
    uint* testptr = (uint*)(0x0);
    activate_address_space(1); // *testptr = 5;
    printf ("DEBUG: AS #1: 0x0 -> 0x%x\n", mmu(1,0x0));

    activate_address_space(1); *testptr = 10;
    activate_address_space(2); *testptr = 20;
    activate_address_space(3); *testptr = 30;

    activate_address_space(1); printf ("AS #1: *test = %d\n", *testptr);
    activate_address_space(2); printf ("AS #2: *test = %d\n", *testptr);
    activate_address_space(3); printf ("AS #3: *test = %d\n", *testptr);
    activate_address_space(0); 
        
    printf ("AS #0: 0x0 -> 0x%x \n", mmu(0,0x0));
    printf ("AS #1: 0x0 -> 0x%x \n", mmu(1,0x0));
    printf ("AS #2: 0x0 -> 0x%x \n", mmu(2,0x0));
    printf ("AS #3: 0x0 -> 0x%x \n", mmu(3,0x0));
    printf ("Activated \n");
    done: ;
  } else if ( strcmp (s, "listas") ) {
    list_address_spaces();
  } else if ( strcmp (s, "bdump") ) {
    kputs ("Memory Dump to Bochs console - you will see nothing in qemu.\n");
    kputs ("This will take several minutes...\n");
    bochs_puts ("Memory Dump: GDT\n");
    // bochs_hexdump(0xc0000000,0xc03fdfff);
    bochs_hexdump((uint)&gdt,(uint)&gdt+sizeof(gdt));
    bochs_puts ("Memory Dump: current_pd\n");
    bochs_hexdump((uint)current_pd,(uint)current_pd+sizeof(*current_pd));
    bochs_puts ("Memory Dump: current_pt\n");
    bochs_hexdump((uint)current_pt,(uint)current_pt+sizeof(*current_pt));
    
  } else if ( strcmp (s, "gf") ) {
    uint newframeid = request_new_frame();
    kputs ("New frame ID: "); printint (newframeid); kputch ('\n');
  } else if ( strcmp (s, "gp") ) {
    /* uint* page = */ request_new_page(0);
    // kputs (", Page @ "); printhex ((uint)page); kputch ('\n');
  } else if ( strcmp (s, "rp") ) {
    printf ("releasing page range 0xc03fe..0xc07e6 \n");
    // release_page (0xc03fe);
    release_page_range (0xc03fe,0xc07e6);
  } else if ( strcmp (s, "time") ) {
    command_time();
  } else if ( strcmp (s, "gp1k") ) {
    char buf[20];
    uint* page;
    for (int i=0; i<1024; i++) {
      sprintf ((char*)&buf, "Create: %d   ", i);
      set_statusline ((char*)&buf);
      page = request_new_page(0);
      // kputs (", Page @ "); printhex ((uint)page); kputch ('\n');
    }
  } else if ( strcmp (s, "gp10k") ) {
    char buf[20];
    uint* page;
    for (int i=0; i<10*1024; i++) {
      sprintf ((char*)&buf, "Create: %d   ", i);
      set_statusline ((char*)&buf);
      page = request_new_page(0);
      // kputs (", Page @ "); printhex ((uint)page); kputch ('\n');
    }
  } 
    else if ( strcmp (s, "testdisk") ) {

    /*
    char buf_array[1024];
    char *buf;
    buf = &buf_array;
    printf ("address of buf: %x\n", buf);
    kernel_read_sector (1, buf);
    kernel_read_sector (1, buf);
    kernel_read_sector (1, buf);
    */

    show_superblock();
    create_null_file(4000, "test0002.txt");
    list_dir (1);;

    /*
    uart2putc(CMD_STAT);
    // printf ("start: %d, end: %d\n", serial_disk_buffer_start, serial_disk_buffer_end);
    printf ("Going to send a sector.\n");
    char buf[1024];
    memcpy (&buf, "Hallo Test!\0", 13);
    kernel_write_sector (600, (char*)&buf);

    printf ("Going to request two sectors.\n");
    kernel_read_sector (0, (char*)&buf);
    kernel_read_sector (0, (char*)&buf);

    // printf ("start: %d, end: %d\n", serial_disk_buffer_start, serial_disk_buffer_end)
    */
    
  }
    else if ( strcmp (s, "exec") ) {
      start_program_from_disk ("/sh");
      activate_address_space (1);
      ENABLE_SCHEDULER;
      cpu_usermode (0, 64*1024);
  }
    else if ( strcmp (s, "ls") ) {
      simplefs_ls ();
      asm ("sti");
  }  
    
    else if ( strcmp (s, "") ) {
    // no command
    ;
  } else {
    printf ("Error: >%s< not found\n", s);
  }
  return;
}




void simple_shell() {
  char s[101];

  system_kbd_pos = 0;
  system_kbd_lastread = -1;
  system_kbd_count = 0;

  printf ("Ulix Shell. Commands: %s\n", SHELL_COMMANDS);
  printf ("Press [Esc] to display page table.\n");
  printf ("Press [Shift+Esc] to relaunch shell when in user mode.\n");
  printf ("Press [Shift+n] to switch to address space n (0..9).\n");
  for (;;) {
    update_statusline ();
    kputs ("esser@ulix:~$ ");
    kreadline ((char*)&s,sizeof(s)-1);
    if ( strcmp ((char*)&s, "exit") ) return;
    run_command ((char*)&s);
  };
};
@







\chapter{Clean me up!}

Here's some support for the Bochs emulator:

The macro [[bochs_putch()]] writes a character onto the Bochs
console (the terminal from which Bochs was started). In order to
use it, the line

<<bochs output configuration>>=
port_e9_hack: enabled=1
@

must be put into the Bochs config file.

<<ulix.h>>=
#define bochs_putch(c) outportb(0xe9, c)
@

The header file:

\red
<<ulix.h>>=
/* bkerndev - Bran's Kernel Development Tutorial
*  By:   Brandon F. (friesenb@gmail.com)
*  Desc: Global function declarations and type definitions
*
*  Notes: No warranty expressed or implied. Use at own risk. */
#ifndef __SYSTEM_H
#define __SYSTEM_H

typedef int size_t;
typedef unsigned int uint;   // short name for "unsigned int"

/* This defines what the stack looks like after an ISR was running */
struct regs {
  uint gs, fs, es, ds;
  uint edi, esi, ebp, esp, ebx, edx, ecx, eax;
  uint int_no, err_code;
  uint eip, cs, eflags, useresp, ss;
};

// following code was modified:
// regs_syscall is now identical to regs, so remove it
// originally it did not have the int_no and err_code inside
// (8 bytes less)

struct regs_syscall {
  uint gs, fs, es, ds;
  uint edi, esi, ebp, esp, ebx, edx, ecx, eax;
  uint int_no, err_code;
  uint eip, cs, eflags, useresp, ss;    
};

<<ulix.h function prototypes>>

/* MAIN.C */
extern void *memcpy(void *dest, const void *src, size_t count);
extern void *strncpy(void *dest, const void *src, size_t count);
// int strlen (const char* str);  // already defined elsewhere
extern void *memset(void *dest, char val, size_t count);
extern unsigned short *memsetw(unsigned short *dest, unsigned short val, size_t count);
extern size_t strlen(const char *str);
extern unsigned char inportb (unsigned short _port);
extern void outportb (unsigned short _port, unsigned char _data);

/* CONSOLE.C */
extern void init_video(void);
extern void kputs(char *text);
extern void kputch(unsigned char c);
extern void putnl ();
extern void cls();

/* GDT.C */
extern void gdt_set_gate(int num, unsigned long base, unsigned long limit, unsigned char access, unsigned char gran);
extern void gdt_install();

/* IDT.C */
extern void idt_set_gate(unsigned char num, unsigned long base, unsigned short sel, 
                         unsigned char flags);
extern void idt_install();

/* ISRS.C */
extern void isrs_install();

/* IRQ.C */
extern void irq_install_handler(int irq, void (*handler)(struct regs *r));
extern void irq_uninstall_handler(int irq);
extern void irq_install();

/* TIMER.C */
extern void timer_wait(int ticks);
extern void timer_install();

/* KEYBOARD.C */
extern void keyboard_install();

#endif


// Buffer for keyboard input
#define SYSTEM_KBD_BUFLEN 32
#define TERMINALS 10
typedef struct {
  char kbd[SYSTEM_KBD_BUFLEN+1];
  int kbd_pos;
  int kbd_lastread;
  int kbd_count;
} terminal_t;

terminal_t terminals[TERMINALS] = { 0 };

char *system_kbd = terminals[0].kbd;

// char system_kbd[SYSTEM_KBD_BUFLEN+1];
int system_kbd_pos;
int system_kbd_lastread;
int system_kbd_count;
@
\black


The assembler code:

\red
<<start.asm>>=
; bkerndev - Bran's Kernel Development Tutorial
; By:   Brandon F. (friesenb@gmail.com)
; Desc: Kernel entry point, stack, and Interrupt Service Routines.
;
; Notes: No warranty expressed or implied. Use at own risk.
;
; This is the kernel's entry point. We could either call main here,
; or we can use this to setup the stack or other nice stuff, like
; perhaps setting up the GDT and segments. Please note that interrupts
; are disabled at this point: More on interrupts later!
[BITS 32]
global start

[section .setup]
start:

; BEGIN higher half trick 
	; here's the trick: we load a GDT with a base address
	; of 0x40000000 for the code (0x08) and data (0x10) segments
	lgdt [trickgdt]
	mov ax, 0x10
	mov ds, ax
	mov es, ax
	mov fs, ax
	mov gs, ax
	mov ss, ax
 
	; jump to the higher half kernel
	jmp 0x08:higherhalf

[section .text] 
higherhalf:
; END higher half trick 

    mov esp, _sys_stack     ; This points the stack to our new stack area
    jmp stublet

; This part MUST be 4byte aligned, so we solve that issue using 'ALIGN 4'
ALIGN 4
mboot:
    ; Multiboot macros to make a few lines later more readable
    MULTIBOOT_PAGE_ALIGN	equ 1<<0
    MULTIBOOT_MEMORY_INFO	equ 1<<1
    MULTIBOOT_AOUT_KLUDGE	equ 1<<16
    MULTIBOOT_HEADER_MAGIC	equ 0x1BADB002
    MULTIBOOT_HEADER_FLAGS	equ MULTIBOOT_PAGE_ALIGN | MULTIBOOT_MEMORY_INFO | MULTIBOOT_AOUT_KLUDGE
    MULTIBOOT_CHECKSUM	equ -(MULTIBOOT_HEADER_MAGIC + MULTIBOOT_HEADER_FLAGS)
    EXTERN code, bss, end

    ; This is the GRUB Multiboot header. A boot signature
    dd MULTIBOOT_HEADER_MAGIC
    dd MULTIBOOT_HEADER_FLAGS
    dd MULTIBOOT_CHECKSUM
    
    ; AOUT kludge - must be physical addresses. Make a note of these:
    ; The linker script fills in the data for these ones!
    dd mboot
    dd code
    dd bss
    dd end
    dd start

; This is an endless loop here. Make a note of this: Later on, we
; will insert an 'extern _main', followed by 'call _main', right
; before the 'jmp $'.
stublet:
    push esp  ; save current ESP
    push ebx

    extern main
    call main
    jmp $

; This will set up our new segment registers. We need to do
; something special in order to set CS. We do what is called a
; far jump. A jump that includes a segment as well as an offset.
; This is declared in C as 'extern void gdt_flush();'
global gdt_flush
extern gp
gdt_flush:
    lgdt [gp]
    mov ax, 0x10
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov ss, ax
    jmp 0x08:flush2
flush2:
    ret

; Loads the IDT defined in 'idtp' into the processor.
; This is declared in C as 'extern void idt_load();'
global idt_load
extern idtp
idt_load:
    lidt [idtp]
    ret

; Returns EIP register    
global get_eip
get_eip:
  pop eax
  push eax
  ret
  jmp eax 

; In just a few pages in this tutorial, we will add our Interrupt
; Service Routines (ISRs) right here!
global isr0, isr1, isr2, isr3, isr4, isr5, isr6, isr7
global isr8, isr9, isr10, isr11, isr12, isr13, isr14, isr15
global isr16, isr17, isr18, isr19, isr20, isr21, isr22, isr23
global isr24, isr25, isr26, isr27, isr28, isr29, isr30, isr31

;  0: Divide By Zero Exception
isr0:
    cli
    push byte 0
    push byte 0
    jmp isr_common_stub

;  1: Debug Exception
isr1:
    cli
    push byte 0
    push byte 1
    jmp isr_common_stub

;  2: Non Maskable Interrupt Exception
isr2:
    cli
    push byte 0
    push byte 2
    jmp isr_common_stub

;  3: Int 3 Exception
isr3:
    cli
    push byte 0
    push byte 3
    jmp isr_common_stub

;  4: INTO Exception
isr4:
    cli
    push byte 0
    push byte 4
    jmp isr_common_stub

;  5: Out of Bounds Exception
isr5:
    cli
    push byte 0
    push byte 5
    jmp isr_common_stub

;  6: Invalid Opcode Exception
isr6:
    cli
    push byte 0
    push byte 6
    jmp isr_common_stub

;  7: Coprocessor Not Available Exception
isr7:
    cli
    push byte 0
    push byte 7
    jmp isr_common_stub

;  8: Double Fault Exception (With Error Code!)
isr8:
    cli
    push byte 8
    jmp isr_common_stub

;  9: Coprocessor Segment Overrun Exception
isr9:
    cli
    push byte 0
    push byte 9
    jmp isr_common_stub

; 10: Bad TSS Exception (With Error Code!)
isr10:
    cli
    push byte 10
    jmp isr_common_stub

; 11: Segment Not Present Exception (With Error Code!)
isr11:
    cli
    push byte 11
    jmp isr_common_stub

; 12: Stack Fault Exception (With Error Code!)
isr12:
    cli
    push byte 12
    jmp isr_common_stub

; 13: General Protection Fault Exception (With Error Code!)
isr13:
    cli
    push byte 13
    jmp isr_common_stub

; 14: Page Fault Exception (With Error Code!)
isr14:
    cli
    push byte 14
    jmp isr_common_stub

; 15: Reserved Exception
isr15:
    cli
    push byte 0
    push byte 15
    jmp isr_common_stub

; 16: Floating Point Exception
isr16:
    cli
    push byte 0
    push byte 16
    jmp isr_common_stub

; 17: Alignment Check Exception
isr17:
    cli
    push byte 0
    push byte 17
    jmp isr_common_stub

; 18: Machine Check Exception
isr18:
    cli
    push byte 0
    push byte 18
    jmp isr_common_stub

; 19: Reserved
isr19:
    cli
    push byte 0
    push byte 19
    jmp isr_common_stub

; 20: Reserved
isr20:
    cli
    push byte 0
    push byte 20
    jmp isr_common_stub

; 21: Reserved
isr21:
    cli
    push byte 0
    push byte 21
    jmp isr_common_stub

; 22: Reserved
isr22:
    cli
    push byte 0
    push byte 22
    jmp isr_common_stub

; 23: Reserved
isr23:
    cli
    push byte 0
    push byte 23
    jmp isr_common_stub

; 24: Reserved
isr24:
    cli
    push byte 0
    push byte 24
    jmp isr_common_stub

; 25: Reserved
isr25:
    cli
    push byte 0
    push byte 25
    jmp isr_common_stub

; 26: Reserved
isr26:
    cli
    push byte 0
    push byte 26
    jmp isr_common_stub

; 27: Reserved
isr27:
    cli
    push byte 0
    push byte 27
    jmp isr_common_stub

; 28: Reserved
isr28:
    cli
    push byte 0
    push byte 28
    jmp isr_common_stub

; 29: Reserved
isr29:
    cli
    push byte 0
    push byte 29
    jmp isr_common_stub

; 30: Reserved
isr30:
    cli
    push byte 0
    push byte 30
    jmp isr_common_stub

; 31: Reserved
isr31:
    cli
    push byte 0
    push byte 31
    jmp isr_common_stub

; We call a C function in here. We need to let the assembler know
; that 'fault_handler' exists in another file
extern fault_handler

; This is our common ISR stub. It saves the processor state, sets
; up for kernel mode segments, calls the C-level fault handler,
; and finally restores the stack frame.
isr_common_stub:
    pusha
    push ds
    push es
    push fs
    push gs
    mov ax, 0x10
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov eax, esp
    push eax
    mov eax, fault_handler
    call eax
    pop eax
    pop gs
    pop fs
    pop es
    pop ds
    popa
    add esp, 8
    iret

global irq0, irq1, irq2, irq3, irq4, irq5, irq6, irq7
global irq8, irq9, irq10, irq11, irq12, irq13, irq14, irq15

; 32: IRQ0
irq0:  cli
       push byte 0
       push byte 32
       jmp irq_common_stub

; 33: IRQ1
irq1:  cli
       push byte 0
       push byte 33
       jmp irq_common_stub

; 34: IRQ2
irq2:  cli
       push byte 0
       push byte 34
       jmp irq_common_stub

; 35: IRQ3
irq3:  cli
       push byte 0
       push byte 35
       jmp irq_common_stub

; 36: IRQ4
irq4:  cli
       push byte 0
       push byte 36
       jmp irq_common_stub

; 37: IRQ5
irq5:  cli
       push byte 0
       push byte 37
       jmp irq_common_stub

; 38: IRQ6
irq6:  cli
       push byte 0
       push byte 38
       jmp irq_common_stub

; 39: IRQ7
irq7:  cli
       push byte 0
       push byte 39
       jmp irq_common_stub

; 40: IRQ8
irq8:  cli
       push byte 0
       push byte 40
       jmp irq_common_stub

; 41: IRQ9
irq9:  cli
       push byte 0
       push byte 41
       jmp irq_common_stub

; 42: IRQ10
irq10: cli
       push byte 0
       push byte 42
       jmp irq_common_stub

; 43: IRQ11
irq11: cli
       push byte 0
       push byte 43
       jmp irq_common_stub

; 44: IRQ12
irq12: cli
       push byte 0
       push byte 44
       jmp irq_common_stub

; 45: IRQ13
irq13: cli
       push byte 0
       push byte 45
       jmp irq_common_stub

; 46: IRQ14
irq14: cli
       push byte 0
       push byte 46
       jmp irq_common_stub

; 47: IRQ15
irq15: cli
       push byte 0
       push byte 47
       jmp irq_common_stub

extern irq_handler

irq_common_stub:
    pusha
    push ds
    push es
    push fs
    push gs

    mov ax, 0x10
    mov ds, ax
    mov es, ax
    mov fs, ax
    mov gs, ax
    mov eax, esp

    push eax
    mov eax, irq_handler
    call eax
    pop eax

    pop gs
    pop fs
    pop es
    pop ds
    popa
    add esp, 8
    iret

; BEGIN higher half trick 

[section .setup] ; tells the assembler to include this data in the '.setup' section
 
trickgdt:
	dw gdt_end - gdt - 1 ; size of the GDT
	dd gdt ; linear address of GDT
 
gdt:
	dd 0, 0							; null gate
	db 0xFF, 0xFF, 0, 0, 0, 10011010b, 11001111b, 0x40	; code selector 0x08: base 0x40000000, limit 0xFFFFFFFF, type 0x9A, granularity 0xCF
	db 0xFF, 0xFF, 0, 0, 0, 10010010b, 11001111b, 0x40	; data selector 0x10: base 0x40000000, limit 0xFFFFFFFF, type 0x92, granularity 0xCF
 
gdt_end:

; END higher half trick 


<<tss flush code in start.asm>>


; Here is the definition of our BSS section. Right now, we'll use
; it just to store the stack. Remember that a stack actually grows
; downwards, so we declare the size of the data before declaring
; the identifier '_sys_stack'

global stack_first_address
global stack_last_address

SECTION .bss
stack_first_address:
    resb 32*1024               ; This reserves 8KBytes of memory here
stack_last_address:
_sys_stack:
@
\black



\chapter{User Mode Library and Programs}

In this chapter we present a library that lets user mode applications
access the kernel functions.

\section{The Library}

The library source code consists of a header file [[ulixlib.h]] and a source
file [[ulixlib.c]].

<<user/ulixlib.h>>=
int printf (const char *format, ...);
int sprintf(char *out, const char *format, ...);

@

We start with code for printing text ([[printf]]). We first define 
a simple function for printing one character:

<<user/ulixlib.c>>=
#include "ulixlib.h"

void uputch (int c) {
  asm (".intel_syntax noprefix; \
    mov eax, 0x1001; /* system call number for print */ \
    int 0x80; \
    .att_syntax" : : "b"(c) );
};
@

Here we include (once again) the [[printf]] code which is supplied
by Georges Menie:

<<user/ulixlib.c>>=
// printf and sprintf: (c) 
/*
	Copyright 2001, 2002 Georges Menie (www.menie.org)

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU Lesser General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/

/*
	putchar is the only external dependency for this file,
	if you have a working putchar, just remove the following
	define. If the function should be called something else,
	replace outbyte(c) by your own function call.
*/
#define putchar(c) uputch(c)

static void printchar(char **str, int c)
{
	// extern int putchar(int c);
	if (str) {
		**str = c;
		++(*str);
	}
	else (void)putchar(c);
}

#define PAD_RIGHT 1
#define PAD_ZERO 2

static int prints(char **out, const char *string, int width, int pad)
{
	register int pc = 0, padchar = ' ';

	if (width > 0) {
		register int len = 0;
		register const char *ptr;
		for (ptr = string; *ptr; ++ptr) ++len;
		if (len >= width) width = 0;
		else width -= len;
		if (pad & PAD_ZERO) padchar = '0';
	}
	if (!(pad & PAD_RIGHT)) {
		for ( ; width > 0; --width) {
			printchar (out, padchar);
			++pc;
		}
	}
	for ( ; *string ; ++string) {
		printchar (out, *string);
		++pc;
	}
	for ( ; width > 0; --width) {
		printchar (out, padchar);
		++pc;
	}

	return pc;
}

/* the following should be enough for 32 bit int */
#define PRINT_BUF_LEN 12

static int printi(char **out, int i, int b, int sg, int width, int pad, int letbase)
{
	char print_buf[PRINT_BUF_LEN];
	register char *s;
	register int t, neg = 0, pc = 0;
	register unsigned int u = i;

	if (i == 0) {
		print_buf[0] = '0';
		print_buf[1] = '\0';
		return prints (out, print_buf, width, pad);
	}

	if (sg && b == 10 && i < 0) {
		neg = 1;
		u = -i;
	}

	s = print_buf + PRINT_BUF_LEN-1;
	*s = '\0';

	while (u) {
		t = u % b;
		if( t >= 10 )
			t += letbase - '0' - 10;
		*--s = t + '0';
		u /= b;
	}

	if (neg) {
		if( width && (pad & PAD_ZERO) ) {
			printchar (out, '-');
			++pc;
			--width;
		}
		else {
			*--s = '-';
		}
	}

	return pc + prints (out, s, width, pad);
}

static int print(char **out, int *varg)
{
	register int width, pad;
	register int pc = 0;
	register char *format = (char *)(*varg++);
	char scr[2];

	for (; *format != 0; ++format) {
		if (*format == '%') {
			++format;
			width = pad = 0;
			if (*format == '\0') break;
			if (*format == '%') goto out;
			if (*format == '-') {
				++format;
				pad = PAD_RIGHT;
			}
			while (*format == '0') {
				++format;
				pad |= PAD_ZERO;
			}
			for ( ; *format >= '0' && *format <= '9'; ++format) {
				width *= 10;
				width += *format - '0';
			}
			if( *format == 's' ) {
				register char *s = *((char **)varg++);
				pc += prints (out, s?s:"(null)", width, pad);
				continue;
			}
			if( *format == 'd' ) {
				pc += printi (out, *varg++, 10, 1, width, pad, 'a');
				continue;
			}
			if( *format == 'x' ) {
				pc += printi (out, *varg++, 16, 0, width, pad, 'a');
				continue;
			}
			if( *format == 'X' ) {
				pc += printi (out, *varg++, 16, 0, width, pad, 'A');
				continue;
			}
			if( *format == 'u' ) {
				pc += printi (out, *varg++, 10, 0, width, pad, 'a');
				continue;
			}
			if( *format == 'c' ) {
				/* char are converted to int then pushed on the stack */
				scr[0] = *varg++;
				scr[1] = '\0';
				pc += prints (out, scr, width, pad);
				continue;
			}
		}
		else {
		out:
			printchar (out, *format);
			++pc;
		}
	}
	if (out) **out = '\0';
	return pc;
}

/* assuming sizeof(void *) == sizeof(int) */

int printf(const char *format, ...)
{
	register int *varg = (int *)(&format);
	return print(0, varg);
}

int sprintf(char *out, const char *format, ...)
{
	register int *varg = (int *)(&format);
	return print(&out, varg);
}
@

Here ends the code taken from Georges Menie.




\section{Applications}

Bla

\subsection{ush -- the Ulix Shell}

Bla


\chapter{Linux Tools}

In order to test \UlixI{}, several tools have been developed which
setup an environment in which \shellcmd{qemu} can run the kernel.
This includes formatting two virtual hard disks with a Minix 
filesystem and as swap.

\comment{to be done}


\section{ulix-mkfs.minix}

Linux already includes a \shellcmd{mkfs.minix} tool, but we have
rewritten it in a simplified way, since we do not need it to access
real partitions. Instead it will write a Minix filesystem into a file.
The tool can optionally create the file when the option
\shellcmd{-size N} is supplied.

\comment{to be done}


\section{ulix-mkswap}

The \shellcmd{mkswap} tool does only one thing: It writes a \UlixI{}
Swap signature into the first block of the file.
The tool can optionally create the file when the option
\shellcmd{-size N} is supplied.

\comment{to be done}


\section{ulix-install}

This command copies a few standard files onto a \UlixI{} disk image. It can
fail if the image is full. The tool mounts the disk image using Linux'
Minix filesystem driver, for this reason it requires root privileges on
the Linux machine (in order to call \shellcmd{mount} and \shellcmd{umount}).

\comment{to be done}


\section{bindump}

Similar to hexdump, here's an implementation of bindump. The tool has
an option [[-r]] which reverses the output order of 8-bit-strings (bytes;
e.\,g. 10100000 instead of 00000101). bindump accepts no filename, you
must use it as a filter (e.\,g. [[bindump -r < image.img]]).

<<bindump source code>>=
// bindump.c
// Hans-Georg Esser

// nur als Filter verwenden:
//   bindump < image.img      (fuer normale Ausgabe)
//   bindump -r < image.img   (fuer reverse-Ausgabe)
//   cat image.img | bindump

#include <stdio.h>

int rev;  // reverse output?

void binwrite (unsigned char c) {
  unsigned int v = (unsigned int)c;
  int i;
  for (i=7; i>-1; i--) {
    if (rev==0)
      printf ("%d", (v>>i)%2);       // normale Ausgabe
    else
      printf ("%d", (v>>(7-i))%2);   // reverse
  };
  printf (" ");
}

void bindump (unsigned char* bytes, int offset, int num) {
  int i; unsigned char c;
  printf ("%08x  ", offset);
  for (i=0; i<num; i++) {
    binwrite (bytes[i]);
  };
  printf (" ");
  for (i=0; i<num; i++) {
    c = bytes[i];
    if ((c>31)&&(c<128))
      printf ("%c",c);
    else
      printf (".");
  };
  printf ("\n");
  return;
};

int main (int argc, char *argv[]) {
  unsigned char buf[8];
  int count;
  int pos = 0;
  rev = 0;  // reverse?
  // Test, ob Option -r gesetzt:
  if (argc>1)
    if (!strcmp(argv[1],"-r"))
      rev = 1;  // reverse!
  do {
    count = read (0, &buf, 8);
    if (count>0) bindump ((unsigned char*)&buf, pos, count);
    pos += 8;
  } while (count > 0);
  return 0;
}
@


\section{Setting up the Environment}

In order to start using \UlixI{} the following commands are sufficient:

<<setup-ulix-environment>>=
ulix-mkfs.minix -size 100 /tmp/ulixhd.img
sudo ulix-install /tmp/ulixhd.img
ulix-mkswap -size 32 /tmp/ulixswap.img
qemu -kernel ulix.img -hda /tmp/ulixhd.img -hdb /tmp/ulixswap.img
@



\section{My Assembler Parser}

<<assembler-parser.py>>=
#!/usr/bin/python

"""
This Parser replaces Code of the following form:

asm {
  starta: mov eax, 0x1001   // comment
  mov ebx, 'A'              // more comment
  int 0x80
}

with code that looks like this:

asm ("\
  .intel_syntax noprefix; \
  starta: mov eax, 0x1001; \
  mov ebx, 'A'; \
  int 0x80; \
  .att_syntax; \
");

It also understands  asm volatile.

What it cannot cope with is variable / register usage.

Note that it does not change the number or position
of code lines.
"""

from sys import argv, exit

if len(argv)<3:
  print ("Error: give input and output filenames")
  exit (1)
infilename = argv[1]
outfilename = argv[2]


global ReplaceMode
ReplaceMode = False

def count_leading_blanks (line):
  counter = 0
  while line and (line[0] == " "):
    counter+=1
    line = line[1:]
  return counter

def remove_trailing_blanks (line):
  if (line == ""): return line
  while (line != "") and (line[-1] == " "):
    line = line[:-1]
  return line
  
def transform (line):
  global ReplaceMode
  if ReplaceMode:
    if "}" in line:
      # reached the end; skip this line
      blanks = count_leading_blanks (line)
      line = (blanks+2) * " " + '.att_syntax; ");'
      ReplaceMode = False
      return line
    else:  
      # do something to the line
      if '//' in line:
        # remove comment
        pos = line.find ("//")
        line = line[:pos]
        line = remove_trailing_blanks (line)
      line = line + "; \\"
      return line


def process (line):
  global ReplaceMode
  line = line[:-1]
  if ReplaceMode:
    # we're already in ReplaceMode, working on assembler
    line = transform (line)
  else:
    # we're in normal C mode, check for asm {
    if ("asm volatile{" in line) or ("asm volatile {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm volatile (".intel_syntax noprefix; \\'
      ReplaceMode = True
    elif ("asm{" in line) or ("asm {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm (".intel_syntax noprefix; \\'
      ReplaceMode = True
    
  return line

infile  = file (infilename,  "r")
outfile = file (outfilename, "w");

EndOfLoop = False

for line in infile:
  # line = infile.readline()[:-1]
  # if (not line): EndOfLoop = True   # end loop
  line = process (line)
  outfile.write (line+"\n")

infile.close()
outfile.close()
@


\chapter{Stuff. For the thesis? Or not?}

\section{Toolchain for Mac OS}

Install GCC Cross Compiler on Mac OS (documentation: 
\url{http://www.fanofblitzbasic.de/prettyos/PrettyOSMacOSX.pdf}),
get file
\url{http://www.fanofblitzbasic.de/prettyos/i586-elf-binutils-gcc-macos.zip}

Install GMP and MPFR:

\lstset{language=bash,breaklines=true,basicstyle=\ttfamily}
\begin{lstlisting}
port install gmp
port install mpfr
\end{lstlisting}

Set some links:

\begin{lstlisting}
ln -s /opt/local/var/macports/software/mpfr/3.0.0-p8_0/opt/local/lib/libmpfr.4.dylib /usr/local/lib/libmpfr.1.dylib
ln -s /opt/local/var/macports/software/gmp/5.0.1_0/opt/local/lib/libgmp.3.dylib /usr/local/lib/libgmp.3.dylib
\end{lstlisting}

Credits: Andrea googled this for me :)


\section{All in one boot disk}

A DOS-formatted GRUB boot disk (with other stuff on there, e.g.
a free DOS clone and tools):

\url{http://rescup.winbuilder.net/bootdisk/}

I use this because I can access this with the \verb#mtools# tools:
When I need to copy a new kernel to the disk, I just type

\begin{verbatim}
mcopy -i bootdisk.img kernel.img ::kernel.img
\end{verbatim}

(the first \verb#:# in \verb#::# is a ``drive letter'' used for
talking to the disk image referenced by \verb#-i#).

I modified the boot disk so that it has only one menu entry
to boot \verb#/ulix.bin#. It must be copied to the disk with
mtools. (When mounting and copying with cp, the filesystem
breaks -- why?)


\section{GDT Trick}

Higher Half With GDT,

\url{http://wiki.osdev.org/Higher_Half_With_GDT}


\section{readelf}

Useful tool \verb#readelf# (in package \verb#binutils#), shows
structure of ELF files.

Discussion in book ``Professional Linux Kernel Architecture'', 2008,
\url{Wrox.Professional.Linux.Kernel.Architecture.Oct.2008.pdf},
pp. 1241 ff.

\section{mfstool}

[[mfstool]] can access Minix filesystem images.

\url{http://mfstool.sourceforge.net/}

It works on Linux, Mac OS, and other Unix versions.

Example:

{\small
\begin{verbatim}
[esser@macbookpro:Code]$ mfstool dir minix1.img
.
..
testname.txt
test0002.txt
\end{verbatim}
}

\section{minixfs (MacFUSE)}

[[minixfs]] from the MacFUSE-based UnixFS package lets OS X users
mount Minix-formatted volumes---but only in read-only mode.

\url{http://osxbook.com/software/unixfs/}


\cleardoublepage
\addcontentsline{toc}{part}{Appendices}


\clearpage
\addcontentsline{toc}{section}{Chunk Index}
\chapter*{Chunk Index}

\nowebchunks

% how can this be merged with normal latex index?
\cleardoublepage

\addcontentsline{toc}{section}{Identifier Index}
\chapter*{Identifier Index}

\nowebindex



\cleardoublepage
\addcontentsline{toc}{section}{Index}
\printindex

\cleardoublepage
\addcontentsline{toc}{section}{Bibliography}
\bibliographystyle{hgealpha}
%\setbibpreamble{\setlength{\bibhang}{10em}}
\bibliography{diss-hgesser,ulix-felix}




\end{document}
